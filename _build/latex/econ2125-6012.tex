%% Generated by Sphinx.
\def\sphinxdocclass{jupyterBook}
\documentclass[letterpaper,10pt,english]{jupyterBook}
\ifdefined\pdfpxdimen
   \let\sphinxpxdimen\pdfpxdimen\else\newdimen\sphinxpxdimen
\fi \sphinxpxdimen=.75bp\relax
\ifdefined\pdfimageresolution
    \pdfimageresolution= \numexpr \dimexpr1in\relax/\sphinxpxdimen\relax
\fi
%% let collapsible pdf bookmarks panel have high depth per default
\PassOptionsToPackage{bookmarksdepth=5}{hyperref}
%% turn off hyperref patch of \index as sphinx.xdy xindy module takes care of
%% suitable \hyperpage mark-up, working around hyperref-xindy incompatibility
\PassOptionsToPackage{hyperindex=false}{hyperref}
%% memoir class requires extra handling
\makeatletter\@ifclassloaded{memoir}
{\ifdefined\memhyperindexfalse\memhyperindexfalse\fi}{}\makeatother

\PassOptionsToPackage{warn}{textcomp}

\catcode`^^^^00a0\active\protected\def^^^^00a0{\leavevmode\nobreak\ }
\usepackage{cmap}
\usepackage{fontspec}
\defaultfontfeatures[\rmfamily,\sffamily,\ttfamily]{}
\usepackage{amsmath,amssymb,amstext}
\usepackage{polyglossia}
\setmainlanguage{english}



\setmainfont{FreeSerif}[
  Extension      = .otf,
  UprightFont    = *,
  ItalicFont     = *Italic,
  BoldFont       = *Bold,
  BoldItalicFont = *BoldItalic
]
\setsansfont{FreeSans}[
  Extension      = .otf,
  UprightFont    = *,
  ItalicFont     = *Oblique,
  BoldFont       = *Bold,
  BoldItalicFont = *BoldOblique,
]
\setmonofont{FreeMono}[
  Extension      = .otf,
  UprightFont    = *,
  ItalicFont     = *Oblique,
  BoldFont       = *Bold,
  BoldItalicFont = *BoldOblique,
]



\usepackage[Bjarne]{fncychap}
\usepackage[,numfigreset=1,mathnumfig]{sphinx}

\fvset{fontsize=\small}
\usepackage{geometry}


% Include hyperref last.
\usepackage{hyperref}
% Fix anchor placement for figures with captions.
\usepackage{hypcap}% it must be loaded after hyperref.
% Set up styles of URL: it should be placed after hyperref.
\urlstyle{same}


\usepackage{sphinxmessages}



        % Start of preamble defined in sphinx-jupyterbook-latex %
         \usepackage[Latin,Greek]{ucharclasses}
        \usepackage{unicode-math}
        % fixing title of the toc
        \addto\captionsenglish{\renewcommand{\contentsname}{Contents}}
        \hypersetup{
            pdfencoding=auto,
            psdextra
        }
        % End of preamble defined in sphinx-jupyterbook-latex %
        

\title{ECON2125/6012}
\date{Aug 30, 2023}
\release{}
\author{Fedor Iskhakov}
\newcommand{\sphinxlogo}{\vbox{}}
\renewcommand{\releasename}{}
\makeindex
\begin{document}

\pagestyle{empty}
\sphinxmaketitle
\pagestyle{plain}
\sphinxtableofcontents
\pagestyle{normal}
\phantomsection\label{\detokenize{00.index::doc}}


\begin{DUlineblock}{0em}
\item[] \sphinxstylestrong{\Large Preliminary schedule}
\end{DUlineblock}


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|T|T|}
\hline
\sphinxstyletheadfamily 
\sphinxAtStartPar
Week
&\sphinxstyletheadfamily 
\sphinxAtStartPar
Date
&\sphinxstyletheadfamily 
\sphinxAtStartPar
Topic
&\sphinxstyletheadfamily 
\sphinxAtStartPar
Notes
\\
\hline
\sphinxAtStartPar
1
&
\sphinxAtStartPar
July 27
&
\sphinxAtStartPar
{\hyperref[\detokenize{01.introduction::doc}]{\sphinxcrossref{\DUrole{doc,std,std-doc}{Introduction}}}}
&
\sphinxAtStartPar
Recorded lecture
\\
\hline
\sphinxAtStartPar
2
&
\sphinxAtStartPar
Aug 3
&
\sphinxAtStartPar
{\hyperref[\detokenize{02.optimization_intro::doc}]{\sphinxcrossref{\DUrole{doc,std,std-doc}{Univariate and bivariate optimization}}}}
&
\sphinxAtStartPar
Tutorials start
\\
\hline
\sphinxAtStartPar
3
&
\sphinxAtStartPar
Aug 10
&
\sphinxAtStartPar
{\hyperref[\detokenize{03.set_theory::doc}]{\sphinxcrossref{\DUrole{doc,std,std-doc}{Elements of set theory}}}}
&
\sphinxAtStartPar

\\
\hline
\sphinxAtStartPar
3
&
\sphinxAtStartPar
Aug 17
&
\sphinxAtStartPar
{\hyperref[\detokenize{04.basic_analysis::doc}]{\sphinxcrossref{\DUrole{doc,std,std-doc}{Basics of real analysis}}}}
&
\sphinxAtStartPar

\\
\hline
\sphinxAtStartPar
Test
&
\sphinxAtStartPar

&
\sphinxAtStartPar
15\%
&
\sphinxAtStartPar
Submit by Aug 23
\\
\hline
\sphinxAtStartPar
4
&
\sphinxAtStartPar
Aug 24
&
\sphinxAtStartPar
{\hyperref[\detokenize{05.linear_algebra::doc}]{\sphinxcrossref{\DUrole{doc,std,std-doc}{Elements of linear algebra}}}}
&
\sphinxAtStartPar

\\
\hline
\sphinxAtStartPar
6
&
\sphinxAtStartPar
Aug 31
&
\sphinxAtStartPar
{\hyperref[\detokenize{06.optimization_fundamentals::doc}]{\sphinxcrossref{\DUrole{doc,std,std-doc}{Fundamentals of optimization}}}}
&
\sphinxAtStartPar

\\
\hline
\sphinxAtStartPar
Test
&
\sphinxAtStartPar

&
\sphinxAtStartPar
15\%
&
\sphinxAtStartPar
Submit by Sept 3
\\
\hline
\sphinxAtStartPar
Break
&
\sphinxAtStartPar

&
\sphinxAtStartPar

&
\sphinxAtStartPar
2 weeks
\\
\hline
\sphinxAtStartPar
7
&
\sphinxAtStartPar
Sept 21
&
\sphinxAtStartPar
{\hyperref[\detokenize{07.unconstrained::doc}]{\sphinxcrossref{\DUrole{doc,std,std-doc}{Unconstrained optimization}}}}
&
\sphinxAtStartPar

\\
\hline
\sphinxAtStartPar
8
&
\sphinxAtStartPar
Sept 28
&
\sphinxAtStartPar
{\hyperref[\detokenize{08.constrained::doc}]{\sphinxcrossref{\DUrole{doc,std,std-doc}{Constrained optimization}}}}
&
\sphinxAtStartPar

\\
\hline
\sphinxAtStartPar
Test
&
\sphinxAtStartPar

&
\sphinxAtStartPar
15\%
&
\sphinxAtStartPar
Submit by Oct 4
\\
\hline
\sphinxAtStartPar
9
&
\sphinxAtStartPar
Oct 5
&
\sphinxAtStartPar
{\hyperref[\detokenize{09.practical_session::doc}]{\sphinxcrossref{\DUrole{doc,std,std-doc}{Practical session/invited speaker}}}}
&
\sphinxAtStartPar
TBA
\\
\hline
\sphinxAtStartPar
10
&
\sphinxAtStartPar
Oct 12
&
\sphinxAtStartPar
{\hyperref[\detokenize{10.envelope_maximum::doc}]{\sphinxcrossref{\DUrole{doc,std,std-doc}{Envelope and maximum theorems}}}}
&
\sphinxAtStartPar

\\
\hline
\sphinxAtStartPar
11
&
\sphinxAtStartPar
Oct 19
&
\sphinxAtStartPar
{\hyperref[\detokenize{11.dynamic::doc}]{\sphinxcrossref{\DUrole{doc,std,std-doc}{Dynamic optimization}}}}
&
\sphinxAtStartPar

\\
\hline
\sphinxAtStartPar
12
&
\sphinxAtStartPar
Oct 26
&
\sphinxAtStartPar
{\hyperref[\detokenize{12.revision::doc}]{\sphinxcrossref{\DUrole{doc,std,std-doc}{Revision}}}}
&
\sphinxAtStartPar

\\
\hline
\sphinxAtStartPar
Exam
&
\sphinxAtStartPar

&
\sphinxAtStartPar
55\%
&
\sphinxAtStartPar
During exam period
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

\begin{DUlineblock}{0em}
\item[] \sphinxstylestrong{\large ANU course pages}
\end{DUlineblock}

\sphinxAtStartPar
\sphinxhref{https://wattlecourses.anu.edu.au/course/view.php?id=41102}{Course Wattle page}
Schedule, announcements, teaching team contacts, recordings, assignement, grades

\sphinxAtStartPar
\sphinxhref{https://programsandcourses.anu.edu.au/2023/course/ECON2125\#terms}{Course overview}
\sphinxhref{https://programsandcourses.anu.edu.au/course/ECON2125/Second\%20Semester/6275}{Class summary}
General course description in ANU Programs and Courses

\begin{DUlineblock}{0em}
\item[] \sphinxstylestrong{\large Tutoring team}
\end{DUlineblock}

\sphinxAtStartPar
\sphinxstylestrong{Wending Liu}
\begin{itemize}
\item {} 
\sphinxAtStartPar
Email: \sphinxhref{mailto:Wending.Liu@anu.edu.au}{Wending.Liu@anu.edu.au}

\item {} 
\sphinxAtStartPar
Room: Room 2084, Copland Bld (24)

\item {} 
\sphinxAtStartPar
Office hours: \sphinxstylestrong{Friday 1pm\sphinxhyphen{}3pm}

\end{itemize}

\sphinxAtStartPar
\sphinxstylestrong{Chien Yeh}
\begin{itemize}
\item {} 
\sphinxAtStartPar
Email: \sphinxhref{mailto:Chien.Yeh@anu.edu.au}{Chien.Yeh@anu.edu.au}

\item {} 
\sphinxAtStartPar
Room: Room 1010, HW Arndt Bld (25a)

\item {} 
\sphinxAtStartPar
Office hours: \sphinxstylestrong{Monday 2pm\sphinxhyphen{}4pm}

\end{itemize}

\begin{sphinxadmonition}{note}{Note:}
\sphinxAtStartPar
Chien moved office to 1010, HW Arndt Bld (25a)
\end{sphinxadmonition}



\sphinxstepscope


\chapter{Welcome}
\label{\detokenize{01.introduction:welcome}}\label{\detokenize{01.introduction::doc}}
\sphinxAtStartPar
Course title: \sphinxstylestrong{“Optimization for Economics and Financial Economics”}
\begin{itemize}
\item {} 
\sphinxAtStartPar
Elective second year course in the \sphinxstyleemphasis{Bachelor of Economics} program ECON2125

\item {} 
\sphinxAtStartPar
Compulsory second math course in the \sphinxstyleemphasis{Master of Economics} program ECON6012

\end{itemize}

\sphinxAtStartPar
The two courses are identical in content and assessment, but final grades may be adjusted depending on your program.


\section{Plan for this lecture}
\label{\detokenize{01.introduction:plan-for-this-lecture}}\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
Organization

\item {} 
\sphinxAtStartPar
Administrative topics

\item {} 
\sphinxAtStartPar
Course content

\item {} 
\sphinxAtStartPar
Self\sphinxhyphen{}learning materials

\end{enumerate}


\section{Instructor}
\label{\detokenize{01.introduction:instructor}}
\sphinxAtStartPar
\sphinxstylestrong{Fedor Iskhakov}
Professor of Economics at RSE
\begin{itemize}
\item {} 
\sphinxAtStartPar
Office: 1021 HW Arndt Building

\item {} 
\sphinxAtStartPar
Email: \sphinxhref{mailto:fedor.iskhakov@anu.edu.au}{fedor.iskhakov@anu.edu.au}

\item {} 
\sphinxAtStartPar
Web: \sphinxhref{https://fedor.iskh.me}{fedor.iskh.me}

\item {} 
\sphinxAtStartPar
Contact hours: Thursday 9:30\sphinxhyphen{}11:30

\end{itemize}


\section{Timetable}
\label{\detokenize{01.introduction:timetable}}
\sphinxAtStartPar
\sphinxstylestrong{Face\sphinxhyphen{}to\sphinxhyphen{}face:}
\begin{itemize}
\item {} 
\sphinxAtStartPar
Lectures: Thursday 15:30 — 17:30

\item {} 
\sphinxAtStartPar
Location: \sphinxstylestrong{DNF Dunbar Lecture Theatre, Physics Bldg 39A}

\end{itemize}

\sphinxAtStartPar
\sphinxstylestrong{Online:}
\begin{itemize}
\item {} 
\sphinxAtStartPar
Echo\sphinxhyphen{}360 recordings on Wattle

\item {} 
\sphinxAtStartPar
All notes and materials on \sphinxstylestrong{\sphinxhref{http://optim.iskh.me}{optim.iskh.me}}

\end{itemize}

\sphinxAtStartPar
Face\sphinxhyphen{}to\sphinxhyphen{}face is strictly preferred


\section{Course web pages}
\label{\detokenize{01.introduction:course-web-pages}}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxhref{https://wattlecourses.anu.edu.au/course/view.php?id=41102}{Wattle}
Schedule, announcements, teaching team contacts, recordings, assignment, grades

\item {} 
\sphinxAtStartPar
\sphinxhref{https://optim.iskh.me}{Online notes}
Lecture notes, slides, assignment tasks

\item {} 
\sphinxAtStartPar
Lecture slides should appear online the previous day before the lecture

\item {} 
\sphinxAtStartPar
Details on assessment including the exam instructions will appear on Wattle

\end{itemize}


\section{Tutorials}
\label{\detokenize{01.introduction:tutorials}}\begin{itemize}
\item {} 
\sphinxAtStartPar
Enrollments open on \sphinxstyleemphasis{Wattle}

\end{itemize}

\sphinxAtStartPar
Tutorial questions
\begin{itemize}
\item {} 
\sphinxAtStartPar
posted on the course website

\item {} 
\sphinxAtStartPar
not assessed, help you learn and prepare

\end{itemize}

\sphinxAtStartPar
Tutorials start on week 2


\section{Tutors}
\label{\detokenize{01.introduction:tutors}}
\sphinxAtStartPar
\sphinxstylestrong{Wending Liu}
\begin{itemize}
\item {} 
\sphinxAtStartPar
Email: \sphinxhref{mailto:Wending.Liu@anu.edu.au}{Wending.Liu@anu.edu.au}

\item {} 
\sphinxAtStartPar
Room: Room 2084, Copland Bld (24)

\item {} 
\sphinxAtStartPar
Office hours: \sphinxstylestrong{Friday 1pm\sphinxhyphen{}3pm}

\end{itemize}

\sphinxAtStartPar
\sphinxstylestrong{Chien Yeh}
\begin{itemize}
\item {} 
\sphinxAtStartPar
Email: \sphinxhref{mailto:Chien.Yeh@anu.edu.au}{Chien.Yeh@anu.edu.au}

\item {} 
\sphinxAtStartPar
Room: Room 1010, HW Arndt Bld (25a)

\item {} 
\sphinxAtStartPar
Office hours: \sphinxstylestrong{Monday 2pm\sphinxhyphen{}4pm}

\end{itemize}


\section{Prerequisites}
\label{\detokenize{01.introduction:prerequisites}}
\sphinxAtStartPar
See \sphinxhref{https://programsandcourses.anu.edu.au/2023/course/ECON2125\#terms}{Course overview} and
\sphinxhref{https://programsandcourses.anu.edu.au/course/ECON2125/Second\%20Semester/6275}{Class summary}

\sphinxAtStartPar
What you actually need to know:
\begin{itemize}
\item {} 
\sphinxAtStartPar
basic algebra

\item {} 
\sphinxAtStartPar
basic calculus

\item {} 
\sphinxAtStartPar
some idea of what a matrix is, etc.

\end{itemize}

\sphinxAtStartPar
≈ content of EMET1001/EMET7001 math course


\section{Focus?}
\label{\detokenize{01.introduction:focus}}
\sphinxAtStartPar
\sphinxstyleemphasis{Q:} Is this optimization or a general math\sphinxhyphen{}econ course?

\sphinxAtStartPar
\sphinxstyleemphasis{A:} A general course on mathematical modeling for economics and financial economics. Optimization will be an important and recurring theme.


\section{Assessment}
\label{\detokenize{01.introduction:assessment}}\begin{itemize}
\item {} 
\sphinxAtStartPar
3 timed open book tests (15\% each)

\item {} 
\sphinxAtStartPar
Final exam (55\%)

\end{itemize}

\sphinxAtStartPar
The three tests spread out through the semester will check the knowledge of the immediately preceding material. The final closed book in\sphinxhyphen{}person exam will cover the entire course.


\section{Questions}
\label{\detokenize{01.introduction:questions}}\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
Administrative questions: RSE admin

\end{enumerate}
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Bronwyn Cammack} Senior School Administrator

\item {} 
\sphinxAtStartPar
Email: \sphinxhref{mailto:enquiries.rse@anu.edu.au}{enquiries.rse@anu.edu.au}

\item {} 
\sphinxAtStartPar
“I can not register for the tutorial group”

\end{itemize}
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\setcounter{enumi}{1}
\item {} 
\sphinxAtStartPar
Content related questions: please, refer to the tutors

\end{enumerate}
\begin{itemize}
\item {} 
\sphinxAtStartPar
“I don’t understand why this function is convex”

\end{itemize}
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\setcounter{enumi}{2}
\item {} 
\sphinxAtStartPar
Other questions: to Fedor

\end{enumerate}
\begin{itemize}
\item {} 
\sphinxAtStartPar
“I’m working hard but still can not keep up”

\item {} 
\sphinxAtStartPar
“Can I please have extra assignment for more practice”

\end{itemize}


\section{Attendance}
\label{\detokenize{01.introduction:attendance}}\begin{itemize}
\item {} 
\sphinxAtStartPar
Please, \sphinxstylestrong{do not} use email for \sphinxstyleemphasis{instructional} questions\textbackslash{}Instead make use of the office hours

\item {} 
\sphinxAtStartPar
Attendance of tutorials is \sphinxstyleemphasis{very highly} recommended\\
You will make your life much easier this way

\item {} 
\sphinxAtStartPar
Attendance of lectures is \sphinxstyleemphasis{highly} recommended\\
But not mandatory

\end{itemize}


\section{Comments for lectures notes/slides}
\label{\detokenize{01.introduction:comments-for-lectures-notes-slides}}\begin{itemize}
\item {} 
\sphinxAtStartPar
Cover exactly what you are required to know

\item {} 
\sphinxAtStartPar
Code inserts are the exception, they are not assessable

\end{itemize}

\sphinxAtStartPar
In particular, you need to know:
\begin{itemize}
\item {} 
\sphinxAtStartPar
The definitions from the notes

\item {} 
\sphinxAtStartPar
The facts from the notes

\item {} 
\sphinxAtStartPar
How to apply facts and definitions

\end{itemize}

\sphinxAtStartPar
If a concept in not in the lecture notes, it is not assessable


\section{Definitions and facts}
\label{\detokenize{01.introduction:definitions-and-facts}}
\sphinxAtStartPar
The lectures notes/slides are full of definitions and facts.

\begin{sphinxadmonition}{note}{Definition}

\sphinxAtStartPar
Functions \(f: \mathbb{R} \rightarrow \mathbb{R}\) is called \sphinxstyleemphasis{continuous at} \(x\) if, for any sequence \(\{x_n\}\) converging to \(x\), we have \(f(x_n) \rightarrow f(x)\).
\end{sphinxadmonition}

\sphinxAtStartPar
Possible exam question: “Show  that if functions \(f\) and \(g\) are continuous at \(x\), so is \(f+g\).”

\sphinxAtStartPar
You should start the answer with the definition of continuity:

\sphinxAtStartPar
“Let \(\{x_n\}\) be any sequence converging to \(x\). We need to show that \(f(x_n) + g(x_n) \rightarrow f(x) + g(x)\). To see this, note that …”


\section{Facts}
\label{\detokenize{01.introduction:facts}}
\sphinxAtStartPar
In the lecture notes/slides you will often see

\begin{sphinxadmonition}{note}{Fact}

\sphinxAtStartPar
The only \(N\)\sphinxhyphen{}dimensional subset of \(\mathbb{R}^N\) is \(\mathbb{R}^N\).
\end{sphinxadmonition}

\sphinxAtStartPar
This means either:
\begin{itemize}
\item {} 
\sphinxAtStartPar
theorem

\item {} 
\sphinxAtStartPar
proposition

\item {} 
\sphinxAtStartPar
lemma

\item {} 
\sphinxAtStartPar
true statement

\end{itemize}

\sphinxAtStartPar
All well known results. You need to remember them, have some intuition for, and be able to apply.


\section{Note on Assessments}
\label{\detokenize{01.introduction:note-on-assessments}}
\sphinxAtStartPar
Assessable = definitions and facts + last year level math + a few simple steps of logic

\sphinxAtStartPar
Exams and tests will award:
\begin{itemize}
\item {} 
\sphinxAtStartPar
Hard work

\item {} 
\sphinxAtStartPar
Deeper understanding of the concepts

\end{itemize}

\sphinxAtStartPar
In each question there will be a \sphinxstyleemphasis{easy} path to the solution


\section{Reading materials}
\label{\detokenize{01.introduction:reading-materials}}
\sphinxAtStartPar
\sphinxstylestrong{Primary reference:} lecture slides

\sphinxAtStartPar
\sphinxstylestrong{Books:}

\noindent\sphinxincludegraphics[height=100\sphinxpxdimen]{{simon_blume}.png}

\noindent\sphinxincludegraphics[height=100\sphinxpxdimen]{{sundaram}.png}

\noindent\sphinxincludegraphics[height=100\sphinxpxdimen]{{stachurski}.png}
\begin{itemize}
\item {} 
\sphinxAtStartPar
“Mathematics for Economists” (1994) by Simon, C. and L. Blume

\item {} 
\sphinxAtStartPar
“A First Course in Optimization” (1996) Theory by Rangarajan Sundaram

\item {} 
\sphinxAtStartPar
“A Primer in Econometric Theory” (2016) by John Stachurski

\end{itemize}

\sphinxAtStartPar
Readings are supplementary but will provide a more detailed explanation with additional examples.
\begin{itemize}
\item {} 
\sphinxAtStartPar
Each lecture will reference book chapters

\end{itemize}


\section{Key points for the administrative part}
\label{\detokenize{01.introduction:key-points-for-the-administrative-part}}\begin{itemize}
\item {} 
\sphinxAtStartPar
Tutorials start next week, \sphinxstylestrong{please register before the next lecture}

\item {} 
\sphinxAtStartPar
Course content = what’s in lecture notes/slides

\item {} 
\sphinxAtStartPar
Lecture slides are available online and will be updated throughout the semester

\item {} 
\sphinxAtStartPar
Optimization is a recurring theme but not the only topic

\end{itemize}


\section{What you will learn in the course}
\label{\detokenize{01.introduction:what-you-will-learn-in-the-course}}\begin{itemize}
\item {} 
\sphinxAtStartPar
The lecture plan is on the course website \sphinxhref{https://optim.iskh.me}{optim.iskh.me} and \sphinxhref{https://programsandcourses.anu.edu.au/course/ECON2125/Second\%20Semester/6275}{Class summary}

\item {} 
\sphinxAtStartPar
See the list of topics on the left

\end{itemize}

\sphinxAtStartPar
Essentially:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Mathematical foundations}

\end{enumerate}
\begin{itemize}
\item {} 
\sphinxAtStartPar
elements of analysis

\item {} 
\sphinxAtStartPar
elements of linear algebra

\item {} 
\sphinxAtStartPar
elements of probability

\end{itemize}
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\setcounter{enumi}{1}
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Optimization theory}

\end{enumerate}
\begin{itemize}
\item {} 
\sphinxAtStartPar
when solution exists

\item {} 
\sphinxAtStartPar
unconstrained optimization

\item {} 
\sphinxAtStartPar
optimization with equality constraints

\item {} 
\sphinxAtStartPar
optimization with inequality constraints

\end{itemize}
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\setcounter{enumi}{2}
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Further topics}

\end{enumerate}
\begin{itemize}
\item {} 
\sphinxAtStartPar
Parameterized optimization problems

\item {} 
\sphinxAtStartPar
Optimization in dynamics

\end{itemize}


\section{Further material and self\sphinxhyphen{}learning}
\label{\detokenize{01.introduction:further-material-and-self-learning}}\begin{itemize}
\item {} 
\sphinxAtStartPar
Each lecture will suggest some material for further reading and learning

\item {} 
\sphinxAtStartPar
Today: \sphinxstylestrong{The Wason Selection Task} logical problem

\item {} 
\sphinxAtStartPar
Mathematics relies on rules of logic

\item {} 
\sphinxAtStartPar
Yet, for human brain applying mathematical logic may be difficult, and dependent on the domain

\end{itemize}

\sphinxAtStartPar
Please, watch the video and try to solve the puzzle yourself
\sphinxhref{https://youtu.be/iR97LBgpsl8}{youtu.be/iR97LBgpsl8}

\sphinxstepscope


\chapter{Univariate and bivariate optimization}
\label{\detokenize{02.optimization_intro:univariate-and-bivariate-optimization}}\label{\detokenize{02.optimization_intro::doc}}
\sphinxAtStartPar
\sphinxstylestrong{ECON2125/6012 Lecture 2}
Fedor Iskhakov


\section{Announcements \& Reminders}
\label{\detokenize{02.optimization_intro:announcements-reminders}}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Tutorials start tomorrow (Aug 4)}

\item {} 
\sphinxAtStartPar
Register for tutorials on \sphinxhref{https://wattlecourses.anu.edu.au/course/view.php?id=41102}{Wattle} if you have not done so already

\item {} 
\sphinxAtStartPar
Office hours of the tutors are updated:
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Wending Liu}
\begin{itemize}
\item {} 
\sphinxAtStartPar
Email: \sphinxhref{mailto:Wending.Liu@anu.edu.au}{Wending.Liu@anu.edu.au}

\item {} 
\sphinxAtStartPar
Room: Room 2084, Copland Bld (24) (\sphinxstyleemphasis{updated!})

\item {} 
\sphinxAtStartPar
Office hours: \sphinxstylestrong{Friday 1pm\sphinxhyphen{}3pm}

\end{itemize}

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Chien Yeh}
\begin{itemize}
\item {} 
\sphinxAtStartPar
Email: \sphinxhref{mailto:Chien.Yeh@anu.edu.au}{Chien.Yeh@anu.edu.au}

\item {} 
\sphinxAtStartPar
Room: Room 2106, Copland Bld (24)

\item {} 
\sphinxAtStartPar
Office hours: \sphinxstylestrong{Monday 2pm\sphinxhyphen{}4pm}

\end{itemize}

\end{itemize}

\item {} 
\sphinxAtStartPar
Reminder on how to ask questions:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
Administrative: RSE admin

\item {} 
\sphinxAtStartPar
Content/understanding: tutors

\item {} 
\sphinxAtStartPar
Other: to Fedor

\end{enumerate}

\end{itemize}


\section{Plan for this lecture}
\label{\detokenize{02.optimization_intro:plan-for-this-lecture}}\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
Motivation (math vs. computing)

\item {} 
\sphinxAtStartPar
Univariate optimization

\item {} 
\sphinxAtStartPar
Working with bivariate functions

\item {} 
\sphinxAtStartPar
Bivariate optimization

\end{enumerate}

\sphinxAtStartPar
\sphinxstylestrong{Supplementary reading:}
\begin{itemize}
\item {} 
\sphinxAtStartPar
Simon \& Blume: part 1 (revision)

\item {} 
\sphinxAtStartPar
Sundaram: sections 1.1, 1.4, chapter 2, chapter 4

\end{itemize}


\section{Computing}
\label{\detokenize{02.optimization_intro:computing}}
\sphinxAtStartPar
The \sphinxstyleemphasis{classic} way we do mathematics is pencil and paper
\begin{quote}

\sphinxAtStartPar
In 1944, Hans Bethe solved following problem \sphinxstyleemphasis{by hand}:\\
Will detonating an atom bomb ignite the atmosphere and
thereby destroy life on earth?\\
\sphinxhref{https://inis.iaea.org/search/search.aspx?orig\_q=RN:25070731}{source}
\end{quote}

\sphinxAtStartPar
These days we rarely calculate with actual numbers

\sphinxAtStartPar
Almost all calculations are done on computers

\begin{sphinxadmonition}{note}{Example: numerical integration}
\begin{equation*}
\begin{split}
\frac{1}{\sqrt{2\pi}} 
\int_{-2}^2 
\exp\left\{ - \frac{x^2}{2} \right\} dx
\end{split}
\end{equation*}\end{sphinxadmonition}

\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{from} \PYG{n+nn}{scipy}\PYG{n+nn}{.}\PYG{n+nn}{stats} \PYG{k+kn}{import} \PYG{n}{norm}
\PYG{k+kn}{from} \PYG{n+nn}{scipy}\PYG{n+nn}{.}\PYG{n+nn}{integrate} \PYG{k+kn}{import} \PYG{n}{quad}
\PYG{n}{phi} \PYG{o}{=} \PYG{n}{norm}\PYG{p}{(}\PYG{p}{)}
\PYG{n}{value}\PYG{p}{,} \PYG{n}{error} \PYG{o}{=} \PYG{n}{quad}\PYG{p}{(}\PYG{n}{phi}\PYG{o}{.}\PYG{n}{pdf}\PYG{p}{,} \PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{2}\PYG{p}{,} \PYG{l+m+mi}{2}\PYG{p}{)}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Integral value =}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}\PYG{n}{value}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
Integral value = 0.9544997361036417
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\begin{sphinxadmonition}{note}{Example: Numerical optimization}
\begin{equation*}
\begin{split}
f(x) = - \exp
\left\{-\frac{(x - 5.0)^4}{1.5} \right\}
\rightarrow \min
\end{split}
\end{equation*}\end{sphinxadmonition}

\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{from} \PYG{n+nn}{scipy}\PYG{n+nn}{.}\PYG{n+nn}{optimize} \PYG{k+kn}{import} \PYG{n}{fminbound}
\PYG{k+kn}{import} \PYG{n+nn}{numpy} \PYG{k}{as} \PYG{n+nn}{np}
\PYG{n}{f} \PYG{o}{=} \PYG{k}{lambda} \PYG{n}{x}\PYG{p}{:} \PYG{o}{\PYGZhy{}}\PYG{n}{np}\PYG{o}{.}\PYG{n}{exp}\PYG{p}{(}\PYG{o}{\PYGZhy{}}\PYG{p}{(}\PYG{n}{x} \PYG{o}{\PYGZhy{}} \PYG{l+m+mf}{5.0}\PYG{p}{)}\PYG{o}{*}\PYG{o}{*}\PYG{l+m+mi}{4} \PYG{o}{/} \PYG{l+m+mf}{1.5}\PYG{p}{)}
\PYG{n}{res} \PYG{o}{=} \PYG{n}{fminbound}\PYG{p}{(}\PYG{n}{f}\PYG{p}{,} \PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{10}\PYG{p}{,} \PYG{l+m+mi}{10}\PYG{p}{)}  \PYG{c+c1}{\PYGZsh{} find approx solution}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Minimum value is attained approximately at}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{res}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
Minimum value is attained approximately at 4.999941901210501
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\begin{sphinxadmonition}{note}{Example: Visualization}

\sphinxAtStartPar
What does this function look like?
\begin{equation*}
\begin{split}
f(x, y) = \frac{\cos(x^2 + y^2)}{1 + x^2 + y^2}
\end{split}
\end{equation*}\end{sphinxadmonition}

\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{import} \PYG{n+nn}{matplotlib}\PYG{n+nn}{.}\PYG{n+nn}{pyplot} \PYG{k}{as} \PYG{n+nn}{plt}
\PYG{k+kn}{from} \PYG{n+nn}{mpl\PYGZus{}toolkits}\PYG{n+nn}{.}\PYG{n+nn}{mplot3d}\PYG{n+nn}{.}\PYG{n+nn}{axes3d} \PYG{k+kn}{import} \PYG{n}{Axes3D}
\PYG{k+kn}{import} \PYG{n+nn}{numpy} \PYG{k}{as} \PYG{n+nn}{np}
\PYG{k+kn}{from} \PYG{n+nn}{matplotlib} \PYG{k+kn}{import} \PYG{n}{cm}
\PYG{n}{f} \PYG{o}{=} \PYG{k}{lambda} \PYG{n}{x}\PYG{p}{,} \PYG{n}{y}\PYG{p}{:} \PYG{n}{np}\PYG{o}{.}\PYG{n}{cos}\PYG{p}{(}\PYG{n}{x}\PYG{o}{*}\PYG{o}{*}\PYG{l+m+mi}{2} \PYG{o}{+} \PYG{n}{y}\PYG{o}{*}\PYG{o}{*}\PYG{l+m+mi}{2}\PYG{p}{)} \PYG{o}{/} \PYG{p}{(}\PYG{l+m+mi}{1} \PYG{o}{+} \PYG{n}{x}\PYG{o}{*}\PYG{o}{*}\PYG{l+m+mi}{2} \PYG{o}{+} \PYG{n}{y}\PYG{o}{*}\PYG{o}{*}\PYG{l+m+mi}{2}\PYG{p}{)}
\PYG{n}{xgrid} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{linspace}\PYG{p}{(}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{3}\PYG{p}{,} \PYG{l+m+mi}{3}\PYG{p}{,} \PYG{l+m+mi}{50}\PYG{p}{)}
\PYG{n}{ygrid} \PYG{o}{=} \PYG{n}{xgrid}
\PYG{n}{x}\PYG{p}{,} \PYG{n}{y} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{meshgrid}\PYG{p}{(}\PYG{n}{xgrid}\PYG{p}{,} \PYG{n}{ygrid}\PYG{p}{)}
\PYG{n}{fig} \PYG{o}{=} \PYG{n}{plt}\PYG{o}{.}\PYG{n}{figure}\PYG{p}{(}\PYG{n}{figsize}\PYG{o}{=}\PYG{p}{(}\PYG{l+m+mi}{8}\PYG{p}{,} \PYG{l+m+mi}{6}\PYG{p}{)}\PYG{p}{)}
\PYG{n}{ax} \PYG{o}{=} \PYG{n}{fig}\PYG{o}{.}\PYG{n}{add\PYGZus{}subplot}\PYG{p}{(}\PYG{l+m+mi}{111}\PYG{p}{,} \PYG{n}{projection}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{3d}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{n}{ax}\PYG{o}{.}\PYG{n}{plot\PYGZus{}surface}\PYG{p}{(}\PYG{n}{x}\PYG{p}{,}
                \PYG{n}{y}\PYG{p}{,}
                \PYG{n}{f}\PYG{p}{(}\PYG{n}{x}\PYG{p}{,} \PYG{n}{y}\PYG{p}{)}\PYG{p}{,}
                \PYG{n}{rstride}\PYG{o}{=}\PYG{l+m+mi}{2}\PYG{p}{,} \PYG{n}{cstride}\PYG{o}{=}\PYG{l+m+mi}{2}\PYG{p}{,}
                \PYG{n}{cmap}\PYG{o}{=}\PYG{n}{cm}\PYG{o}{.}\PYG{n}{jet}\PYG{p}{,}
                \PYG{n}{alpha}\PYG{o}{=}\PYG{l+m+mf}{0.7}\PYG{p}{,}
                \PYG{n}{linewidth}\PYG{o}{=}\PYG{l+m+mf}{0.25}\PYG{p}{)}
\PYG{n}{ax}\PYG{o}{.}\PYG{n}{set\PYGZus{}zlim}\PYG{p}{(}\PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.5}\PYG{p}{,} \PYG{l+m+mf}{1.0}\PYG{p}{)}
\PYG{n}{plt}\PYG{o}{.}\PYG{n}{show}\PYG{p}{(}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\noindent{\hspace*{\fill}\sphinxincludegraphics[width=0.800\linewidth]{{9f17d8225a84f50e4af3428865a35a303a960a7dfc688ae24291d0485ed2538d}.png}\hspace*{\fill}}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\begin{sphinxadmonition}{note}{Example: Symbolic calculations }

\sphinxAtStartPar
Differentiate \(f(x) = (1 + 2x)^5\).\\
Forgotten how?  No problems, just ask a computer for \sphinxstyleemphasis{symbolic} derivative
\end{sphinxadmonition}

\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{import} \PYG{n+nn}{sympy} \PYG{k}{as} \PYG{n+nn}{sp}
\PYG{n}{x} \PYG{o}{=} \PYG{n}{sp}\PYG{o}{.}\PYG{n}{Symbol}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{x}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{n}{fx} \PYG{o}{=} \PYG{p}{(}\PYG{l+m+mi}{1} \PYG{o}{+} \PYG{l+m+mi}{2} \PYG{o}{*} \PYG{n}{x}\PYG{p}{)}\PYG{o}{*}\PYG{o}{*}\PYG{l+m+mi}{5}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Derivative of}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}\PYG{n}{fx}\PYG{p}{,}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{is}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}\PYG{n}{fx}\PYG{o}{.}\PYG{n}{diff}\PYG{p}{(}\PYG{n}{x}\PYG{p}{)}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
Derivative of (2*x + 1)**5 is 10*(2*x + 1)**4
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\sphinxAtStartPar
So if computers can do our maths for us, why learn maths?

\sphinxAtStartPar
The difficulty is
\begin{itemize}
\item {} 
\sphinxAtStartPar
giving them the right inputs and instructions

\item {} 
\sphinxAtStartPar
interpreting what comes out

\end{itemize}

\sphinxAtStartPar
The skills we need are
\begin{itemize}
\item {} 
\sphinxAtStartPar
Understanding of fundamental concepts

\item {} 
\sphinxAtStartPar
Sound deductive reasoning

\end{itemize}

\sphinxAtStartPar
\sphinxstylestrong{These are the focus of the course}


\subsection{Computer Code in the Lectures}
\label{\detokenize{02.optimization_intro:computer-code-in-the-lectures}}
\sphinxAtStartPar
While computation is not a formal part of the course\\
there will be little bits of code in the lectures to illustrate the kinds of things we can do.
\begin{itemize}
\item {} 
\sphinxAtStartPar
All the code will be written in the Python programming language

\item {} 
\sphinxAtStartPar
It is not assessable

\end{itemize}

\sphinxAtStartPar
You might find value in actually running the code shown in lectures\\
If you want to do so please refer to \sphinxstylestrong{linked GitHub repository} in \sphinxhref{https://optim.iskh.me}{optim.iskh.me}


\section{Univariate Optimization}
\label{\detokenize{02.optimization_intro:univariate-optimization}}
\sphinxAtStartPar
Let \(f \colon [a, b] \to \mathbb{R}\) be a differentiable (smooth) function
\begin{itemize}
\item {} 
\sphinxAtStartPar
\([a, b]\) is all \(x\) with \(a \leq x \leq b\)

\item {} 
\sphinxAtStartPar
\(\mathbb{R}\) is “all numbers”

\item {} 
\sphinxAtStartPar
\(f\) takes \(x \in [a, b]\) and returns number \(f(x)\)

\item {} 
\sphinxAtStartPar
derivative \(f'(x)\) exists for all \(x\) with \(a < x < b\)

\end{itemize}

\begin{sphinxadmonition}{note}{Definition}

\sphinxAtStartPar
A  point \(x^* \in [a, b]\) is called a
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleemphasis{\sphinxstylestrong{maximizer}} of \(f\) on \([a, b]\) if \(f(x^*) \geq f(x)\) for all \(x \in [a,b]\)

\item {} 
\sphinxAtStartPar
\sphinxstyleemphasis{\sphinxstylestrong{minimizer}} of \(f\) on \([a, b]\) if \(f(x^*) \leq f(x)\) for all \(x \in [a,b]\)

\end{itemize}
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
Let
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(f(x) = -(x-4)^2 + 10\)

\item {} 
\sphinxAtStartPar
\(a = 2\) and \(b=8\)

\end{itemize}

\sphinxAtStartPar
Then
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(x^* = 4\) is a maximizer of \(f\) on \([2, 8]\)

\item {} 
\sphinxAtStartPar
\(x^{**} = 8\) is a minimizer of \(f\) on \([2, 8]\)

\end{itemize}

\begin{figure}[H]
\centering
\capstart

\noindent\sphinxincludegraphics[width=0.800\linewidth]{{03f255640860aa89576f92c7d8760ce316c0325fbd813956074e5230fa0755ff}.png}
\caption{Maximizer on \([a, b] = [2, 8]\) is \(x^* = 4\)}\label{\detokenize{02.optimization_intro:id1}}\end{figure}

\begin{figure}[H]
\centering
\capstart

\noindent\sphinxincludegraphics[width=0.800\linewidth]{{7a7ba2e2378101f2b281eedf31756eca5d331dc2a4c8578c52ff9485e53e3557}.png}
\caption{Minimizer on \([a, b] = [2, 8]\) is \(x^{**} = 8\)}\label{\detokenize{02.optimization_intro:id2}}\end{figure}
\end{sphinxadmonition}

\sphinxAtStartPar
The set of maximizers/minimizers can be
\begin{itemize}
\item {} 
\sphinxAtStartPar
empty

\item {} 
\sphinxAtStartPar
a singleton (contains one element)

\item {} 
\sphinxAtStartPar
infinite (contains infinitely many elements)

\end{itemize}

\begin{sphinxadmonition}{note}{Example: infinite maximizers}

\sphinxAtStartPar
\(f \colon [0, 1] \to \mathbb{R}\) defined by \(f(x) =1\)\\
has infinitely many maximizers and minimizers on \([0, 1]\)
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Example: no maximizers}

\sphinxAtStartPar
The following function has no maximizers on \([0, 2]\)
\begin{equation*}
\begin{split}
f(x) = 
\begin{cases}
x^2 &  \text{ if } x < 1
\\
1/2 &  \text{ otherwise}
\end{cases}
\end{split}
\end{equation*}
\begin{figure}[H]
\centering
\capstart

\noindent\sphinxincludegraphics[width=0.800\linewidth]{{dc6ae1475886bdbf3870fb56da4b850ca80141076ee12d4c620b333af6eb564d}.png}
\caption{No maximizer on \([0, 2]\)}\label{\detokenize{02.optimization_intro:id3}}\end{figure}
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Definition}

\sphinxAtStartPar
Point  \(x\) is called \sphinxstyleemphasis{\sphinxstylestrong{interior}} to \([a, b]\) if \(a < x < b\)
\end{sphinxadmonition}

\sphinxAtStartPar
The set of all interior points is written \((a, b)\)

\sphinxAtStartPar
We refer to \(x^* \in [a, b]\) as
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleemphasis{\sphinxstylestrong{interior maximizer}} if both a maximizer and interior

\item {} 
\sphinxAtStartPar
\sphinxstyleemphasis{\sphinxstylestrong{interior minimizer}} if both a minimizer and interior

\end{itemize}


\section{Finding optima}
\label{\detokenize{02.optimization_intro:finding-optima}}
\begin{sphinxadmonition}{note}{Definition}

\sphinxAtStartPar
A \sphinxstyleemphasis{\sphinxstylestrong{stationary point}} of \(f\) on \([a, b]\) is an interior point \(x\) with \(f'(x) = 0\)
\end{sphinxadmonition}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=0.800\linewidth]{{stationary}.png}
\caption{Both \(x^*\) and \(x^{**}\) are stationary}\label{\detokenize{02.optimization_intro:id4}}\end{figure}

\begin{sphinxadmonition}{note}{Fact}

\sphinxAtStartPar
If \(f\) is differentiable and \(x^*\) is either an interior minimizer
or an interior maximizer of \(f\) on \([a, b]\), then \(x^*\) is stationary
\end{sphinxadmonition}

\sphinxAtStartPar
Sketch of proof, for maximizers:
\begin{equation*}
\begin{split}
f'(x^*) = \, \lim_{h \to 0} \, \frac{f(x^* + h) - f(x^*)}{h}
\qquad \text{(by def.)}
\end{split}
\end{equation*}\begin{equation*}
\begin{split}
\Rightarrow f(x^* + h) \approx f(x^*) + f'(x^*) h 
\qquad \text{for small } h 
\end{split}
\end{equation*}
\sphinxAtStartPar
If \(f'(x^*) \ne 0\) then exists small \(h\) such that \(f(x^* + h) > f(x^*)\)

\sphinxAtStartPar
Hence interior maximizers must be stationary — otherwise we can do better

\sphinxAtStartPar
\(\Rightarrow\) any interior maximizer stationary\\
\(\Rightarrow\) set of interior maximizers \(\subset\) set of stationary points\\
\(\Rightarrow\) maximizers \(\subset\) stationary points \(\cup \{a\} \cup \{b\}\)

\sphinxAtStartPar
Usage:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
Locate stationary points

\item {} 
\sphinxAtStartPar
Evaluate \(y = f(x)\) for each stationary \(x\) and for \(a\), \(b\)

\item {} 
\sphinxAtStartPar
Pick point giving largest \(y\) value

\end{enumerate}

\sphinxAtStartPar
Minimization: same idea

\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
Let’s solve
\begin{equation*}
\begin{split} 
\max_{-2 \leq x \leq 5} f(x) 
\quad \text{where} \quad
f(x) = x^3 - 6x^2 + 4x + 8
\end{split}
\end{equation*}
\sphinxAtStartPar
Steps
\begin{itemize}
\item {} 
\sphinxAtStartPar
Differentiate to get \(f'(x) = 3x^2 - 12x + 4\)

\item {} 
\sphinxAtStartPar
Solve \(3x^2 - 12x + 4 = 0\) to get stationary \(x\)

\item {} 
\sphinxAtStartPar
Discard any stationary points outside \([-2, 5]\)

\item {} 
\sphinxAtStartPar
Eval \(f\) at remaining points plus end points \(-2\) and \(5\)

\item {} 
\sphinxAtStartPar
Pick point giving largest value

\end{itemize}
\end{sphinxadmonition}

\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{from} \PYG{n+nn}{sympy} \PYG{k+kn}{import} \PYG{o}{*}
\PYG{n}{x} \PYG{o}{=} \PYG{n}{Symbol}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{x}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{n}{points} \PYG{o}{=} \PYG{p}{[}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{2}\PYG{p}{,} \PYG{l+m+mi}{5}\PYG{p}{]}
\PYG{n}{f} \PYG{o}{=} \PYG{n}{x}\PYG{o}{*}\PYG{o}{*}\PYG{l+m+mi}{3} \PYG{o}{\PYGZhy{}} \PYG{l+m+mi}{6}\PYG{o}{*}\PYG{n}{x}\PYG{o}{*}\PYG{o}{*}\PYG{l+m+mi}{2} \PYG{o}{+} \PYG{l+m+mi}{4}\PYG{o}{*}\PYG{n}{x} \PYG{o}{+} \PYG{l+m+mi}{8}
\PYG{n}{fp} \PYG{o}{=} \PYG{n}{diff}\PYG{p}{(}\PYG{n}{f}\PYG{p}{,} \PYG{n}{x}\PYG{p}{)}
\PYG{n}{spoints} \PYG{o}{=} \PYG{n}{solve}\PYG{p}{(}\PYG{n}{fp}\PYG{p}{,} \PYG{n}{x}\PYG{p}{)}
\PYG{n}{points}\PYG{o}{.}\PYG{n}{extend}\PYG{p}{(}\PYG{n}{spoints}\PYG{p}{)}
\PYG{n}{v} \PYG{o}{=} \PYG{p}{[}\PYG{n}{f}\PYG{o}{.}\PYG{n}{subs}\PYG{p}{(}\PYG{n}{x}\PYG{p}{,} \PYG{n}{c}\PYG{p}{)}\PYG{o}{.}\PYG{n}{evalf}\PYG{p}{(}\PYG{p}{)} \PYG{k}{for} \PYG{n}{c} \PYG{o+ow}{in} \PYG{n}{points}\PYG{p}{]}
\PYG{n}{maximizer} \PYG{o}{=} \PYG{n}{points}\PYG{p}{[}\PYG{n}{v}\PYG{o}{.}\PYG{n}{index}\PYG{p}{(}\PYG{n+nb}{max}\PYG{p}{(}\PYG{n}{v}\PYG{p}{)}\PYG{p}{)}\PYG{p}{]}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Maximizer =}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n+nb}{str}\PYG{p}{(}\PYG{n}{maximizer}\PYG{p}{)}\PYG{p}{,}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}\PYG{n}{maximizer}\PYG{o}{.}\PYG{n}{evalf}\PYG{p}{(}\PYG{p}{)}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
Maximizer = 2 \PYGZhy{} 2*sqrt(6)/3 = 0.367006838144548
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}
\begin{sphinxuseclass}{tag_hide-input}\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\noindent{\hspace*{\fill}\sphinxincludegraphics[width=0.800\linewidth]{{a4d14a03565b14b60ee9ecd8272cd378616f877c542a95ebd514d5114e3928d3}.png}\hspace*{\fill}}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\end{sphinxuseclass}

\section{Shape Conditions and Sufficiency}
\label{\detokenize{02.optimization_intro:shape-conditions-and-sufficiency}}
\sphinxAtStartPar
When is \(f'(x^*) = 0\) sufficient for \(x^*\) to be a maximizer?

\sphinxAtStartPar
One answer: When \(f\) is concave

\begin{sphinxuseclass}{cell}
\begin{sphinxuseclass}{tag_hide-input}\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\noindent{\hspace*{\fill}\sphinxincludegraphics[width=0.800\linewidth]{{8d06862c5238701d604531edfbf0b9f77be344ee442dd40ef8cb705c5d9751ed}.png}\hspace*{\fill}}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\end{sphinxuseclass}
\sphinxAtStartPar
(Full definition deferred)

\begin{sphinxadmonition}{note}{Sufficient conditions for \sphinxstyleemphasis{concavity} in one dimension}

\sphinxAtStartPar
Let \(f \colon [a, b] \to \mathbb{R}\)
\begin{itemize}
\item {} 
\sphinxAtStartPar
If \(f''(x) \leq 0\) for all \(x \in (a, b)\) then \(f\) is concave on \((a, b)\)

\item {} 
\sphinxAtStartPar
If \(f''(x) < 0\) for all \(x \in (a, b)\) then \(f\) is \sphinxstylestrong{strictly} concave on \((a, b)\)

\end{itemize}
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Example}
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(f(x) = a + b x\) is concave on \(\mathbb{R}\) but not strictly

\item {} 
\sphinxAtStartPar
\(f(x) = \log(x)\) is strictly concave on \((0, \infty)\)

\end{itemize}
\end{sphinxadmonition}

\sphinxAtStartPar
When is \(f'(x^*) = 0\) sufficient for \(x^*\) to be a minimizer?

\sphinxAtStartPar
One answer: When \(f\) is convex

\begin{sphinxuseclass}{cell}
\begin{sphinxuseclass}{tag_hide-input}\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\noindent{\hspace*{\fill}\sphinxincludegraphics[width=0.800\linewidth]{{0c09b07311ebff7cc9287196f3dcf72f79e958a9e5c6cb035312c18c5cb6d985}.png}\hspace*{\fill}}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\end{sphinxuseclass}
\sphinxAtStartPar
(Full definition deferred)

\begin{sphinxadmonition}{note}{Sufficient conditions for \sphinxstyleemphasis{convexity} in one dimension}

\sphinxAtStartPar
Let \(f \colon [a, b] \to \mathbb{R}\)
\begin{itemize}
\item {} 
\sphinxAtStartPar
If \(f''(x) \geq 0\) for all \(x \in (a, b)\) then \(f\) is convex on \((a, b)\)

\item {} 
\sphinxAtStartPar
If \(f''(x) > 0\) for all \(x \in (a, b)\) then \(f\) is \sphinxstylestrong{strictly}
convex on \((a, b)\)

\end{itemize}
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Example}
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(f(x) = a + b x\) is convex on \(\mathbb{R}\) but not strictly

\item {} 
\sphinxAtStartPar
\(f(x) = x^2\) is strictly convex on \(\mathbb{R}\)

\end{itemize}
\end{sphinxadmonition}


\subsection{Sufficiency and uniqueness with shape conditions}
\label{\detokenize{02.optimization_intro:sufficiency-and-uniqueness-with-shape-conditions}}
\begin{sphinxadmonition}{note}{Fact}

\sphinxAtStartPar
For maximizers:
\begin{itemize}
\item {} 
\sphinxAtStartPar
If \(f \colon [a,b] \to \mathbb{R}\) is concave and \(x^* \in (a, b)\) is
stationary then \(x^*\) is a maximizer

\item {} 
\sphinxAtStartPar
If, in addition, \(f\) is strictly concave, then \(x^*\) is the
unique maximizer

\end{itemize}
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Fact}

\sphinxAtStartPar
For minimizers:
\begin{itemize}
\item {} 
\sphinxAtStartPar
If \(f \colon [a,b] \to \mathbb{R}\) is convex and \(x^* \in (a, b)\) is
stationary then \(x^*\) is a minimizer

\item {} 
\sphinxAtStartPar
If, in addition, \(f\) is strictly convex, then \(x^*\) is the
unique minimizer

\end{itemize}
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
A price taking firm faces output price \(p > 0\), input price \(w >0\)

\sphinxAtStartPar
Maximize profits with respect to input \(\ell\)
\begin{equation*}
\begin{split}
\max_{\ell \ge 0} \pi(\ell) = p f(\ell) - w \ell,
\end{split}
\end{equation*}
\sphinxAtStartPar
where the production technology is given by
\begin{equation*}
\begin{split}
f(\ell) = \ell^{\alpha}, 0 < \alpha < 1.
\end{split}
\end{equation*}\end{sphinxadmonition}

\sphinxAtStartPar
Evidently
\begin{equation*}
\begin{split}
\pi'(\ell) = \alpha p \ell^{\alpha - 1} - w,
\end{split}
\end{equation*}
\sphinxAtStartPar
so unique stationary point is
\begin{equation*}
\begin{split}
\ell^* = (\alpha p/w)^{1/(1 - \alpha)}
\end{split}
\end{equation*}
\sphinxAtStartPar
Moreover,
\begin{equation*}
\begin{split}
\pi''(\ell) = \alpha (\alpha - 1) p \ell^{\alpha - 2} < 0
\end{split}
\end{equation*}
\sphinxAtStartPar
for all \(\ell \ge 0\) so \(\ell^*\) is unique maximizer.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=0.800\linewidth]{{da3e3ad910ccb28a4b672ed661efdfc0367c570aafdfbff4333a1c47f8c4fcd2}.png}
\caption{Profit maximization with \(p=2\), \(w=1\), \(\alpha=0.6\), \(\ell^*=\)\DUrole{output,text_plain}{1.5774}}\label{\detokenize{02.optimization_intro:id5}}\end{figure}


\section{Functions of two variables}
\label{\detokenize{02.optimization_intro:functions-of-two-variables}}
\sphinxAtStartPar
Let’s have a look at some functions of two variables
\begin{itemize}
\item {} 
\sphinxAtStartPar
How to visualize them

\item {} 
\sphinxAtStartPar
Slope, contours, etc.

\end{itemize}

\begin{sphinxadmonition}{note}{Example: Cobb\sphinxhyphen{}Douglas production function}

\sphinxAtStartPar
Consider production function
\begin{equation*}
\begin{split}
f(k, \ell) = k^{\alpha} \ell^{\beta}\\
\alpha \ge 0, \, \beta \ge 0, \, \alpha + \beta < 1
\end{split}
\end{equation*}
\sphinxAtStartPar
Let’s graph it in two dimensions.
\end{sphinxadmonition}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=0.800\linewidth]{{prod2d}.png}
\caption{Production function with \(\alpha=0.4\), \(\beta=0.5\) (a)}\label{\detokenize{02.optimization_intro:id6}}\end{figure}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=0.800\linewidth]{{prod2d_1}.png}
\caption{Production function with \(\alpha=0.4\), \(\beta=0.5\) (b)}\label{\detokenize{02.optimization_intro:id7}}\end{figure}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=0.800\linewidth]{{prod2d_2}.png}
\caption{Production function with \(\alpha=0.4\), \(\beta=0.5\) (c)}\label{\detokenize{02.optimization_intro:id8}}\end{figure}

\sphinxAtStartPar
Like many 3D plots it’s hard to get a good understanding

\sphinxAtStartPar
Let’s try again with contours plus heat map

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=0.800\linewidth]{{prodcontour}.png}
\caption{Production function with \(\alpha=0.4\), \(\beta=0.5\), contours}\label{\detokenize{02.optimization_intro:id9}}\end{figure}

\sphinxAtStartPar
In this context the contour lines are called \sphinxstyleemphasis{\sphinxstylestrong{isoquants}}

\sphinxAtStartPar
Can you see how \(\alpha < \beta\) shows up in the slope of the contours?

\sphinxAtStartPar
We can drop the colours to see the numbers more clearly

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=0.800\linewidth]{{prodcontour2}.png}
\caption{Production function with \(\alpha=0.4\), \(\beta=0.5\)}\label{\detokenize{02.optimization_intro:id10}}\end{figure}

\begin{sphinxadmonition}{note}{Example: log\sphinxhyphen{}utility}

\sphinxAtStartPar
Let \(u(x_1,x_2)\) be “utility” gained from \(x_1\) units of good 1 and \(x_2\) units of good 2

\sphinxAtStartPar
We take
\begin{equation*}
\begin{split}
u(x_1, x_2) = \alpha \log(x_1) + \beta \log(x_2)
\end{split}
\end{equation*}
\sphinxAtStartPar
where
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(\alpha\) and \(\beta\) are parameters

\item {} 
\sphinxAtStartPar
we assume \(\alpha>0, \, \beta > 0\)

\item {} 
\sphinxAtStartPar
The log functions mean “diminishing returns” in each good

\end{itemize}
\end{sphinxadmonition}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=0.800\linewidth]{{log_util}.png}
\caption{Log utility with \(\alpha=0.4\), \(\beta=0.5\)}\label{\detokenize{02.optimization_intro:id11}}\end{figure}

\sphinxAtStartPar
Let’s look at the contour lines

\sphinxAtStartPar
For utility functions, contour lines called \sphinxstyleemphasis{\sphinxstylestrong{indifference curves}}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=0.800\linewidth]{{log_util_contour}.png}
\caption{Indifference curves of log utility with \(\alpha=0.4\), \(\beta=0.5\)}\label{\detokenize{02.optimization_intro:id12}}\end{figure}

\begin{sphinxadmonition}{note}{Example: quasi\sphinxhyphen{}linear utility}
\begin{equation*}
\begin{split}
u(x_1, x_2) = x_1 + \log(x_2)
\end{split}
\end{equation*}\begin{itemize}
\item {} 
\sphinxAtStartPar
Called quasi\sphinxhyphen{}linear because linear in good 1

\end{itemize}
\end{sphinxadmonition}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=0.800\linewidth]{{ql_utility}.png}
\caption{Quasi\sphinxhyphen{}linear utility}\label{\detokenize{02.optimization_intro:id13}}\end{figure}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=0.800\linewidth]{{ql_utility_contour}.png}
\caption{Indifference curves of quasi\sphinxhyphen{}linear utility}\label{\detokenize{02.optimization_intro:id14}}\end{figure}

\begin{sphinxadmonition}{note}{Example: quadratic utility}
\begin{equation*}
\begin{split}
u(x_1, x_2) = - (x_1 - b_1)^2 - (x_2 - b_2)^2
\end{split}
\end{equation*}
\sphinxAtStartPar
Here
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(b_1\) is a “satiation” or “bliss” point for \(x_1\)

\item {} 
\sphinxAtStartPar
\(b_2\) is a “satiation” or “bliss” point for \(x_2\)

\end{itemize}
\end{sphinxadmonition}

\sphinxAtStartPar
Dissatisfaction increases with deviations from the bliss points

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=0.800\linewidth]{{quad_util}.png}
\caption{Quadratic utility with \(b_1 = 3\) and \(b_2 = 2\)}\label{\detokenize{02.optimization_intro:id15}}\end{figure}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=0.800\linewidth]{{quad_util_contour}.png}
\caption{Indifference curves quadratic utility with \(b_1 = 3\) and \(b_2 = 2\)}\label{\detokenize{02.optimization_intro:id16}}\end{figure}


\section{Bivariate Optimization}
\label{\detokenize{02.optimization_intro:bivariate-optimization}}
\sphinxAtStartPar
Consider \(f \colon I \to \mathbb{R}\) where \(I \subset \mathbb{R}^2\)

\sphinxAtStartPar
The set \(\mathbb{R}^2\) is all \((x_1, x_2)\) pairs

\begin{sphinxadmonition}{note}{Definition}

\sphinxAtStartPar
A point \((x_1^*, x_2^*) \in I\) is called a \sphinxstyleemphasis{\sphinxstylestrong{maximizer}} of \(f\) on \(I\) if
\begin{equation*}
\begin{split}
f(x_1^*, x_2^*) \geq f(x_1, x_2) 
\quad \text{for all} \quad
(x_1, x_2) \in I
\end{split}
\end{equation*}\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Definition}

\sphinxAtStartPar
A point \((x_1^*, x_2^*) \in I\) is called a \sphinxstyleemphasis{\sphinxstylestrong{minimizer}} of \(f\) on \(I\) if
\begin{equation*}
\begin{split}
f(x_1^*, x_2^*) \leq f(x_1, x_2) 
\quad \text{for all} \quad
(x_1, x_2) \in I
\end{split}
\end{equation*}\end{sphinxadmonition}

\sphinxAtStartPar
When they exist, the partial derivatives at \((x_1, x_2) \in I\) are
\begin{equation*}
\begin{split}
f_1(x_1, x_2) = \frac{\partial}{\partial x_1} f(x_1, x_2)
\\
f_2(x_1, x_2) = \frac{\partial}{\partial x_2} f(x_1, x_2)
\end{split}
\end{equation*}
\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
When \(f(k, \ell) = k^\alpha \ell^\beta\),
\begin{equation*}
\begin{split}
f_1(k, \ell) 
= \frac{\partial}{\partial k} f(k, \ell)
= \frac{\partial}{\partial k} k^\alpha \ell^\beta
= \alpha k^{\alpha-1} \ell^\beta
\end{split}
\end{equation*}\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Definition}

\sphinxAtStartPar
An interior point \((x_1, x_2) \in I\) is called \sphinxstyleemphasis{\sphinxstylestrong{stationary}} for \(f\) if
\begin{equation*}
\begin{split}
f_1(x_1, x_2) = f_2(x_1, x_2) = 0
\end{split}
\end{equation*}\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Fact}

\sphinxAtStartPar
Let \(f \colon I \to \mathbb{R}\) be a continuously differentiable function.
If \((x_1^*, x_2^*)\) is either
\begin{itemize}
\item {} 
\sphinxAtStartPar
an interior maximizer of \(f\) on \(I\), or

\item {} 
\sphinxAtStartPar
an interior minimizer of \(f\) on \(I\),

\end{itemize}

\sphinxAtStartPar
then \((x_1^*, x_2^*)\) is a stationary point of \(f\)
\end{sphinxadmonition}

\sphinxAtStartPar
Usage, for maximization:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
Compute partials

\item {} 
\sphinxAtStartPar
Set partials to zero to find \(S =\) all stationary points

\item {} 
\sphinxAtStartPar
Evaluate candidates in \(S\) and boundary of \(I\)

\item {} 
\sphinxAtStartPar
Select point \((x^*_1, x_2^*)\) yielding highest value

\end{enumerate}

\begin{sphinxadmonition}{note}{Example}
\begin{equation*}
\begin{split}
f(x_1, x_2) = x_1^2 + 4 x_2^2 \rightarrow \min
\quad \mathrm{s.t.} \quad
x_1 + x_2 \leq 1
\end{split}
\end{equation*}\end{sphinxadmonition}

\sphinxAtStartPar
Setting
\begin{equation*}
\begin{split}
f_1(x_1, x_2) = 2 x_1 = 0 
\quad \text{and} \quad
f_2(x_1, x_2) = 8 x_2 = 0 
\end{split}
\end{equation*}
\sphinxAtStartPar
gives the unique stationary point \((0, 0)\), at which \(f(0, 0) = 0\)

\sphinxAtStartPar
On the boundary we have \(x_1 + x_2 = 1\), so
\begin{equation*}
\begin{split}
f(x_1, x_2) 
= f(x_1, 1 - x_1) 
= x_1^2 + 4 (1 - x_1)^2
\end{split}
\end{equation*}
\sphinxAtStartPar
\sphinxstylestrong{Exercise:} Show right hand side \(> 0\) for any \(x_1\)

\sphinxAtStartPar
Hence minimizer is \((x_1^*, x_2^*) = (0, 0)\)


\subsection{Nasty secrets}
\label{\detokenize{02.optimization_intro:nasty-secrets}}
\sphinxAtStartPar
Solving for \((x_1, x_2)\) such that \(f_1(x_1, x_2) = 0\) and \(f_2(x_1, x_2) = 0\) can be hard
\begin{itemize}
\item {} 
\sphinxAtStartPar
System of nonlinear equations

\item {} 
\sphinxAtStartPar
Might have no analytical solution

\item {} 
\sphinxAtStartPar
Set of solutions can be a continuum

\end{itemize}

\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
(Don’t) try to find all stationary  points of
\begin{equation*}
\begin{split}
f(x_1, x_2) = \frac{\cos(x_1^2 + x_2^2) + x_1^2 + x_1}{2 +
p(-x_1^2) + \sin^2(x_2)}
\end{split}
\end{equation*}\end{sphinxadmonition}

\sphinxAtStartPar
Also:
\begin{itemize}
\item {} 
\sphinxAtStartPar
Boundary is often a continuum, not just two points

\item {} 
\sphinxAtStartPar
Things get even harder in higher dimensions

\end{itemize}

\sphinxAtStartPar
On the other hand:
\begin{itemize}
\item {} 
\sphinxAtStartPar
Most classroom examples are chosen to avoid these problems

\item {} 
\sphinxAtStartPar
Life is still pretty easy if we have concavity / convexity

\item {} 
\sphinxAtStartPar
Clever tricks have been found for certain kinds of problems

\end{itemize}


\section{Second Order Partials}
\label{\detokenize{02.optimization_intro:second-order-partials}}
\sphinxAtStartPar
Let \(f \colon I \to \mathbb{R}\) and, when they exist, denote
\begin{equation*}
\begin{split}
f_{11}(x_1, x_2) 
= \frac{\partial^2}{\partial x_1^2} 
f(x_1, x_2)
\end{split}
\end{equation*}\begin{equation*}
\begin{split}
f_{12}(x_1, x_2) 
= \frac{\partial^2}{\partial x_1 \partial x_2} 
f(x_1, x_2)
\end{split}
\end{equation*}\begin{equation*}
\begin{split}
f_{21}(x_1, x_2) 
= \frac{\partial^2}{\partial x_2 \partial x_1} 
f(x_1, x_2)
\end{split}
\end{equation*}\begin{equation*}
\begin{split}
f_{22}(x_1, x_2) 
= \frac{\partial^2}{\partial x_2^2} 
f(x_1, x_2)
\end{split}
\end{equation*}
\begin{sphinxadmonition}{note}{Example: Cobb\sphinxhyphen{}Douglas technology with linear costs}

\sphinxAtStartPar
If \(\pi(k, \ell) = p k^{\alpha} \ell^{\beta} - w \ell - r k\) then
\begin{equation*}
\begin{split}
\pi_{11}(k, \ell) = p \alpha(\alpha-1) k^{\alpha-2} \ell^{\beta}
\end{split}
\end{equation*}\begin{equation*}
\begin{split}
\pi_{12}(k, \ell) = p \alpha\beta k^{\alpha-1} \ell^{\beta-1}
\end{split}
\end{equation*}\begin{equation*}
\begin{split}
\pi_{21}(k, \ell) = p \alpha\beta k^{\alpha-1} \ell^{\beta-1}
\end{split}
\end{equation*}\begin{equation*}
\begin{split}
\pi_{22}(k, \ell) = p \beta(\beta-1) k^{\alpha} \ell^{\beta-2}
\end{split}
\end{equation*}\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Fact}

\sphinxAtStartPar
If \(f \colon I \to \mathbb{R}\) is twice continuously differentiable at \((x_1, x_2)\), then
\begin{equation*}
\begin{split}
f_{12}(x_1, x_2) = f_{21}(x_1, x_2)
\end{split}
\end{equation*}\end{sphinxadmonition}

\sphinxAtStartPar
\sphinxstylestrong{Exercise:} Confirm the results in the exercise above.


\section{Shape conditions in 2D}
\label{\detokenize{02.optimization_intro:shape-conditions-in-2d}}
\sphinxAtStartPar
Let \(I\) be an “open” set (only interior points – formalities next week)

\sphinxAtStartPar
Let \(f \colon I \to \mathbb{R}\) be twice continuously differentiable

\sphinxAtStartPar
The function \(f\) is strictly \sphinxstylestrong{concave} on \(I\) if, for any \((x_1, x_2) \in I\)
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
\(f_{11}(x_1, x_2) < 0\)

\item {} 
\sphinxAtStartPar
\(f_{11}(x_1, x_2) \, f_{22}(x_1, x_2) >  f_{12}(x_1, x_2)^2\)

\end{enumerate}

\sphinxAtStartPar
The function \(f\) is strictly \sphinxstylestrong{convex} on \(I\) if, for any \((x_1, x_2) \in I\)
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
\(f_{11}(x_1, x_2) > 0\)

\item {} 
\sphinxAtStartPar
\(f_{11}(x_1, x_2) \, f_{22}(x_1, x_2) >  f_{12}(x_1, x_2)^2\)

\end{enumerate}

\sphinxAtStartPar
When is stationarity sufficient?

\begin{sphinxadmonition}{note}{Fact}

\sphinxAtStartPar
If \(f\) is differentiable and strictly concave on \(I\), then any
stationary point of \(f\) is also a unique maximizer of \(f\) on \(I\)
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Fact}

\sphinxAtStartPar
If \(f\) is differentiable and strictly convex on \(I\), then any
stationary point of \(f\) is also a unique minimizer of \(f\) on \(I\)
\end{sphinxadmonition}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=0.800\linewidth]{{concave_max}.png}
\caption{Maximizer of a concave function}\label{\detokenize{02.optimization_intro:id17}}\end{figure}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=0.800\linewidth]{{convex_min}.png}
\caption{Minimizer of a convex function}\label{\detokenize{02.optimization_intro:id18}}\end{figure}

\begin{sphinxadmonition}{note}{Example: unconstrained maximization of quadratic utility}
\begin{equation*}
\begin{split}
u(x_1, x_2) = - (x_1 - b_1)^2 - (x_2 - b_2)^2
\rightarrow \max_{x_1, x_2}
\end{split}
\end{equation*}\end{sphinxadmonition}

\sphinxAtStartPar
Intuitively the solution is \(x_1^*=b_1\) and \(x_2^*=b_2\)

\sphinxAtStartPar
Analysis above leads to the same conclusion

\sphinxAtStartPar
First let’s check first order conditions (\sphinxstyleemphasis{F.O.C.})
\begin{equation*}
\begin{split}
\frac{\partial}{\partial x_1}
u(x_1, x_2) = -2 (x_1 - b_1) = 0
\quad \implies \quad
x_1 = b_1
\end{split}
\end{equation*}\begin{equation*}
\begin{split}
\frac{\partial}{\partial x_2}
u(x_1, x_2) = -2 (x_2 - b_2) = 0
\quad \implies \quad
x_2 = b_2
\end{split}
\end{equation*}
\sphinxAtStartPar
How about (strict) concavity?

\sphinxAtStartPar
Sufficient condition is
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
\(u_{11}(x_1, x_2) < 0\)

\item {} 
\sphinxAtStartPar
\(u_{11}(x_1, x_2)u_{22}(x_1, x_2) > u_{12}(x_1, x_2)^2\)

\end{enumerate}

\sphinxAtStartPar
We have
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(u_{11}(x_1, x_2) = -2\)

\item {} 
\sphinxAtStartPar
\(u_{11}(x_1, x_2)u_{22}(x_1, x_2) = 4 > 0 = u_{12}(x_1, x_2)^2\)

\end{itemize}

\begin{sphinxadmonition}{note}{Example: Profit maximization with two inputs}
\begin{equation*}
\begin{split}
\pi(k, \ell) 
= p k^{\alpha} \ell^{\beta} - w \ell - r k
\rightarrow \max_{k, \ell}
\end{split}
\end{equation*}
\sphinxAtStartPar
where \( \alpha, \beta, p, w\) are all positive and \(\alpha + \beta < 1\)
\end{sphinxadmonition}

\sphinxAtStartPar
Derivatives:
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(\pi_1(k, \ell) = p \alpha k^{\alpha-1} \ell^{\beta} - r\)

\item {} 
\sphinxAtStartPar
\(\pi_2(k, \ell) = p \beta k^{\alpha} \ell^{\beta-1} - w\)

\item {} 
\sphinxAtStartPar
\(\pi_{11}(k, \ell) = p \alpha(\alpha-1) k^{\alpha-2} \ell^{\beta}\)

\item {} 
\sphinxAtStartPar
\(\pi_{22}(k, \ell) = p \beta(\beta-1) k^{\alpha} \ell^{\beta-2}\)

\item {} 
\sphinxAtStartPar
\(\pi_{12}(k, \ell) = p \alpha \beta k^{\alpha-1} \ell^{\beta-1}\)

\end{itemize}

\sphinxAtStartPar
First order conditions: set
\begin{equation*}
\begin{split}
\pi_1(k, \ell) = 0
\\
\pi_2(k, \ell) = 0
\end{split}
\end{equation*}
\sphinxAtStartPar
and solve simultaneously for \(k, \ell\) to get
\begin{equation*}
\begin{split}
k^* =
\left[ 
p (\alpha/r)^{1 - \beta}  (\beta/w)^{\beta}
\right]^{1 / (1 - \alpha - \beta)}
\\
\ell^* =
\left[ 
p (\beta/w)^{1 - \alpha}  (\alpha/r)^{\alpha}
\right]^{1 / (1 - \alpha - \beta)}
\end{split}
\end{equation*}
\sphinxAtStartPar
\sphinxstylestrong{Exercise:} Verify

\sphinxAtStartPar
Now we check second order conditions, hoping for strict concavity

\sphinxAtStartPar
What we need: for any \(k, \ell > 0\)
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
\(\pi_{11}(k, \ell) < 0\)

\item {} 
\sphinxAtStartPar
\(\pi_{11}(k, \ell) \, \pi_{22}(k, \ell) >  \pi_{12}(k, \ell)^2\)

\end{enumerate}

\sphinxAtStartPar
\sphinxstylestrong{Exercise:} Show both inequalities satisfied when \(\alpha + \beta < 1\)

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=0.800\linewidth]{{optprod}.png}
\caption{Profit function when \(p=5\), \(r=w=2\), \(\alpha=0.4\), \(\beta=0.5\)}\label{\detokenize{02.optimization_intro:id19}}\end{figure}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=0.800\linewidth]{{optprod_contour}.png}
\caption{Optimal choice, \(p=5\), \(r=w=2\), \(\alpha=0.4\), \(\beta=0.5\)}\label{\detokenize{02.optimization_intro:id20}}\end{figure}

\sphinxstepscope


\chapter{Elements of set theory}
\label{\detokenize{03.set_theory:elements-of-set-theory}}\label{\detokenize{03.set_theory::doc}}
\sphinxAtStartPar
\sphinxstylestrong{ECON2125/6012 Lecture 3}\\
Fedor Iskhakov


\section{Announcements \& Reminders}
\label{\detokenize{03.set_theory:announcements-reminders}}\begin{itemize}
\item {} 
\sphinxAtStartPar
None

\end{itemize}


\section{Plan for this lecture}
\label{\detokenize{03.set_theory:plan-for-this-lecture}}
\sphinxAtStartPar
We now turn to more formal / foundational ideas
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
Logic and proofs

\item {} 
\sphinxAtStartPar
Sets, operations with sets

\item {} 
\sphinxAtStartPar
Sequences, limits, operations with limits

\item {} 
\sphinxAtStartPar
Functions, properties of functions

\item {} 
\sphinxAtStartPar
Differentiation, Taylor series\\
+

\item {} 
\sphinxAtStartPar
Analysis in \(\mathbb{R}^n\)

\end{enumerate}

\sphinxAtStartPar
Mainly review of key ideas

\sphinxAtStartPar
\sphinxstylestrong{Supplementary reading:}
\begin{itemize}
\item {} 
\sphinxAtStartPar
Simon \& Blume: Appendix A1.1, A1.2, A1.3

\item {} 
\sphinxAtStartPar
Sundaram: Appendix A

\end{itemize}

\begin{sphinxadmonition}{note}{Common symbols}
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(P \implies Q\) means “\(P\) implies \(Q\)”

\item {} 
\sphinxAtStartPar
\(P \iff Q\) means “\(P \implies Q\) and \(Q \implies P\)”

\item {} 
\sphinxAtStartPar
\(\exists\) means “there exists”

\item {} 
\sphinxAtStartPar
\(\forall\) means “for all”

\item {} 
\sphinxAtStartPar
s.t. means “such that”

\item {} 
\sphinxAtStartPar
\(\because\) means “because” (not used very often)

\item {} 
\sphinxAtStartPar
\(\therefore\) means “therefore” (not used very often)

\item {} 
\sphinxAtStartPar
\(a := 1\) means “\(a\) is defined to be equal to 1” (alternatively \(a \equiv 1\) or \(a \stackrel{def.}{=} 1 \))

\item {} 
\sphinxAtStartPar
\(\mathbb{R}\) means all real numbers

\item {} 
\sphinxAtStartPar
\(\mathbb{N}\) means the natural numbers \(\{1, 2, \ldots \}\)

\item {} 
\sphinxAtStartPar
\(\mathbb{Z}\) means integers \(\{\ldots, -2,-1,0,1, 2, \ldots \}\)

\item {} 
\sphinxAtStartPar
\(\mathbb{Q}\) means the rational numbers (ratios of two integers)

\end{itemize}
\end{sphinxadmonition}


\section{Logic}
\label{\detokenize{03.set_theory:logic}}
\sphinxAtStartPar
Let \(P\) and \(Q\) be statements, such as
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(x\) is a negative integer

\item {} 
\sphinxAtStartPar
\(x\) is an odd number

\item {} 
\sphinxAtStartPar
the area of any circle in the plane is \(-2 \pi R\)

\end{itemize}

\begin{sphinxadmonition}{note}{Fact}

\sphinxAtStartPar
\sphinxhref{https://en.wikipedia.org/wiki/Law\_of\_excluded\_middle}{Law of the excluded middle}: Every mathematical statement is either \sphinxcode{\sphinxupquote{true}} or \sphinxcode{\sphinxupquote{false}}
\end{sphinxadmonition}

\sphinxAtStartPar
Statement “\(P \implies Q\)” means “\(P\) implies \(Q\)”

\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
\(k\) is even \(\implies\) \(k = 2n\) for some integer \(n\)
\end{sphinxadmonition}

\sphinxAtStartPar
Equivalent forms of \(P \implies Q\):
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
If \(P\) is true then \(Q\) is true

\item {} 
\sphinxAtStartPar
\(P\) is a \sphinxstyleemphasis{sufficient condition} for \(Q\)

\item {} 
\sphinxAtStartPar
\(Q\) is a necessary condition for \(P\)

\item {} 
\sphinxAtStartPar
If \(Q\) fails then \(P\) fails

\end{enumerate}

\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics[scale=0.3]{{subset}.png}
\end{figure}

\sphinxAtStartPar
Equivalent ways of saying \(P \nRightarrow Q\) (\sphinxstyleemphasis{does not imply}):
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
\(P\) does not imply \(Q\)

\item {} 
\sphinxAtStartPar
\(P\) is not sufficient for \(Q\)

\item {} 
\sphinxAtStartPar
\(Q\) is not necessary for \(P\)

\item {} 
\sphinxAtStartPar
Even if \(Q\) fails, \(P\) can still hold

\end{enumerate}

\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics[scale=0.3]{{notsubset}.png}
\end{figure}

\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
Let
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(P := \) “\(n \in \mathbb{N}\) and even”

\item {} 
\sphinxAtStartPar
\(Q := \) “\(n\) even”

\end{itemize}

\sphinxAtStartPar
Then
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
\(P \implies Q\)

\item {} 
\sphinxAtStartPar
\(P\) is sufficient for \(Q\)

\item {} 
\sphinxAtStartPar
\(Q\) is necessary for \(P\)

\item {} 
\sphinxAtStartPar
If \(Q\) fails then \(P\) fails

\end{enumerate}
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
Let
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(P := \) “\(R\) is a rectangle”

\item {} 
\sphinxAtStartPar
\(Q := \) “\(R\) is a square”

\end{itemize}

\sphinxAtStartPar
Then
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
\(P \not \Rightarrow Q\)

\item {} 
\sphinxAtStartPar
\(P\) is not sufficient for \(Q\)

\item {} 
\sphinxAtStartPar
\(Q\) is not necessary for \(P\)

\item {} 
\sphinxAtStartPar
Just because \(Q\) fails does not mean that \(P\) fails

\end{enumerate}
\end{sphinxadmonition}


\section{Proof by contradiction}
\label{\detokenize{03.set_theory:proof-by-contradiction}}
\sphinxAtStartPar
Suppose we wish to prove a statement such as \(P \implies Q\)
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
A proof by contradiction starts by \sphinxstylestrong{assuming the opposite}: \(P\) holds and yet \(Q\) fails.

\item {} 
\sphinxAtStartPar
We then show that this scenario leads to a contradiction

\end{enumerate}

\begin{sphinxadmonition}{note}{Examples of contradictions}
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(1 < 0\)

\item {} 
\sphinxAtStartPar
\(10\) is an odd number

\end{itemize}
\end{sphinxadmonition}

\sphinxAtStartPar
We then conclude that \(P \implies Q\) is valid after all.

\begin{sphinxadmonition}{note}{Example: proof by contradiction}

\sphinxAtStartPar
Suppose that island X is populated only by pirates and knights:
\begin{itemize}
\item {} 
\sphinxAtStartPar
pirates always lie

\item {} 
\sphinxAtStartPar
knights always tell the truth

\end{itemize}

\sphinxAtStartPar
Claim to prove: If person Y says \sphinxcode{\sphinxupquote{"I'm a pirate"}} then person Y is \sphinxstyleemphasis{\sphinxstylestrong{not}} a native of island X
\end{sphinxadmonition}

\sphinxAtStartPar
Strategy for the \sphinxstylestrong{Proof:}
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
Suppose person Y is a native of the island

\item {} 
\sphinxAtStartPar
Show that this leads to a contradiction

\item {} 
\sphinxAtStartPar
Conclude that Y is not a native of island X, as claimed

\end{enumerate}
\subsubsection*{Proof}

\sphinxAtStartPar
Suppose to the contrary that person Y \sphinxstyleemphasis{\sphinxstylestrong{is}} a native of island X
\begin{itemize}
\item {} 
\sphinxAtStartPar
then Y is either a pirate or a knight

\end{itemize}
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
Suppose first that Y is knight

\end{enumerate}
\begin{itemize}
\item {} 
\sphinxAtStartPar
Y is a knight who claims to be a pirate

\item {} 
\sphinxAtStartPar
This is impossible, since knights always tell the truth

\end{itemize}
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\setcounter{enumi}{1}
\item {} 
\sphinxAtStartPar
Suppose next that Y is pirate

\end{enumerate}
\begin{itemize}
\item {} 
\sphinxAtStartPar
Y is a pirate who claims to be a pirate

\item {} 
\sphinxAtStartPar
Since pirates always lie, they would not make such a statement

\end{itemize}

\sphinxAtStartPar
Either way we get a contradiction \(\implies\) Y is not a native of the island!

\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
There is \sphinxstyleemphasis{\sphinxstylestrong{no}} \(x \in \mathbb{R}\) such that \(0 < x < 1/n\), \(\forall n \in \mathbb{N}\).
\end{sphinxadmonition}
\subsubsection*{Proof}

\sphinxAtStartPar
Suppose to the contrary that such an \(x\) exists

\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics{{no_x}.png}
\end{figure}

\sphinxAtStartPar
Since \(x > 0\) the number \(1/x\) is finite

\sphinxAtStartPar
Let \(k\) be the smallest integer such that \(k \geq 1/x\)
\begin{itemize}
\item {} 
\sphinxAtStartPar
if \(x = 0.3\) then \(1/x = 3.333\cdots\), so set \(k = 4 \in \mathbb{N}\)

\item {} 
\sphinxAtStartPar
if \(x = 0.02\) then \(1/x = 50\cdots\), so set \(k = 50 \in \mathbb{N}\)

\end{itemize}

\sphinxAtStartPar
Since \(k \geq 1/x\) we also have \(1/k \leq x\)

\sphinxAtStartPar
On the other hand, since \(k \in \mathbb{N}\), we have \(x < 1/k\)

\sphinxAtStartPar
But then \(1/k \leq x < 1/k\), and in particular \(1/k < 1/k\), which is impossible — a contradiction!

\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
Let \(n \in \mathbb{N}\). Show that \(n^2\) odd \(\implies\) \(n\) odd
\end{sphinxadmonition}
\subsubsection*{Proof}

\sphinxAtStartPar
Suppose to the contrary that is:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
\(n \in \mathbb{N}\) and \(n^2\) is odd

\item {} 
\sphinxAtStartPar
but \(n\) is even

\end{enumerate}

\sphinxAtStartPar
Then \(n = 2k\) for some \(k \in \mathbb{N}\)

\sphinxAtStartPar
Hence \(n^2 = (2k)^2\)

\sphinxAtStartPar
But then \(n^2 = 2m\) for \(m := 2k^2 \in \mathbb{N}\), and thus \(n^2\) is even!

\sphinxAtStartPar
Contradiction


\section{Sets}
\label{\detokenize{03.set_theory:sets}}
\sphinxAtStartPar
Will often refer to the \sphinxstyleemphasis{\sphinxstylestrong{real numbers}},  \(\mathbb{R}\)

\sphinxAtStartPar
Understand it to contain “all of the numbers” on the “real line”

\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics{{real_line}.png}
\end{figure}

\sphinxAtStartPar
Contains both the rational and the irrational numbers

\sphinxAtStartPar
\(\mathbb{R}\) is an example of a \sphinxstyleemphasis{\sphinxstylestrong{set}}

\sphinxAtStartPar
A set is a collection of objects viewed as a whole

\sphinxAtStartPar
(In case of \(\mathbb{R}\), the objects are numbers)

\sphinxAtStartPar
Other examples of sets:
\begin{itemize}
\item {} 
\sphinxAtStartPar
set of all rectangles in the plane

\item {} 
\sphinxAtStartPar
set of all prime numbers

\item {} 
\sphinxAtStartPar
set of students in the class

\end{itemize}

\sphinxAtStartPar
Notation:
\begin{itemize}
\item {} 
\sphinxAtStartPar
Sets: \(A, B, C\)

\item {} 
\sphinxAtStartPar
Elements: \(x,y,z\)

\end{itemize}

\sphinxAtStartPar
Important sets:
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(\mathbb{N} := \{1, 2, 3, \ldots \}\)

\item {} 
\sphinxAtStartPar
\(\mathbb{Z} := \{\ldots, -2, -1, 0, 1, 2, \ldots \}\)

\item {} 
\sphinxAtStartPar
\(\mathbb{Q} := \{ p/q : p, q \in \mathbb{Z}, \; q \ne 0 \}\)

\item {} 
\sphinxAtStartPar
\(\mathbb{R} := \mathbb{Q} \cup \{ \text{ irrationals } \}\)

\end{itemize}
\phantomsection\label{\detokenize{03.set_theory:ref-set-defition}}
\begin{sphinxadmonition}{note}{Definition of a set}

\sphinxAtStartPar
A set \(A\) can be defined by either
\begin{itemize}
\item {} 
\sphinxAtStartPar
direct enumeration of its elements

\item {} 
\sphinxAtStartPar
defining a formula for infinite number of elements

\item {} 
\sphinxAtStartPar
as a \sphinxstyleemphasis{subset} of already defined set \(B\) and known function \(\psi(x)\)

\end{itemize}
\begin{equation*}
\begin{split}
A = \{ \psi(x), x \in B \colon \text{condition on x}\}
\end{split}
\end{equation*}\end{sphinxadmonition}


\section{Intervals of \protect\(\mathbb{R}\protect\)}
\label{\detokenize{03.set_theory:intervals-of-mathbb-r}}
\sphinxAtStartPar
Common notation:
\begin{equation*}
\begin{split}
(a, b)  := \{ x \in \mathbb{R} : a < x < b \}
\end{split}
\end{equation*}\begin{equation*}
\begin{split}
(a, b]  := \{ x \in \mathbb{R} : a < x \leq b \}
\end{split}
\end{equation*}\begin{equation*}
\begin{split}
[a, b)  := \{ x \in \mathbb{R} : a \leq x < b \}
\end{split}
\end{equation*}\begin{equation*}
\begin{split}
[a, b]  := \{ x \in \mathbb{R} : a \leq x \leq b \}
\end{split}
\end{equation*}\begin{equation*}
\begin{split}
[a, \infty) := \{ x \in \mathbb{R} : a \leq x  \}
\end{split}
\end{equation*}\begin{equation*}
\begin{split}
(-\infty, b) := \{ x \in \mathbb{R} :  x < b  \}
\end{split}
\end{equation*}
\sphinxAtStartPar
Etc.


\section{Operations with sets}
\label{\detokenize{03.set_theory:operations-with-sets}}
\sphinxAtStartPar
Let \(A\) and \(B\) be any sets

\sphinxAtStartPar
Statement \(x \in A\) means that \(x\) is an element of \(A\)

\sphinxAtStartPar
\(A \subset B\) means that any element of \(A\) is also an element of \(B\)

\begin{sphinxadmonition}{note}{Example}
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(\mathbb{N} \subset \mathbb{Z}\)

\item {} 
\sphinxAtStartPar
irrational numbers are a subset of \(\mathbb{R}\)

\end{itemize}
\end{sphinxadmonition}

\sphinxAtStartPar
\sphinxstyleemphasis{\sphinxstylestrong{Equality}} of \(A\) and \(B\)

\sphinxAtStartPar
Let \(S\) be any set and \(A\) and \(B\) be subsets of \(S\)

\sphinxAtStartPar
\(A = B\) means that \(A\) and \(B\) contain the same elements

\sphinxAtStartPar
Equivalently, \(A = B\) \(\iff\) \(A \subset B\) and \(B \subset A\)

\begin{sphinxadmonition}{note}{Definition}

\sphinxAtStartPar
\sphinxstyleemphasis{\sphinxstylestrong{Union}} of \(A\) and \(B\)
\begin{equation*}
\begin{split}
A \cup B := 
\{ x \in S : x \in A \text{ or } x \in B \}
\end{split}
\end{equation*}
\sphinxAtStartPar
\sphinxstyleemphasis{\sphinxstylestrong{Intersection}} of \(A\) and \(B\)
\begin{equation*}
\begin{split}
A \cap B := 
\{ x \in S : x \in A \text{ and } x \in B \}
\end{split}
\end{equation*}
\sphinxAtStartPar
\sphinxstyleemphasis{\sphinxstylestrong{Set theoretic difference}} of \(A\) and \(B\)
\begin{equation*}
\begin{split}
A \setminus B := 
\{ x \in S : x \in A \text{ and } x \notin B \}
\end{split}
\end{equation*}
\sphinxAtStartPar
In other words, all points in \(A\) that are not points in \(B\)
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Example}
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(\mathbb{Z} \setminus \mathbb{N} = \{\ldots, -2, -1, 0\}\)

\item {} 
\sphinxAtStartPar
\(\mathbb{R} \setminus \mathbb{Q} = \) the set of irrational numbers

\item {} 
\sphinxAtStartPar
\(\mathbb{R} \setminus [0, \infty) = (-\infty, 0)\)

\item {} 
\sphinxAtStartPar
\(\mathbb{R} \setminus (a, b) = (-\infty, a] \cup [b, \infty)\)

\end{itemize}
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Definition}

\sphinxAtStartPar
\sphinxstyleemphasis{\sphinxstylestrong{Complement}} of \(A\)

\sphinxAtStartPar
All elements of \(S\) that are not in \(A\):
\begin{equation*}
\begin{split}
A^c := S \setminus A :=: \{ x \in S : x \notin A \}
\end{split}
\end{equation*}\end{sphinxadmonition}

\sphinxAtStartPar
Remarks:
\begin{itemize}
\item {} 
\sphinxAtStartPar
Need to know what \(S\) is before we can determine \(A^c\)

\item {} 
\sphinxAtStartPar
If not clear better write \(S \setminus A\)

\end{itemize}

\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
\((a,\infty)^c\) generally understood to be \((-\infty, a]\)
\end{sphinxadmonition}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{allsets}.png}
\caption{\textbackslash{}label\{f:allsets\} Unions, intersections and complements}\label{\detokenize{03.set_theory:allsets}}\end{figure}


\section{Set operations properties}
\label{\detokenize{03.set_theory:set-operations-properties}}
\sphinxAtStartPar
If \(A\) and \(B\) subsets of \(S\), then
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
\(A \cup B = B \cup A\) and \(A \cap B = B \cap A\)

\end{enumerate}
\begin{itemize}
\item {} 
\sphinxAtStartPar
\((A \cup B)^c = B^c \cap A^c\) and \((A \cap B)^c = B^c \cup A^c\)

\item {} 
\sphinxAtStartPar
\(A \setminus B = A \cap B^c\)

\end{itemize}
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\setcounter{enumi}{8}
\item {} 
\sphinxAtStartPar
\((A^c)^c = A\)

\end{enumerate}

\sphinxAtStartPar
The \sphinxstyleemphasis{\sphinxstylestrong{empty set}} \(\emptyset\) is the set containing no elements

\sphinxAtStartPar
If \(A \cap B = \emptyset\), then \(A\) and \(B\) said to be \sphinxstyleemphasis{\sphinxstylestrong{disjoint}}


\section{Infinite Unions and Intersections}
\label{\detokenize{03.set_theory:infinite-unions-and-intersections}}
\sphinxAtStartPar
Given a family of sets \(K_{\lambda} \subset S\) with \(\lambda \in \Lambda\),
\begin{equation*}
\begin{split}
\bigcap_{\lambda \in \Lambda} K_{\lambda} 
:= \{ x \in S : x\in K_{\lambda}
\textnormal{ for all } \lambda \in \Lambda \}
\end{split}
\end{equation*}\begin{equation*}
\begin{split}
\bigcup_{\lambda \in \Lambda} K_{\lambda}  
:= \{x \in S \colon \textnormal{there
exists an } \lambda \in \Lambda \textnormal{ such that } x\in K_{\lambda} \}
\end{split}
\end{equation*}\begin{itemize}
\item {} 
\sphinxAtStartPar
“there exists” means “there exists \sphinxstyleemphasis{\sphinxstylestrong{at least}} one”

\end{itemize}

\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
Let \(A := \cap_{n \in \mathbb{N}} (0, 1/n)\)

\sphinxAtStartPar
Claim: \(A = \emptyset\)
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Proof}

\sphinxAtStartPar
We need to show that \(A\) contains no elements

\sphinxAtStartPar
Suppose to the contrary that \(x \in A = \cap_{n \in \mathbb{N}} (0, 1/n)\)

\sphinxAtStartPar
Then \(x\) is a number satisfying \(0 < x < 1/n\) for all \(n \in \mathbb{N}\)

\sphinxAtStartPar
No such \(x\) exists as we showed above. Contradiction.
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
For any \(a < b\) we have \(\cup_{\epsilon > 0 } \; [a + \epsilon, b) = (a, b)\)
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Proof}

\sphinxAtStartPar
To show equality of the sets, we show that RHS \(\subset\) LHS and LHS \(\subset\) RHS

\sphinxAtStartPar
Pick any \(a < b\)

\sphinxAtStartPar
Suppose first that \(x \in \cup_{\epsilon > 0 } \; [a + \epsilon, b)\)

\sphinxAtStartPar
This means there exists \(\epsilon > 0\) such that \(a + \epsilon \leq x < b\)

\sphinxAtStartPar
Clearly \(a < x < b\), and hence \(x \in (a, b)\)

\sphinxAtStartPar
Conversely, if \(a < x < b\), then \(\exists \, \epsilon > 0\) s.t. \(a +
\epsilon \leq x < b\)

\sphinxAtStartPar
Hence \(x \in \cup_{\epsilon > 0 } \; [a + \epsilon, b)\)
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Fact: de Morgan’s laws}

\sphinxAtStartPar
Let \(S\) be any set and let \(K_{\lambda} \subset S\) for all \(\lambda \in \Lambda\). Then
\begin{equation*}
\begin{split}
\left[ \bigcup_{\lambda \in \Lambda} K_{\lambda}  \right]^{c}  =
\bigcap_{\lambda \in \Lambda} K_{\lambda}^{c}
\quad \text{and} \quad
\left[ \bigcap_{\lambda \in \Lambda}
K_{\lambda}  \right]^{c}  = \bigcup_{\lambda \in \Lambda} K_{\lambda}^{c}
\end{split}
\end{equation*}\end{sphinxadmonition}

\sphinxAtStartPar
Let’s prove that \(A := \left( \cup_{\lambda \in \Lambda} K_{\lambda}  \right)^{c}
= \cap_{\lambda \in \Lambda} K_{\lambda}^{c} =: B\)

\sphinxAtStartPar
Suffices to show that \(A \subset B\) and \(B \subset A\)

\sphinxAtStartPar
Let’s just do  \(A \subset B\)

\sphinxAtStartPar
Must show that every \(x \in A\) is also in \(B\)

\sphinxAtStartPar
Fix \(x \in A\)

\sphinxAtStartPar
Since \(x \in A\), it must be that \(x\) is not in \(\cup_{\lambda \in \Lambda} K_{\lambda}\)
\begin{equation*}
\begin{split}
\text{therefore } \text{ $x$ is not in any $K_{\lambda}$ }
\end{split}
\end{equation*}\begin{equation*}
\begin{split}
\text{therefore } x \in K_{\lambda}^c \text{ for each } \lambda \in \Lambda
\end{split}
\end{equation*}\begin{equation*}
\begin{split}
\text{therefore } x \in \cap_{\lambda \in \Lambda} K_{\lambda}^{c} =: B
\end{split}
\end{equation*}

\section{Tuples}
\label{\detokenize{03.set_theory:tuples}}
\sphinxAtStartPar
We often organize collections with natural order into “tuples”

\begin{sphinxadmonition}{note}{Definition}

\sphinxAtStartPar
A \sphinxstyleemphasis{\sphinxstylestrong{tuple}} is
\begin{itemize}
\item {} 
\sphinxAtStartPar
a finite ordered sequence of terms

\item {} 
\sphinxAtStartPar
denoted using notation such as \((a_1, a_2)\) or \((x_1, x_2, x_3)\)

\end{itemize}
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
Flip a coin 10 times and let
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(0\) represent tails and \(1\) represent heads

\end{itemize}

\sphinxAtStartPar
Typical outcome \((1, 1, 0, 0, 0, 0, 1, 0, 1, 1)\)

\sphinxAtStartPar
Generic outcome \((b_1, b_2, \ldots, b_{10})\)  for \(b_n \in \{0, 1\}\)
\end{sphinxadmonition}


\section{Cartesian Products}
\label{\detokenize{03.set_theory:cartesian-products}}
\sphinxAtStartPar
We make collections of tuples using Cartesian products

\begin{sphinxadmonition}{note}{Definition}

\sphinxAtStartPar
The \sphinxstyleemphasis{\sphinxstylestrong{Cartesian product}} of \(A_1, \ldots, A_N\) is the set
\begin{equation*}
\begin{split}
A_1 \times \cdots \times A_N
:= \{ (a_1, \ldots, a_N) : a_n \in A_n \text{ for } n =1, \ldots, N \}
\end{split}
\end{equation*}\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Example}
\begin{equation*}
\begin{split}
```[0, 8] \times [0, 1] = \{ (x_1,x_2) : 0 \leq x_1 \leq 8, \, 0 \leq x_2 \leq 1 \}
\end{split}
\end{equation*}\end{sphinxadmonition}

\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics{{cart_prod}.png}
\end{figure}

\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
Set of all outcomes from flip experiment is
\begin{equation*}
\begin{split}
B := \Big\{ (b_1, \ldots, b_{10}) : b_n \in \{0, 1\} \text{ for } n = 1, \ldots, 10 \Big\}
\end{split}
\end{equation*}\begin{equation*}
\begin{split}
= \{0, 1\} \times \cdots \times \{0, 1\} \quad (10 \text{ products})
\end{split}
\end{equation*}\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
The \sphinxstyleemphasis{\sphinxstylestrong{vector space}} \(\mathbb{R}^N\) is the Cartesian product
\begin{equation*}
\begin{split}
\mathbb{R}^N = \mathbb{R} \times \cdots \times \mathbb{R} \quad (N \text{ times})
\end{split}
\end{equation*}\begin{equation*}
\begin{split}
= \{ 
\, \text{all tuples } (x_1, \ldots, x_N) \text{ with } x_n \in \mathbb{R}
\}
\end{split}
\end{equation*}\end{sphinxadmonition}


\section{Counting Finite Sequences}
\label{\detokenize{03.set_theory:counting-finite-sequences}}
\sphinxAtStartPar
Counting methods answer common questions such as
\begin{itemize}
\item {} 
\sphinxAtStartPar
How many arrangements of a sequence?

\item {} 
\sphinxAtStartPar
How many subsets of a set?

\end{itemize}

\sphinxAtStartPar
They also address deeper problems such as
\begin{itemize}
\item {} 
\sphinxAtStartPar
How “large” is a given set?

\item {} 
\sphinxAtStartPar
Can we compare size of sets even when they are infinite?

\end{itemize}

\sphinxAtStartPar
The key rule is: multiply possibilities

\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
Can travel from Sydney to Tokyo in 3 ways and Tokyo to NYC in 8 ways
\(\implies\) can travel from Sydney to NYC in 24 ways
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
Number of 10 letter passwords from the lowercase letters \sphinxcode{\sphinxupquote{a,b,...,z}} is
\$\(
26^{10} = 141,167,095,653,376
\)\$
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
Number of possible distinct outcomes \((i, j)\) from 2 rolls of a dice is
\$\(
6 \times 6 = 36
\)\$
\end{sphinxadmonition}


\section{Counting Cartesian Products}
\label{\detokenize{03.set_theory:counting-cartesian-products}}
\begin{sphinxadmonition}{note}{Fact}

\sphinxAtStartPar
If \(A_n\) are finite for \(n=1, \ldots,N\), then
\begin{equation*}
\begin{split}
\#(A_1 \times \cdots \times A_N) = (\# A_1) \times \cdots \times (\# A_N)
\end{split}
\end{equation*}\end{sphinxadmonition}

\sphinxAtStartPar
That is, number of possible tuples \(=\) product of the number of
possibilities for each element

\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
Number of binary sequences of length \(10\) is
\$\(
\# [\{0, 1\} \times \cdots \times \{0, 1\}]
= 2 \times \cdots \times 2 = 2^{10}
\)\$
\end{sphinxadmonition}

\sphinxAtStartPar
\sphinxstylestrong{Infinite Cartesian Products}

\sphinxAtStartPar
If \(\{A_n\}\) is a collection of sets, one
for each \(n \in \mathbb{N}\), then
\begin{equation*}
\begin{split}
A_1 \times A_2 \times \cdots 
:= \{ (a_1, a_2, \ldots) : a_n \in A_n \text{ for each } n \in \mathbb{N} \}
\end{split}
\end{equation*}
\sphinxAtStartPar
Sometimes denoted \(\times_{n=1}^{\infty} A_n\)

\sphinxAtStartPar
If \(A_n = A\) for all \(n\), then \(\times_{n=1}^{\infty} A\) also written as \(A^{\mathbb{N}}\)

\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
The set of all binary sequences \(\{0, 1\}^{\mathbb{N}}\)
\end{sphinxadmonition}


\section{Functions}
\label{\detokenize{03.set_theory:functions}}
\begin{sphinxadmonition}{note}{Definition}

\sphinxAtStartPar
A \sphinxstyleemphasis{\sphinxstylestrong{function}} \(f \colon A \rightarrow B\) from set \(A\) to set \(B\) is a rule that
associates to each element of \(A\) a uniquely determined element of \(B\)
\end{sphinxadmonition}
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(f \colon A \to B\) means that \(f\) is a function from \(A\) to \(B\)

\end{itemize}

\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics{{function}.png}
\end{figure}

\sphinxAtStartPar
\(A\) is called the \sphinxstyleemphasis{\sphinxstylestrong{domain}} of \(f\) and \(B\) is called the \sphinxstyleemphasis{\sphinxstylestrong{codomain}}

\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
\(f\) defined by
\begin{equation*}
\begin{split}
f(x) = \exp(-x^2)
\end{split}
\end{equation*}
\sphinxAtStartPar
is a function from \(\mathbb{R}\) to \(\mathbb{R}\)

\sphinxAtStartPar
Sometimes we write the whole thing like this
\begin{equation*}
\begin{split}
f \colon \mathbb{R} \to \mathbb{R} \\
x \mapsto \exp(-x^2), \text{ or}\\
f \colon \mathbb{R} \ni x \mapsto \exp(-x^2) \in \mathbb{R} 
\end{split}
\end{equation*}\end{sphinxadmonition}

\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics[scale=0.5]{{allfunctions}.png}
\end{figure}

\sphinxAtStartPar
Lower panel: functions have to map \sphinxstyleemphasis{all} elements in domain to a \sphinxstyleemphasis{uniquely determined} element in codomain.

\begin{sphinxadmonition}{note}{Example: not a function}

\begin{figure}[H]
\centering

\noindent\sphinxincludegraphics[scale=0.8]{{xy_non_func}.png}
\end{figure}
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Definition}

\sphinxAtStartPar
For each \(a \in A\), \(f(a) \in B\) is called the \sphinxstyleemphasis{\sphinxstylestrong{image of \(a\)}} under \(f\)
\end{sphinxadmonition}

\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics[scale=0.8]{{xy_func}.png}
\end{figure}

\sphinxAtStartPar
If \(f(a) = b\) then \(a\) is called a \sphinxstyleemphasis{\sphinxstylestrong{preimage of \(b\)}} under \(f\)

\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics[scale=0.8]{{preimage}.png}
\end{figure}

\sphinxAtStartPar
A point in \(B\) can have one, many or zero preimages

\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics[scale=0.8]{{preimage2}.png}
\end{figure}

\sphinxAtStartPar
The codomain of a function is not uniquely pinned down

\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
Consider the mapping defined by
\$\(f(x) = \exp(-x^2)\)\$

\sphinxAtStartPar
Both of these statements are valid:
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(f\) a function from \(\mathbb{R}\) to \(\mathbb{R}\)

\item {} 
\sphinxAtStartPar
\(f\) a function from \(\mathbb{R}\) to \((0, \infty)\)

\end{itemize}
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Definition}

\sphinxAtStartPar
The smallest possible codomain is called the \sphinxstyleemphasis{\sphinxstylestrong{range}} of \(f \colon A \to B\):
\end{sphinxadmonition}
\begin{equation*}
\begin{split}
\mathrm{rng}(f) := \{ b \in B : f(a) = b \text{ for some } a \in A \} 
\end{split}
\end{equation*}
\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics[scale=0.5]{{range}.png}
\end{figure}

\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
Let \(f \colon [-1, 1] \to \mathbb{R}\) be defined by
\$\(
f(x) =  0.6 \cos(4 x) + 1.4
\)\(
Then \)\textbackslash{}mathrm\{rng\}(f) = {[}0.8, 2.0{]}\$
\end{sphinxadmonition}

\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics{{range2}.png}
\end{figure}

\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
If \( f \colon [0, 1] \to \mathbb{R}\) is defined by
\$\(
f(x) = 2x
\)\(
then \)\textbackslash{}mathrm\{rng\}(f) = {[}0, 2{]}\$
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
If \(f \colon \mathbb{R} \to \mathbb{R}\) is defined by
\$\(
f(x) = \exp(x) 
\)\(
then \)\textbackslash{}mathrm\{rng\}(f) = (0, \textbackslash{}infty)\$
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Proof}

\sphinxAtStartPar
The \sphinxstyleemphasis{\sphinxstylestrong{composition}} of \(f \colon A \to B\) and \(g \colon B \to C\) is the
function \(g \circ f\) from \(A\) to \(C\) defined by
\begin{equation*}
\begin{split}
(g \circ f)(a) = g(f(a)) \quad (a \in A)
\end{split}
\end{equation*}\end{sphinxadmonition}

\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics{{composition}.png}
\end{figure}


\section{Onto Functions (Surjections)}
\label{\detokenize{03.set_theory:onto-functions-surjections}}
\begin{sphinxadmonition}{note}{Definition}

\sphinxAtStartPar
A function \(f \colon A \to B\) is called \sphinxstyleemphasis{\sphinxstylestrong{onto}} (or surjection) if every element of \(B\)
is the image under \(f\) of at least one point in \(A\).
\end{sphinxadmonition}

\sphinxAtStartPar
Equivalently, \(\mathrm{rng}(f) = B\)

\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics[scale=0.5]{{function1}.png}
\end{figure}

\begin{sphinxadmonition}{note}{Fact}

\sphinxAtStartPar
\(f \colon A \to B\) is onto if and only if each element of \(B\)
has at least one preimage under \(f\)
\end{sphinxadmonition}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[scale=0.5]{{bijection3}.png}
\caption{Onto (surjection)}\label{\detokenize{03.set_theory:bijection3}}\end{figure}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[scale=0.5]{{function3}.png}
\caption{Not \sphinxstyleemphasis{onto}!}\label{\detokenize{03.set_theory:function3}}\end{figure}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[scale=0.5]{{bijection2}.png}
\caption{Not \sphinxstyleemphasis{onto}!}\label{\detokenize{03.set_theory:bijection22}}\end{figure}

\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
The function \(f \colon \mathbb{R} \to \mathbb{R}\) defined by
\begin{equation*}
\begin{split}
f(x) = ax^3 + b x^2 + cx + d
\end{split}
\end{equation*}
\sphinxAtStartPar
is onto whenever \(a \ne 0\)
\end{sphinxadmonition}

\sphinxAtStartPar
To see this pick any \(y \in \mathbb{R}\)

\sphinxAtStartPar
We claim \(\exists \; x \in \mathbb{R}\) such that \(f(x) = y\)

\sphinxAtStartPar
Equivalent:
\begin{equation*}
\begin{split}
\exists \; x \in \mathbb{R} \; \mathrm{s.t.} \;
ax^3 + b x^2 + cx + d - y = 0
\end{split}
\end{equation*}
\begin{sphinxadmonition}{note}{Fact}

\sphinxAtStartPar
Every cubic equation with \(a \ne 0\) has at least one real root
\end{sphinxadmonition}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{cubic}.png}
\caption{Cubic functions from \(\mathbb{R}\) to \(\mathbb{R}\) are always onto}\label{\detokenize{03.set_theory:cubic}}\end{figure}


\section{One\sphinxhyphen{}to\sphinxhyphen{}One Functions (Injections)}
\label{\detokenize{03.set_theory:one-to-one-functions-injections}}
\begin{sphinxadmonition}{note}{Definition}

\sphinxAtStartPar
A function \(f \colon A \to B\) is called \sphinxstyleemphasis{\sphinxstylestrong{one\sphinxhyphen{}to\sphinxhyphen{}one}} (or injection) if distinct
elements of \(A\) are always mapped into distinct elements of \(B\).
\end{sphinxadmonition}

\sphinxAtStartPar
That is, \(f\) is one\sphinxhyphen{}to\sphinxhyphen{}one if
\begin{equation*}
\begin{split}
a \in A, \; a' \in A  \text{ and } a \ne a' 
\implies f(a) \ne f(a')
\end{split}
\end{equation*}
\sphinxAtStartPar
Equivalently,
\begin{equation*}
\begin{split}
f(a) = f(a') \implies a = a'
\end{split}
\end{equation*}
\begin{sphinxadmonition}{note}{Fact}

\sphinxAtStartPar
\(f \colon A \to B\) is one\sphinxhyphen{}to\sphinxhyphen{}one if and only if each element of \(B\)
has at most one preimage under \(f\)
\end{sphinxadmonition}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[scale=0.5]{{bijection2}.png}
\caption{One\sphinxhyphen{}to\sphinxhyphen{}one}\label{\detokenize{03.set_theory:bijection2}}\end{figure}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[scale=0.5]{{bijection3}.png}
\caption{One\sphinxhyphen{}to\sphinxhyphen{}one}\label{\detokenize{03.set_theory:bijection3b}}\end{figure}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[scale=0.5]{{bijection1}.png}
\caption{Not one\sphinxhyphen{}to\sphinxhyphen{}one}\label{\detokenize{03.set_theory:bijection1}}\end{figure}


\section{Bijections}
\label{\detokenize{03.set_theory:bijections}}
\begin{sphinxadmonition}{note}{Definition}

\sphinxAtStartPar
A function that is
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
one\sphinxhyphen{}to\sphinxhyphen{}one (injection) and

\item {} 
\sphinxAtStartPar
onto (surjection)

\end{enumerate}

\sphinxAtStartPar
is called a \sphinxstyleemphasis{\sphinxstylestrong{bijection}} or \sphinxstyleemphasis{\sphinxstylestrong{one\sphinxhyphen{}to\sphinxhyphen{}one correspondence}}
\end{sphinxadmonition}

\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics[scale=0.5]{{bijection3}.png}
\end{figure}

\begin{sphinxadmonition}{note}{Fact}

\sphinxAtStartPar
\(f \colon A \to B\) is a bijection if and only if each \(b \in B\) has one and only one preimage in \(A\)
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
\(x \mapsto 2x\) is a bijection from \(\mathbb{R}\) to \(\mathbb{R}\)
\end{sphinxadmonition}

\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics{{x_to_2x}.png}
\end{figure}

\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
\(k \mapsto -k\) is a bijection from \(\mathbb{Z}\) to \(\mathbb{Z}\)
\end{sphinxadmonition}

\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics{{k_to_minus_k}.png}
\end{figure}

\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
\(x \mapsto x^2\) is \sphinxstyleemphasis{\sphinxstylestrong{not}} a bijection from \(\mathbb{R}\) to \(\mathbb{R}
\)
\end{sphinxadmonition}

\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics{{x_squared}.png}
\end{figure}

\begin{sphinxadmonition}{note}{Fact}

\sphinxAtStartPar
If \(f \colon A \to B\) a bijection, then there exists a unique
function \(\phi \colon B \to A\) such that
\begin{equation*}
\begin{split}
\phi(f(a)) = a, \quad \forall \; a \in A
\end{split}
\end{equation*}
\sphinxAtStartPar
That function \(\phi\) is called the \sphinxstyleemphasis{\sphinxstylestrong{inverse}} of \(f\) and written \(f^{-1}\)
\end{sphinxadmonition}

\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics{{bijec}.png}
\end{figure}

\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
Let
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(f \colon \mathbb{R} \to (0, \infty)\) be defined by \(f(x) = \exp(x) :=
e^x\)

\item {} 
\sphinxAtStartPar
\(\phi \colon (0, \infty) \to \mathbb{R}\) be defined by \(\phi(x) = \log(x)\)

\end{itemize}

\sphinxAtStartPar
Then \(\phi = f^{-1}\) because, for any \(a \in \mathbb{R}\),
\begin{equation*}
\begin{split}
\phi(f(a)) = \log(\exp(a)) = a
\end{split}
\end{equation*}\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Fact}

\sphinxAtStartPar
If \(f \colon A \to B\) is one\sphinxhyphen{}to\sphinxhyphen{}one, then \(f \colon A \to \mathrm{rng}(f)\) is a bijection
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Fact}

\sphinxAtStartPar
Let \(f \colon A \to B\) and \(g \colon B \to C\) be bijections
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
\(f^{-1}\) is a bijection and its inverse is \(f\)

\end{enumerate}
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(f^{-1}(f(a)) = a\) for all \(a \in A\)

\item {} 
\sphinxAtStartPar
\(f(f^{-1}(b)) = b\) for all \(b \in B\)

\item {} 
\sphinxAtStartPar
\(g \circ f\) is a bijection from \(A\) to \(C\) and \((g \circ f)^{-1}
= f^{-1} \circ g^{-1}\)
\textbackslash{}end\{enumerate\}

\end{itemize}
\end{sphinxadmonition}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{bij_inv}.png}
\caption{Illustration of \((g \circ f)^{-1} = f^{-1} \circ g^{-1}\)}\label{\detokenize{03.set_theory:bij-inv}}\end{figure}


\section{Cardinality}
\label{\detokenize{03.set_theory:cardinality}}
\sphinxAtStartPar
If a bijection exists between sets \(A\) and \(B\) they are said to have the \sphinxstyleemphasis{\sphinxstylestrong{same cardinality}}, and we write \(|A| = |B|\)

\begin{sphinxadmonition}{note}{Fact}

\sphinxAtStartPar
If \(|A| = |B|\) and \(A\) and \(B\) are finite then \(A\) and \(B\) have the same number of elements (same cardinality).
\end{sphinxadmonition}

\sphinxAtStartPar
\sphinxstylestrong{Exercise:} Convince yourself this is true

\sphinxAtStartPar
Hence “same cardinality” is analogous to “same size”
\begin{itemize}
\item {} 
\sphinxAtStartPar
But cardinality applies to infinite sets as well!

\end{itemize}

\begin{sphinxadmonition}{note}{Fact}

\sphinxAtStartPar
If \(|A| = |B|\) and \(|B| = |C|\) then \(|A| = |C|\)
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Proof}
\begin{itemize}
\item {} 
\sphinxAtStartPar
Since \(|A| = |B|\), there exists a bijection \(f \colon A \to B\)

\item {} 
\sphinxAtStartPar
Since \(|B| = |C|\), there exists a bijection \(g \colon B \to C\)

\end{itemize}

\sphinxAtStartPar
Let \(h := g \circ f\)

\sphinxAtStartPar
Then \(h\) is a bijection from \(A\) to \(C\)

\sphinxAtStartPar
Hence \(|A| = |C|\)
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Definition}

\sphinxAtStartPar
A nonempty set \(A\) is called \sphinxstyleemphasis{\sphinxstylestrong{finite}} if
\$\(
|A| = |\{1, 2, \ldots, n\}|
\quad \text{ for some } \quad
n \in \mathbb{N}
\)\$

\sphinxAtStartPar
Otherwise called \sphinxstyleemphasis{\sphinxstylestrong{infinite}}
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Definition}

\sphinxAtStartPar
Sets that either
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
are finite, or

\item {} 
\sphinxAtStartPar
have the same cardinality as \(\mathbb{N}\)

\end{enumerate}

\sphinxAtStartPar
are called \sphinxstyleemphasis{\sphinxstylestrong{countable}}, denoted \(|A| = \aleph_0\)
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
\(-\mathbb{N} := \{\ldots, -4, -3, -2, -1\}\) is countable
\end{sphinxadmonition}
\begin{equation*}
\begin{split}
\begin{array}{ccc}
-1 & \leftrightarrow & 1 \\
-2 & \leftrightarrow & 2 \\
-3 & \leftrightarrow & 3 \\
& \vdots &  \\
-n & \leftrightarrow & n \\
& \vdots &  
\end{array}
\end{split}
\end{equation*}
\sphinxAtStartPar
Formally: \(f(k) = -k\) is a bijection from \(-\mathbb{N}\) to \(\mathbb{N}\)

\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
\(E := \{2, 4, \ldots\}\) is countable
\end{sphinxadmonition}
\begin{equation*}
\begin{split}
\begin{array}{ccc}
2 & \leftrightarrow & 1 \\
4 & \leftrightarrow & 2 \\
6 & \leftrightarrow & 3 \\
& \vdots &  \\
2n & \leftrightarrow & n \\
& \vdots &  
\end{array}
\end{split}
\end{equation*}
\sphinxAtStartPar
Formally: \(f(k) = k/2\) is a bijection from \(E\) to \(\mathbb{N}\)

\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
\(\{100, 200, 300, \ldots\}\) is countable
\end{sphinxadmonition}
\begin{equation*}
\begin{split}
\begin{array}{ccc}
100 & \leftrightarrow & 1 \\
200 & \leftrightarrow & 2 \\
300 & \leftrightarrow & 3 \\
& \vdots &  \\
100n & \leftrightarrow & n \\
& \vdots &  
\end{array}
\end{split}
\end{equation*}
\begin{sphinxadmonition}{note}{Fact}

\sphinxAtStartPar
Nonempty subsets of countable sets are countable
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Fact}

\sphinxAtStartPar
Finite unions of countable sets are countable
\end{sphinxadmonition}

\sphinxAtStartPar
Sketch of proof, for
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(A\) and \(B\) countable \(\implies A \cup B\) countable

\item {} 
\sphinxAtStartPar
\(A\) and \(B\) are disjoint and infinite

\end{itemize}

\sphinxAtStartPar
By assumption, can write \(A = \{a_1, a_2, \ldots\}\) and \(B = \{b_1, b_2,
\ldots\}\)

\sphinxAtStartPar
Now count it like so:
\begin{equation*}
\begin{split}
\begin{matrix}
a_1 &      & a_2 &      & a_3 &      & a_4 & \cdots\\
\downarrow & \nearrow & \downarrow & \nearrow & \downarrow & \nearrow & \downarrow & \nearrow \\
b_1 &      & b_2 &      & b_3 &      & b_4 & \cdots  
\end{matrix}
\end{split}
\end{equation*}
\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
\(\mathbb{Z} = \{\ldots, -2, -1\} \cup \{ 0 \} \cup \{1, 2, \ldots\}\) is countable
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Fact}

\sphinxAtStartPar
Finite Cartesian products of countable sets is countable
\end{sphinxadmonition}

\sphinxAtStartPar
Sketch of proof, for
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(A\) and \(B\) countable \(\implies A \times B\) countable

\item {} 
\sphinxAtStartPar
\(A\) and \(B\) are disjoint and infinite

\end{itemize}

\sphinxAtStartPar
Now count like so:
\begin{equation*}
\begin{split}
\begin{matrix}
(a_{1},b_{1})&\to &(a_{1},b_{2})&       & (a_{1},b_{3})&\to\cdots\\
&\swarrow&             &\nearrow   &              & \\
(a_{2},b_{1})&    &(a_{2},b_{2})&       &\cdots        & \\
\downarrow   &\nearrow&             &       &              & \\
(a_{3},b_{1})&    &\vdots       &       &              & \\
\vdots       &    &             &       &              & 
\end{matrix}
\end{split}
\end{equation*}
\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
\(\mathbb{Z} \times \mathbb{Z} = \{ (p,q) : p \in \mathbb{Z}, q \in \mathbb{Z} \}\) is countable
\end{sphinxadmonition}

\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics{{lattice}.png}
\end{figure}

\begin{sphinxadmonition}{note}{Fact}

\sphinxAtStartPar
\(\mathbb{Q}\) is countable
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Proof}

\sphinxAtStartPar
By definition
\begin{equation*}
\begin{split}
\mathbb{Q}:= 
\left\{ \, 
\text{all } \frac{p}{q}
\text{ where } p \in \mathbb{Z} \text{ and }  q \in \mathbb{N} \,
\right\}
\end{split}
\end{equation*}
\sphinxAtStartPar
Consider the function \(\phi\) defined by \(\phi(p/q) = (p, q)\)
\begin{itemize}
\item {} 
\sphinxAtStartPar
A one\sphinxhyphen{}to\sphinxhyphen{}one function from \(\mathbb{Q}\) to \(\mathbb{Z} \times \mathbb{N}\)

\item {} 
\sphinxAtStartPar
A bijection from \(\mathbb{Q}\) to \(\mathrm{rng}(\phi)\)

\end{itemize}

\sphinxAtStartPar
Since \(\mathbb{Z} \times \mathbb{N}\) is countable, so is \(\mathrm{rng}(\phi) \subset \mathbb{Z} \times \mathbb{N}\)

\sphinxAtStartPar
Hence \(\mathbb{Q}\) is also countable
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
An example of an \sphinxstyleemphasis{\sphinxstylestrong{uncountable}} set is all binary sequences
\$\(
\{0,1\}^{\mathbb{N}} := \big\{ (b_1,b_2,\ldots) :  \, b_n \in \{0,1\ \} \text{
for each } n \big\}
\)\$
\end{sphinxadmonition}

\sphinxAtStartPar
\sphinxstylestrong{Sketch of proof:} If this set were countable then it could be listed as follows:
\begin{equation*}
\begin{split}
\begin{matrix}
1      & \leftrightarrow & {\bf a_1}, \; a_2, \; a_3, \; a_4, \ldots \\
2      & \leftrightarrow & b_1, \;{\bf b_2}, \; b_3, \; b_4, \ldots \\
3      & \leftrightarrow & c_1, \; c_2, \;{\bf c_3}, \; c_4, \ldots \\
4      & \leftrightarrow & d_1, \; d_2, \; d_3, \;{\bf d_4}, \ldots \\
\vdots &                 & \vdots
\end{matrix}
\end{split}
\end{equation*}
\sphinxAtStartPar
Such a list is never complete: Cantor’s diagonalization argument

\sphinxAtStartPar
Cardinality of  \(\{0,1\}^{\mathbb{N}}\) called the \sphinxstyleemphasis{\sphinxstylestrong{power of the continuum}}

\sphinxAtStartPar
Other sets with the power of the continuum
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(\mathbb{R}\)

\item {} 
\sphinxAtStartPar
\((a, b)\) for any \(a < b\)

\item {} 
\sphinxAtStartPar
\([a, b]\) for any \(a < b\)

\item {} 
\sphinxAtStartPar
\(\mathbb{R}^N\) for any finite \(N \in \mathbb{N}\)

\end{itemize}

\begin{sphinxadmonition}{note}{Continuum hypothesis}

\sphinxAtStartPar
Every nonempty subset of \(\mathbb{R}\) is either
countable or has the power of the continuum
\end{sphinxadmonition}
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxhref{https://en.wikipedia.org/wiki/Continuum\_hypothesis}{Not a homework exercise}!

\end{itemize}

\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
\(\mathbb{R}\) and \((-1, 1)\) have the same cardinality because \(x \mapsto 2\arctan(x)/\pi\) is a bijection from \(\mathbb{R}\) to \((-1, 1)\)
\end{sphinxadmonition}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{arctan}.png}
\caption{Same cardinality}\label{\detokenize{03.set_theory:arctan}}\end{figure}


\section{Extra material}
\label{\detokenize{03.set_theory:extra-material}}
\sphinxAtStartPar
\sphinxstylestrong{Veritasium} video on paradoxes of set theory and mathematical incompleteness \sphinxhref{https://youtu.be/HeQX2HjkcNo}{YouTube}

\sphinxstepscope


\chapter{Basics of real analysis}
\label{\detokenize{04.basic_analysis:basics-of-real-analysis}}\label{\detokenize{04.basic_analysis::doc}}
\sphinxAtStartPar
\sphinxstylestrong{ECON2125/6012 Lecture 4}\\
Fedor Iskhakov


\section{Announcements \& Reminders}
\label{\detokenize{04.basic_analysis:announcements-reminders}}\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
The first test is due before the next lecture!

\end{enumerate}
\begin{itemize}
\item {} 
\sphinxAtStartPar
The test will be published tomorrow (before midnight on Friday)

\item {} 
\sphinxAtStartPar
The test will include multiple choice questions (where multiple options can be correct), True/False questions and open response questions where you may need to upload a file

\item {} 
\sphinxAtStartPar
Please, find the practice test on Wattle and make sure you are comfortable with the setup, including uploading an image/pdf file

\item {} 
\sphinxAtStartPar
Tests are timed: practice paying attention to the countdown timer

\item {} 
\sphinxAtStartPar
The deadline for submission of the first test is \sphinxstyleemphasis{\sphinxstylestrong{midnight on Wednesday, August 23}}

\end{itemize}
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\setcounter{enumi}{1}
\item {} 
\sphinxAtStartPar
I am traveling next week, \sphinxstyleemphasis{\sphinxstylestrong{no face\sphinxhyphen{}to\sphinxhyphen{}face lecture on August 24}}!

\end{enumerate}
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxhref{https://dseconf.org}{DSE summer school and conference}

\end{itemize}


\section{Plan for this lecture}
\label{\detokenize{04.basic_analysis:plan-for-this-lecture}}
\sphinxAtStartPar
Continuing with revision of fundamental concepts and ideas
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
Sequences

\item {} 
\sphinxAtStartPar
Convergence and limits

\item {} 
\sphinxAtStartPar
Differentiation, Taylor series

\item {} 
\sphinxAtStartPar
Analysis in \(\mathbb{R}^n\)

\item {} 
\sphinxAtStartPar
Open and closed sets

\item {} 
\sphinxAtStartPar
Continuity of functions

\end{enumerate}

\sphinxAtStartPar
Mainly review of key ideas

\sphinxAtStartPar
\sphinxstylestrong{Supplementary reading:}
\begin{itemize}
\item {} 
\sphinxAtStartPar
Simon \& Blume: 12.1, 12.2, 12.3, 12.4, 12.5 10.1, 10.2, 10.3, 10.4, 13.4

\item {} 
\sphinxAtStartPar
Sundaram: 1.1.1, 1.1.2, 1.2.1, 1.2.2, 1.2.3, 1.2.7, 1.2.8, 1.4.1

\end{itemize}

\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
Let \(F(x)\) be a profit function, so for solving profit maximization we have to solve \(f(x)=0\) where \(f(x)=F'(x)\).

\sphinxAtStartPar
Or: we want to solve an equation \(g(x) = y\) for \(x\), equivalently
\(f(x) = g(x) - y\)
\end{sphinxadmonition}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{root}.png}
\caption{Existence of a root}\label{\detokenize{04.basic_analysis:root}}\end{figure}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{no_root}.png}
\caption{Non\sphinxhyphen{}existence of a root}\label{\detokenize{04.basic_analysis:no-root}}\end{figure}

\sphinxAtStartPar
One answer: a solution exists under certain conditions including continuity.

\sphinxAtStartPar
Questions:
\begin{itemize}
\item {} 
\sphinxAtStartPar
So how can I tell if \(f\) is continuous?

\item {} 
\sphinxAtStartPar
Can we weaken the continuity assumption?

\item {} 
\sphinxAtStartPar
Does this work in multiple dimensions?

\item {} 
\sphinxAtStartPar
When is the root unique?

\item {} 
\sphinxAtStartPar
How can we compute it?

\end{itemize}

\sphinxAtStartPar
\sphinxstyleemphasis{These are typical problems in analysis}


\section{Bounded sets}
\label{\detokenize{04.basic_analysis:bounded-sets}}
\begin{sphinxadmonition}{note}{Definition}

\sphinxAtStartPar
The \sphinxstyleemphasis{\sphinxstylestrong{absolute value}} of \(x \in \mathbb{R}\) denoted \(|x|\) is \(|x| := \max\{x, -x\}\).
\end{sphinxadmonition}

\begin{sphinxuseclass}{cell}
\begin{sphinxuseclass}{tag_hide-input}\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\noindent{\hspace*{\fill}\sphinxincludegraphics[width=0.800\linewidth]{{c3d49575ab0603d82f067893f6c13ae3c5adb5dc916e018b3a54c762dcbfde84}.png}\hspace*{\fill}}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\end{sphinxuseclass}
\begin{sphinxadmonition}{note}{Fact}

\sphinxAtStartPar
For any \(x, y \in \mathbb{R}\), the following statements hold
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
\(|x| \leq y\) if and only if \(-y \leq x \leq y\)

\item {} 
\sphinxAtStartPar
\(|x| < y\) if and only if \(-y < x < y\)

\item {} 
\sphinxAtStartPar
\(|x| = 0\) if and only if \(x=0\)

\item {} 
\sphinxAtStartPar
\(|xy| = |x| |y|\)

\item {} 
\sphinxAtStartPar
\(|x+y| \leq |x| + |y|\)

\end{enumerate}

\sphinxAtStartPar
Last inequality is called the \sphinxstyleemphasis{\sphinxstylestrong{triangle inequality}}
\end{sphinxadmonition}

\sphinxAtStartPar
Using these rules, let’s show that if \(x, y, z \in \mathbb{R}\), then
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
\(|x-y| \leq |x| + |y|\)

\item {} 
\sphinxAtStartPar
\(|x-y| \leq |x - z| + |z - y|\)

\end{enumerate}

\begin{sphinxadmonition}{note}{Proof}

\sphinxAtStartPar
Hint: \(x-y = x-z+z-y\)
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Definition}

\sphinxAtStartPar
\(A \subset \mathbb{R}\) is called \sphinxstyleemphasis{\sphinxstylestrong{bounded}} if
\(\exists \; M \in \mathbb{R}\) s.t. \(|x| \leq M\), all \(x \in A\)
\end{sphinxadmonition}

\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics{{bounded}.png}
\end{figure}

\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
Every finite subset \(A\) of \(\mathbb{R}\) is bounded
\end{sphinxadmonition}

\sphinxAtStartPar
Set \(M := \max \{  |a| : a \in A \}\)

\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
\(\mathbb{N}\) is unbounded
\end{sphinxadmonition}

\sphinxAtStartPar
For any \(M \in \mathbb{R}\) there is an \(n\) that exceeds it

\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
\((a, b)\) is bounded for any \(a\) and \(b\)
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Proof}

\sphinxAtStartPar
We have to show that each \(x \in (a, b)\) satisfies \(|x| \leq M := \max\{ |a|, |b| \}\)
\begin{equation*}
\begin{split}
x \in (a, b) \iff a < x < b
\end{split}
\end{equation*}
\sphinxAtStartPar
Cases:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
\(0 \le a \le b \implies x > 0, x = |x| < |b| = b = \max\{|a|,|b|\}\)

\item {} 
\sphinxAtStartPar
\(a \le b \le 0 \implies a < x < 0, |x|= -x < -a = |a| = \max\{|a|,|b|\}\)

\item {} 
\sphinxAtStartPar
\(a \le 0 \le b \implies\)

\end{enumerate}
\begin{equation*}
\begin{split}
\begin{cases}
|x|<|b|, x \ge 0\\
|x|<|a|, x < 0
\end{cases}
\implies |x|< \max\{|a|,|b|\} \text{ from 1. and 2.}
\end{split}
\end{equation*}\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Fact}

\sphinxAtStartPar
If \(A\) and \(B\) are bounded sets then so is \(A \cup B\)
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Proof}

\sphinxAtStartPar
Let \(A\) and \(B\) be bounded sets and let \(C := A \cup B\)

\sphinxAtStartPar
By definition, \(\exists \, M_A\) and \(M_B\) with
\begin{equation*}
\begin{split}
|a| \leq M_A, \text{ all } a \in A, 
\quad \quad
|b| \leq M_B, \text{ all } b \in B
\end{split}
\end{equation*}
\sphinxAtStartPar
Let \(M_C := \max\{M_A , M_B\}\) and fix any \(x \in C\)
\begin{equation*}
\begin{split}
x \in C
\implies x \in A \text{ or } x \in B
\end{split}
\end{equation*}\begin{equation*}
\begin{split}
\text{therefore } |x| \leq M_A \quad \text{or} \quad |x| \leq M_B
\end{split}
\end{equation*}\begin{equation*}
\begin{split}
\text{therefore } |x| \leq M_C
\end{split}
\end{equation*}\end{sphinxadmonition}


\section{Epsilon\sphinxhyphen{}balls (\protect\(\epsilon\protect\)\sphinxhyphen{}balls)}
\label{\detokenize{04.basic_analysis:epsilon-balls-epsilon-balls}}
\begin{sphinxadmonition}{note}{Definition}

\sphinxAtStartPar
Given \(\epsilon > 0\) and \(a \in \mathbb{R}\), the \sphinxstyleemphasis{\sphinxstylestrong{\(\epsilon\)\sphinxhyphen{}ball}}
around \(a\) is
\begin{equation*}
\begin{split}
B_{\epsilon}(a) 
:= \{ x \in \mathbb{R} : |a - x| < \epsilon \}
\end{split}
\end{equation*}\end{sphinxadmonition}

\sphinxAtStartPar
Equivalently,
\begin{equation*}
\begin{split}
B_\epsilon(a)
= \{ x \in \mathbb{R} :  a - \epsilon < x < a + \epsilon \}
\end{split}
\end{equation*}
\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics{{eps_ball1D}.png}
\end{figure}

\sphinxAtStartPar
\sphinxstylestrong{Exercise:} Check equivalence

\begin{sphinxadmonition}{note}{Fact}

\sphinxAtStartPar
If \(x\) is in every \(\epsilon\)\sphinxhyphen{}ball around \(a\) then \(x=a\)
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Proof}

\sphinxAtStartPar
Suppose to the contrary that
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(x\) is in every \(\epsilon\)\sphinxhyphen{}ball around \(a\) and yet \(x \ne a\)

\end{itemize}

\sphinxAtStartPar
Since \(x\) is not \(a\) we must have \(|x-a| > 0\)

\sphinxAtStartPar
Set \(\epsilon := |x-a|\)

\sphinxAtStartPar
Since \(\epsilon > 0\), we have \(x \in B_{\epsilon}(a)\)

\sphinxAtStartPar
This means that \(|x-a| < \epsilon\)

\sphinxAtStartPar
That is, \(|x - a| < |x - a|\)

\sphinxAtStartPar
Contradiction!
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Fact}

\sphinxAtStartPar
If \(a \ne b\), then \(\exists \; \epsilon > 0\) such that \(B_{\epsilon}(a)\) and \(B_{\epsilon}(b)\) are disjoint.
\end{sphinxadmonition}

\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics{{disjnt_balls0}.png}
\end{figure}

\begin{sphinxadmonition}{note}{Proof}

\sphinxAtStartPar
Let \(a, b \in \mathbb{R}\) with \(a \ne b\)

\sphinxAtStartPar
If we set \(\epsilon := |a-b|/2\), then \(B_{\epsilon}(a)\) and
\(B_\epsilon(b)\) are disjoint

\sphinxAtStartPar
To see this, suppose to the contrary that \(\exists \, x \in B_{\epsilon}(a) \cap B_\epsilon(B)\)

\sphinxAtStartPar
Then \( |x - a| < |a -b|/2\) and \(|x - b| < |a -b|/2\)

\sphinxAtStartPar
But then
\begin{equation*}
\begin{split}
|a - b| \leq |a - x| + |x - b| < |a -b|/2 + |a -b|/2 = |a-b|
\end{split}
\end{equation*}
\sphinxAtStartPar
Contradiction!
\end{sphinxadmonition}


\section{Sequences}
\label{\detokenize{04.basic_analysis:sequences}}
\begin{sphinxadmonition}{note}{Definition}

\sphinxAtStartPar
A \sphinxstyleemphasis{\sphinxstylestrong{sequence}} is a function from \(\mathbb{N}\) to \(\mathbb{R}\)
\end{sphinxadmonition}

\sphinxAtStartPar
To each \(n \in \mathbb{N}\) we associate one \(x_n \in \mathbb{R}\)

\sphinxAtStartPar
Typically written as \(\{x_n\}_{n=1}^{\infty}\) or \(\{x_n\}\) or \(\{x_1, x_2, x_3, \ldots\}\)

\begin{sphinxadmonition}{note}{Example}
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(\{x_n\} = \{2, 4, 6, \ldots \}\)

\item {} 
\sphinxAtStartPar
\(\{x_n\} = \{1, 1/2, 1/4, \ldots \}\)

\item {} 
\sphinxAtStartPar
\(\{x_n\} = \{1, -1, 1, -1, \ldots \}\)

\item {} 
\sphinxAtStartPar
\(\{x_n\} = \{0, 0, 0, \ldots \}\)

\end{itemize}
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Definition}

\sphinxAtStartPar
Sequence \(\{x_n\}\) is called
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleemphasis{\sphinxstylestrong{bounded}} if \(\{x_1, x_2, \ldots\}\) is a bounded set

\item {} 
\sphinxAtStartPar
\sphinxstyleemphasis{\sphinxstylestrong{monotone increasing}}  if \(x_{n+1} \geq x_n\) for all \(n\)

\item {} 
\sphinxAtStartPar
\sphinxstyleemphasis{\sphinxstylestrong{monotone decreasing}}  if \(x_{n+1} \leq x_n\) for all \(n\)

\item {} 
\sphinxAtStartPar
\sphinxstyleemphasis{\sphinxstylestrong{monotone}}  if it is either monotone increasing or monotone decreasing

\end{itemize}
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Example}
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(x_n = 1/n\) is monotone decreasing, bounded

\item {} 
\sphinxAtStartPar
\(x_n = (-1)^n\) is not monotone but is bounded

\item {} 
\sphinxAtStartPar
\(x_n = 2n\) is monotone increasing but not bounded

\end{itemize}
\end{sphinxadmonition}


\section{Convergence}
\label{\detokenize{04.basic_analysis:convergence}}
\sphinxAtStartPar
Let \(a \in \mathbb{R}\) and let \(\{x_n\}\) be a sequence

\sphinxAtStartPar
Suppose, for any \(\epsilon > 0\), we can find an \(N \in \mathbb{N}\) such that
\begin{equation*}
\begin{split}
x_n \in B_\epsilon(a) \text{ for all } n \geq N
\end{split}
\end{equation*}
\sphinxAtStartPar
Then \(\{x_n\}\) is said to \sphinxstyleemphasis{\sphinxstylestrong{converge}} to \(a\)

\sphinxAtStartPar
Convergence to \(a\) in symbols,
\begin{equation*}
\begin{split}
\forall \, \epsilon > 0, \;
\exists \, N \in \mathbb{N} \; 
\text{ such that } n \geq N \implies x_n \in B_{\epsilon}(a)
\end{split}
\end{equation*}
\sphinxAtStartPar
The sequence \(\{x_n\}\) is eventually in this \(\epsilon\)\sphinxhyphen{}ball around \(a\)

\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics{{convergent_seqs1}.png}
\end{figure}

\sphinxAtStartPar
…and this one

\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics{{convergent_seqs2}.png}
\end{figure}

\sphinxAtStartPar
…and this one

\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics{{convergent_seqs3}.png}
\end{figure}

\sphinxAtStartPar
…and this one

\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics{{convergent_seqs4}.png}
\end{figure}

\begin{sphinxadmonition}{note}{Definition}

\sphinxAtStartPar
The point \(a\) is called the \sphinxstyleemphasis{\sphinxstylestrong{limit}} of the sequence, denoted
\begin{equation*}
\begin{split} 
x_n \to a \text{ as } n \to \infty 
\quad \text{ or } \quad
\lim_{n \to \infty} x_n = a,
\end{split}
\end{equation*}
\sphinxAtStartPar
if
\begin{equation*}
\begin{split}
\forall \, \epsilon > 0, \;
\exists \, N \in \mathbb{N} \; 
\text{ such that } n \geq N \implies x_n \in B_{\epsilon}(a)
\end{split}
\end{equation*}\end{sphinxadmonition}

\sphinxAtStartPar
We call \(\{ x_n \}\) \sphinxstyleemphasis{\sphinxstylestrong{convergent}} if it converges to some limit in
\(\mathbb{R}\)

\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
\(\{x_n\}\) defined by \(x_n = 1 + 1/n\) converges to \(1\):
\begin{equation*}
\begin{split}
x_n \to 1 \; \mathrm{as} \; n \to \infty
\end{split}
\end{equation*}\begin{equation*}
\begin{split}
\lim_{n \to \infty} x_n = 1
\end{split}
\end{equation*}\end{sphinxadmonition}

\sphinxAtStartPar
To prove this must show that \(\forall \, \epsilon > 0\), there is an \(N \in \mathbb{N}\) such that
\begin{equation*}
\begin{split}
n \geq N
\implies
|x_n - 1| < \epsilon
\end{split}
\end{equation*}
\sphinxAtStartPar
To show this formally we need to come up with an  “algorithm”
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
You give me any \(\epsilon > 0\)

\item {} 
\sphinxAtStartPar
I respond with an \(N\) such that equation above holds

\end{enumerate}

\sphinxAtStartPar
In general, as \(\epsilon\) shrinks, \(N\) will have to grow

\begin{sphinxadmonition}{note}{Proof}

\sphinxAtStartPar
Here’s how to do this for the case \(1 + 1/n\) converges to \(1\)

\sphinxAtStartPar
First pick an arbitrary \(\epsilon > 0\)

\sphinxAtStartPar
Now we have to come up with an \(N\) such that
\begin{equation*}
\begin{split}
n \geq N
\implies
|1 + 1/n - 1| < \epsilon
\end{split}
\end{equation*}
\sphinxAtStartPar
Let \(N\) be the first integer greater than \( 1/\epsilon\)

\sphinxAtStartPar
Then
\begin{equation*}
\begin{split}
n \geq N 
\implies n > 1/\epsilon 
\implies 1/n < \epsilon 
\implies |1 + 1/n - 1| < \epsilon 
\end{split}
\end{equation*}
\sphinxAtStartPar
Remark: Any \(N' > N\) would also work
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
The sequence \(x_n = 2^{-n}\) converges to \(0\) as \(n \to \infty\)
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Proof}

\sphinxAtStartPar
Must show that, \(\forall \, \epsilon > 0\), \(\exists \, N \in \mathbb{N}\) such that
\begin{equation*}
\begin{split}
n \geq N
\implies
|2^{-n} - 0| < \epsilon
\end{split}
\end{equation*}
\sphinxAtStartPar
So pick any \(\epsilon > 0\), and observe that
\begin{equation*}
\begin{split}
|2^{-n} - 0| < \epsilon
\; \iff \;
2^{-n}  < \epsilon
\; \iff \;
n > - \frac{\ln \epsilon}{\ln 2}
\end{split}
\end{equation*}
\sphinxAtStartPar
Hence we take \(N\) to be the first integer greater than \(- \ln \epsilon /
\ln 2\)

\sphinxAtStartPar
Then
\begin{equation*}
\begin{split}
n \geq N 
\implies n > -\frac{\ln \epsilon}{\ln 2}
\implies |2^{-n} - 0| < \epsilon
\end{split}
\end{equation*}\end{sphinxadmonition}

\sphinxAtStartPar
What if we want to show that \(x_n \to a\) fails?

\sphinxAtStartPar
To show convergence fails we need to show the \sphinxstyleemphasis{\sphinxstylestrong{negation}}
of
\begin{equation*}
\begin{split}
\forall \,\; \epsilon > 0, \;\; 
\exists \,\; N \in \mathbb{N} \;\mathrm{such\;that}\; n \geq N
\implies x_n \in B_{\epsilon}(a)
\end{split}
\end{equation*}
\sphinxAtStartPar
Negation: there is an \(\epsilon > 0\) where we can’t find any such \(N\)

\sphinxAtStartPar
More specifically, \(\exists \, \epsilon > 0\) such that, which ever \(N \in
\mathbb{N}\) we look at, there’s an \(n \geq N\) with \(x_n\) outside \(B_{\epsilon}(a)\)

\sphinxAtStartPar
One way to say this: there exists a \(B_\epsilon(a)\) such that \(x_n \notin B_\epsilon(a)\) again and again as \(n \to \infty\).

\sphinxAtStartPar
This is the kind of picture we’re thinking of

\begin{sphinxuseclass}{cell}
\begin{sphinxuseclass}{tag_hide-input}\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\noindent{\hspace*{\fill}\sphinxincludegraphics[width=0.800\linewidth]{{5fbbd51f35f701b13d6cb96a1f38df9a8607cf9378ee6a9de22ac366a4b0bc7d}.png}\hspace*{\fill}}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\end{sphinxuseclass}
\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
The sequence \(x_n = (-1)^n\) does \sphinxstyleemphasis{\sphinxstylestrong{not}} converge to any \(a \in \mathbb{R}\)
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Proof}

\sphinxAtStartPar
This is what we want to show
\begin{equation*}
\begin{split}
\exists \,\;  \epsilon > 0 \;\text{ such that } x_n \notin B_{\epsilon}(a) \text{ infinitely many times as } n \to \infty
\end{split}
\end{equation*}
\sphinxAtStartPar
Since it’s a “there exists”, we need to come up with such an \(\epsilon\)

\sphinxAtStartPar
Let’s try \(\epsilon = 0.5\), so that
\begin{equation*}
\begin{split}
B_\epsilon(a) = \{ x \in \mathbb{R} : |x - a| < 0.5 \} = (a-0.5, a+0.5 )
\end{split}
\end{equation*}
\sphinxAtStartPar
We have:
\begin{itemize}
\item {} 
\sphinxAtStartPar
If \(n\) is odd then \(x_n = -1\) when \(n > N\) for \sphinxstyleemphasis{any} \(N\).

\item {} 
\sphinxAtStartPar
If \(n\) is even then \(x_n = 1\) when \(n > N\) for \sphinxstyleemphasis{any} \(N\).

\end{itemize}

\sphinxAtStartPar
Therefore even if \(a=1\) or \(a=-1\), \(\{x_n\}\) not in \(B_\epsilon(a)\) infinitely many times as \(n \to \infty\). It holds for all other values of \(a \in \mathbb{R}\).
\end{sphinxadmonition}


\section{Properties of Limits}
\label{\detokenize{04.basic_analysis:properties-of-limits}}
\begin{sphinxadmonition}{note}{Fact}

\sphinxAtStartPar
Let \(\{x_n\}\) be a sequence in \(\mathbb{R}\) and let \(a \in \mathbb{R}\).
Then as \(n \to \infty\)
\begin{equation*}
\begin{split}
x_n \to a \iff |x_n - a| \to 0
\end{split}
\end{equation*}\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Proof}

\sphinxAtStartPar
Compare the definitions:
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(x_n \to a\) \(\iff\) \(\forall \, \epsilon > 0\), \(\exists \, N \in
\mathbb{N}\) s.t. \(|x_n - a| < \epsilon\)

\item {} 
\sphinxAtStartPar
\(|x_n - a| \to 0\) \(\iff\) \(\forall \, \epsilon > 0\), \(\exists \, N \in
\mathbb{N}\) s.t. \(||x_n - a| - 0| < \epsilon\)

\end{itemize}

\sphinxAtStartPar
Clearly these statements are equivalent
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Fact}

\sphinxAtStartPar
Each sequence in \(\mathbb{R}\) has at most one limit
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Proof}

\sphinxAtStartPar
Suppose instead that \(x_n \to a \text{ and } x_n \to b \text{ with } a \ne b \)

\sphinxAtStartPar
Take disjoint \(\epsilon\)\sphinxhyphen{}balls around \(a\) and \(b\)

\begin{figure}[H]
\centering

\noindent\sphinxincludegraphics{{disjnt_balls0}.png}
\end{figure}

\sphinxAtStartPar
Since \(x_n \to a\) and \(x_n \to b\),
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(\exists \; N_a\) s.t. \(n \geq N_a \implies x_n \in B_{\epsilon}(a)\)

\item {} 
\sphinxAtStartPar
\(\exists \; N_b\) s.t. \(n \geq N_b \implies x_n \in B_{\epsilon}(b)\)

\end{itemize}

\sphinxAtStartPar
But then \(n \geq \max\{N_a, N_b\} \implies \) \(x_n \in B_{\epsilon}(a)\) and \(x_n \in B_{\epsilon}(b)\)

\sphinxAtStartPar
Contradiction, as the balls are assumed disjoint
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Fact}

\sphinxAtStartPar
Every convergent sequence is bounded
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Proof}

\sphinxAtStartPar
Let \(\{x_n\}\) be convergent with \(x_n \to a\)

\sphinxAtStartPar
Fix any \(\epsilon > 0\) and choose \(N\) s.t. \(x_n \in B_{\epsilon}(a)\) when
\(n \geq N\)

\sphinxAtStartPar
Regarded as sets,
\begin{equation*}
\begin{split}
\{x_n\} \subset \{x_1, \ldots, x_{N-1}\} \cup B_{\epsilon}(a)
\end{split}
\end{equation*}
\sphinxAtStartPar
Both of these sets are bounded
\begin{itemize}
\item {} 
\sphinxAtStartPar
First because finite sets are bounded

\item {} 
\sphinxAtStartPar
Second because \(B_{\epsilon}(a)\) is bounded

\end{itemize}

\sphinxAtStartPar
Further, finite unions of bounded sets are bounded
\end{sphinxadmonition}


\section{Operations with limits}
\label{\detokenize{04.basic_analysis:operations-with-limits}}
\sphinxAtStartPar
Here are some basic tools for working with limits

\begin{sphinxadmonition}{note}{Fact}

\sphinxAtStartPar
If \(x_n \to x\) and  \(y_n \to y\), then
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
\(x_n + y_n \to x +  y\)

\item {} 
\sphinxAtStartPar
\(x_n y_n \to x y\)

\item {} 
\sphinxAtStartPar
\(x_n /y_n \to x / y\) when \(y_n\) and \(y\) are \(\ne 0\)

\item {} 
\sphinxAtStartPar
\(x_n \leq y_n\) for all \(n \implies x \leq y\)

\end{enumerate}
\end{sphinxadmonition}

\sphinxAtStartPar
Let’s check that \(x_n \to x\) and \(y_n \to y\) implies \(x_n + y_n \to x +  y\)

\begin{sphinxadmonition}{note}{Proof}

\sphinxAtStartPar
Fix \(\epsilon > 0\)

\sphinxAtStartPar
Need to find \(N \in \mathbb{N}\) such that
\begin{equation*}
\begin{split}
n \geq N 
\; \implies \;
|(x_n + y_n) - (x + y)| < \epsilon
\end{split}
\end{equation*}
\sphinxAtStartPar
Note that
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(|(x_n + y_n) - (x + y)| \leq |x_n - x| + |y_n - y|\) by triangle inequality

\item {} 
\sphinxAtStartPar
\(\exists N_x \in \mathbb{N}\) such that \(n \geq N_x \implies |x_n - x| < \epsilon/2\) by definition of the limit

\item {} 
\sphinxAtStartPar
\(\exists N_y \in \mathbb{N}\) such that \(n \geq N_y \implies |y_n - y| < \epsilon/2\) by definition of the limit as well

\end{itemize}

\sphinxAtStartPar
Take \(N := \max\{N_x, N_y\}\)

\sphinxAtStartPar
Combining the inequalities above concludes the proof.
\end{sphinxadmonition}

\sphinxAtStartPar
Let’s also check the claim that \(x_n \to x\),  \(y_n \to y\)  and
\(x_n \leq y_n\) for all \(n \in \mathbb{N}\) implies \(x \leq y\)

\begin{sphinxadmonition}{note}{Proof}

\sphinxAtStartPar
Suppose instead that \(x > y\)

\sphinxAtStartPar
Take disjoint \(\epsilon\)\sphinxhyphen{}balls \(B_\epsilon(x)\) and \(B_\epsilon(y)\) around
these points

\begin{figure}[H]
\centering

\noindent\sphinxincludegraphics{{disjnt_balls0}.png}
\end{figure}

\sphinxAtStartPar
There exists an \(n\) such that \(x_n \in B_\epsilon(x)\) and \(y_n \in B_\epsilon(y)\)

\sphinxAtStartPar
But then \(x_n > y_n\), a contradiction
\end{sphinxadmonition}

\sphinxAtStartPar
In words: “Weak inequalities are preserved under limits”

\sphinxAtStartPar
Here’s another property of limits, called the “squeeze theorem”

\begin{sphinxadmonition}{note}{Fact}

\sphinxAtStartPar
Let \(\{x_n\}\) \(\{y_n\}\) and \(\{z_n\}\) be sequences in \(\mathbb{R}\). If
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
\(x_n \leq y_n \leq z_n\) for all \(n \in \mathbb{N}\)

\item {} 
\sphinxAtStartPar
\(x_n \to a\) and \(z_n \to a\)

\end{enumerate}

\sphinxAtStartPar
then \(y_n \to a\) also holds
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Proof}

\sphinxAtStartPar
Pick any \(\epsilon > 0\)

\sphinxAtStartPar
We can choose an
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(N_x \in \mathbb{N}\) such that \(n \geq N_x \implies x_n \in B_\epsilon(a)\)

\item {} 
\sphinxAtStartPar
\(N_z \in \mathbb{N}\) such that \(n \geq N_z \implies z_n \in B_\epsilon(a)\)

\end{itemize}

\sphinxAtStartPar
\sphinxstylestrong{Exercise:} Show that \(n \geq \max\{N_x, N_z\} \implies y_n \in B_\epsilon(a)\)
\end{sphinxadmonition}


\section{Infinite Sums}
\label{\detokenize{04.basic_analysis:infinite-sums}}
\begin{sphinxadmonition}{note}{Definition}

\sphinxAtStartPar
Let \(\{x_n\}\) be a sequence in \(\mathbb{R}\)

\sphinxAtStartPar
Then the infinite sum of \(\sum_{n=1}^{\infty} x_n\) is defined by
\begin{equation*}
\begin{split}
\sum_{n=1}^{\infty} x_n := \lim_{k\to \infty} \sum_{n=1}^k x_n  
\end{split}
\end{equation*}\end{sphinxadmonition}

\sphinxAtStartPar
Thus, \(\sum_{n=1}^{\infty} x_n\) is defined as the limit, if it exists,
of \(\{y_k\}\) where
\begin{equation*}
\begin{split}
y_k :=  \sum_{n=1}^k x_n  
\end{split}
\end{equation*}
\sphinxAtStartPar
Other notation:
\begin{equation*}
\begin{split}
\sum_n x_n, 
\quad \sum_{n \geq 1} x_n,
\quad \sum_{n \in \mathbb{N}} x_n,
\quad \text{etc.}
\end{split}
\end{equation*}
\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
If \(x_n = \alpha^n\) for \(\alpha \in (0, 1)\), then
\begin{equation*}
\begin{split}
\sum_{n=1}^{\infty} x_n 
= \lim_{k\to \infty} \sum_{n=1}^k \alpha^n
= \lim_{k\to \infty} \alpha \frac{1 - \alpha^k}{1 - \alpha}
=  \frac{\alpha}{1 - \alpha}
\end{split}
\end{equation*}\end{sphinxadmonition}

\sphinxAtStartPar
\sphinxstyleemphasis{\sphinxstylestrong{Exercise:}} show that \(\sum_{n=1}^k \alpha^n
= \alpha \frac{1 - \alpha^k}{1 - \alpha}\).

\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
If \(x_n = (-1)^n\) the limit fails to exist because
\begin{equation*}
\begin{split}
y_k 
= \sum_{n=1}^k x_n
=
\begin{cases}
0 & \text{if $k$ is even}    
\\
-1 & \text{otherwise}
\end{cases}
\end{split}
\end{equation*}\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Fact}

\sphinxAtStartPar
If \(\{x_n\}\) is nonnegative and \(\sum_n x_n < \infty\), then \(x_n \to 0\)
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Proof}

\sphinxAtStartPar
Suppose to the contrary that \(x_n \to 0\) fails

\sphinxAtStartPar
Then\\
\(\exists \; \epsilon > 0\) and \(N\) such that \(x_n \notin B_\epsilon(0)\) for \(n>N\) infinitely many times as \(n \to \infty\)

\sphinxAtStartPar
Because \(x_n\) is nonnegative, \(x_n \notin B_\epsilon(0) \implies x_n > \epsilon\)

\sphinxAtStartPar
But then \(\sum_{n = N}^{N+k} x_n > k \epsilon \to \infty\) as \(k \to \infty\)

\sphinxAtStartPar
In other words, \(\sum_{n \ge N} x_n\) cannot be finite — contradiction
\end{sphinxadmonition}


\section{Cauchy Sequences}
\label{\detokenize{04.basic_analysis:cauchy-sequences}}
\sphinxAtStartPar
Informal definition: Cauchy sequences are those where \(|x_n - x_{n+1}|\) gets smaller and smaller

\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics{{cauchy}.png}
\end{figure}

\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
Sequences generated by iterative methods for solving nonlinear equations often have this property
\end{sphinxadmonition}

\begin{sphinxuseclass}{cell}
\begin{sphinxuseclass}{tag_hide-input}\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
Newton method
   0:  x =   123.45000000    diff =  41.1477443465
   1:  x =    82.30225565    diff =  27.4306976138
   2:  x =    54.87155804    diff =  18.2854286376
   3:  x =    36.58612940    diff =  12.1877193931
   4:  x =    24.39841001    diff =   8.1212701971
   5:  x =    16.27713981    diff =   5.4083058492
   6:  x =    10.86883396    diff =   3.5965889909
   7:  x =     7.27224497    diff =   2.3839931063
   8:  x =     4.88825187    diff =   1.5680338561
   9:  x =     3.32021801    diff =   1.0119341175
  10:  x =     2.30828389    diff =   0.6219125117
  11:  x =     1.68637138    diff =   0.3347943714
  12:  x =     1.35157701    diff =   0.1251775194
  13:  x =     1.22639949    diff =   0.0188751183
  14:  x =     1.20752437    diff =   0.0004173878
  15:  x =     1.20710698    diff =   0.0000002022
  16:  x =     1.20710678    diff =   0.0000000000
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\end{sphinxuseclass}
\sphinxAtStartPar
Cauchy sequences “look like” they are converging to something

\sphinxAtStartPar
A key \sphinxstyleemphasis{\sphinxstylestrong{axiom}} of analysis is that such sequences do converge to
something — details follow

\begin{sphinxadmonition}{note}{Definition}

\sphinxAtStartPar
A sequence \(\{x_n\}\) is called \sphinxstyleemphasis{\sphinxstylestrong{Cauchy}} if
\(\forall \; \epsilon > 0, \;\; \exists \; N \in \mathbb{N}\) such that
\begin{equation*}
\begin{split}
n \geq N 
\text{ and } \forall j \geq 1 \;\; 
\implies |x_n - x_{n+j}| < \epsilon
\end{split}
\end{equation*}\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
\(\{x_n\}\) defined by \(x_n = \alpha^n\) where \(\alpha \in
(0, 1)\) is Cauchy
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Proof}

\sphinxAtStartPar
For any \(n , j\) we have
\begin{equation*}
\begin{split}
|x_n - x_{n+j}|
= |\alpha^n - \alpha^{n+j}| 
= \alpha^n |1 - \alpha^j|  \leq \alpha^n
\end{split}
\end{equation*}
\sphinxAtStartPar
Fix \(\epsilon > 0\)

\sphinxAtStartPar
We can show that \(n > \log(\epsilon) / \log(\alpha) \implies \alpha^n < \epsilon\)

\sphinxAtStartPar
Hence any integer \(N > \log(\epsilon) / \log(\alpha)\) the sequence is Cauchy by definition.
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Fact}

\sphinxAtStartPar
For any sequence the following equivalence holds: convergent \(\iff\) Cauchy
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Proof}

\sphinxAtStartPar
Proof of \(\implies\):

\sphinxAtStartPar
Let \(\{x_n\}\) be a sequence converging to some \(a \in \mathbb{R}\)

\sphinxAtStartPar
Fix \(\epsilon > 0\)

\sphinxAtStartPar
We can choose \(N\) s.t.
\begin{equation*}
\begin{split}
n \geq N \;\; \implies \;\; |x_n - a | < \frac{\epsilon}{2} 
\end{split}
\end{equation*}
\sphinxAtStartPar
For this \(N\) we have \(n \geq N\) and \(j \geq 1\) implies
\begin{equation*}
\begin{split}
|x_n - x_{n+j}|
\leq |x_n - a| + |x_{n+j} - a|
< \frac{\epsilon}{2} + \frac{\epsilon}{2} = \epsilon
\end{split}
\end{equation*}
\sphinxAtStartPar
Proof of \(\Leftarrow\):

\sphinxAtStartPar
This is basically an \sphinxstyleemphasis{\sphinxstylestrong{axiom}} in the definition of \(\mathbb{R}\)

\sphinxAtStartPar
Either
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
We assume it, or

\item {} 
\sphinxAtStartPar
We assume something else that’s essentially equivalent

\end{enumerate}
\end{sphinxadmonition}

\sphinxAtStartPar
Implications:
\begin{itemize}
\item {} 
\sphinxAtStartPar
There are no “gaps” in the real line

\item {} 
\sphinxAtStartPar
To check \(\{x_n\}\) converges to something we just need to check Cauchy property

\end{itemize}

\begin{sphinxadmonition}{note}{Fact}

\sphinxAtStartPar
Every bounded monotone sequence in \(\mathbb{R}\) is convergent
\end{sphinxadmonition}

\sphinxAtStartPar
Sketch of the proof:

\sphinxAtStartPar
Suffices to show that \(\{x_n\}\) is Cauchy

\sphinxAtStartPar
Suppose not

\sphinxAtStartPar
Then no matter how far we go down the sequence we can find another jump
of size \(\epsilon > 0\)

\sphinxAtStartPar
Since monotone, all the jumps are in the same direction

\sphinxAtStartPar
But then \(\{x_n\}\) not bounded — a contradiction

\sphinxAtStartPar
Full proof: See any text on analysis


\section{Subsequences}
\label{\detokenize{04.basic_analysis:subsequences}}
\begin{sphinxadmonition}{note}{Definition}

\sphinxAtStartPar
A sequence \(\{x_{n_k} \}\) is called a \sphinxstyleemphasis{\sphinxstylestrong{subsequence}} of \(\{x_n\}\) if
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
\(\{x_{n_k} \}\) is a subset of \(\{x_n\}\)

\item {} 
\sphinxAtStartPar
the indices \(n_k\) are strictly increasing

\end{enumerate}
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Example}
\begin{equation*}
\begin{split}
\{x_n\} = \{x_1, x_2, x_3, x_4, x_5, \ldots\} 
\end{split}
\end{equation*}\begin{equation*}
\begin{split}
\{x_{n_k}\} = \{x_2, x_4, x_6, x_8 \ldots\} 
\end{split}
\end{equation*}\end{sphinxadmonition}

\sphinxAtStartPar
In this case
\begin{equation*}
\begin{split}
\{n_k\} = \{n_1, n_2, n_3, \ldots\} = \{2, 4, 6, \ldots\}
\end{split}
\end{equation*}
\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
\(\{\frac{1}{1}, \frac{1}{3}, \frac{1}{5},\ldots\}\) is a
subsequence of \(\{\frac{1}{1}, \frac{1}{2}, \frac{1}{3}, \ldots\}\)

\sphinxAtStartPar
\(\{\frac{1}{1}, \frac{1}{2}, \frac{1}{3},\ldots\}\) is a
subsequence of \(\{\frac{1}{1}, \frac{1}{2}, \frac{1}{3}, \ldots\}\)

\sphinxAtStartPar
\(\{\frac{1}{2}, \frac{1}{2}, \frac{1}{2},\ldots\}\) is \sphinxstyleemphasis{\sphinxstylestrong{not}} a
subsequence of \(\{\frac{1}{1}, \frac{1}{2}, \frac{1}{3}, \ldots\}\)
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Fact}

\sphinxAtStartPar
Every sequence has a monotone subsequence
\end{sphinxadmonition}

\sphinxAtStartPar
Proof omitted

\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
The sequence \(x_n = (-1)^n\) has monotone subsequence
\begin{equation*}
\begin{split}
\{x_2, x_4, x_6, \ldots \}
= \{1, 1, 1, \ldots \}
\end{split}
\end{equation*}\end{sphinxadmonition}

\sphinxAtStartPar
This leads us to the famous \sphinxstyleemphasis{\sphinxstylestrong{Bolzano\sphinxhyphen{}Weierstrass theorem}},
to be used later when we discuss optimization.

\begin{sphinxadmonition}{note}{Fact: Bolzano\sphinxhyphen{}Weierstrass theorem}

\sphinxAtStartPar
Every bounded sequence in \(\mathbb{R}\) has a convergent subsequence
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Proof}

\sphinxAtStartPar
Let \(\{x_n\}\) be a bounded sequence

\sphinxAtStartPar
There exists a monotone subsequence
\begin{itemize}
\item {} 
\sphinxAtStartPar
which is itself a bounded sequence  (why?)

\item {} 
\sphinxAtStartPar
and hence both monotone and bounded

\end{itemize}

\sphinxAtStartPar
Every bounded monotone sequence converges

\sphinxAtStartPar
Hence \(\{x_n\}\) has a convergent subsequence
\end{sphinxadmonition}


\section{Derivatives}
\label{\detokenize{04.basic_analysis:derivatives}}
\begin{sphinxadmonition}{note}{Definition}

\sphinxAtStartPar
Let \(f \colon (a, b) \to \mathbb{R}\) and let \(x \in (a, b)\)

\sphinxAtStartPar
Let \(H\) be all sequences \(\{h_n\}\) such that
\(h_n \ne 0\) and \(h_n \to 0\)

\sphinxAtStartPar
If there exists a constant \(f'(x)\) such that
\begin{equation*}
\begin{split}
\frac{f(x + h_n) - f(x)}{h_n} \to f'(x)
\end{split}
\end{equation*}
\sphinxAtStartPar
for every \(\{h_n\} \in H\), then
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(f\) is said to be \sphinxstyleemphasis{\sphinxstylestrong{differentiable}} at \(x\)

\item {} 
\sphinxAtStartPar
\(f'(x)\) is called the \sphinxstyleemphasis{\sphinxstylestrong{derivative}} of \(f\) at \(x\)

\end{itemize}
\end{sphinxadmonition}

\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics{{derivative}.png}
\end{figure}

\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
Let \(f \colon \mathbb{R} \to \mathbb{R}\) be defined by \(f(x) = x^2\)

\sphinxAtStartPar
Fix any \(x \in \mathbb{R}\) and any \(h_n \to 0\) with \(n \to \infty\)

\sphinxAtStartPar
We have
\begin{equation*}
\begin{split}
\frac{f(x + h_n) - f(x)}{h_n} 
= \frac{(x + h_n)^2 - x^2}{h_n} =
\end{split}
\end{equation*}\begin{equation*}
\begin{split}
= \frac{x^2 + 2xh_n + h_n^2 - x^2}{h_n}
= 2x + h_n
\end{split}
\end{equation*}\begin{equation*}
\begin{split}
\text{therefore }
f'(x)
= \lim_{n \to \infty} (2x + h_n)
= 2x
\end{split}
\end{equation*}\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
Let \(f \colon \mathbb{R} \to \mathbb{R}\) be defined by \(f(x) = |x|\)

\sphinxAtStartPar
This function is not differentiable at \(x=0\)

\sphinxAtStartPar
Indeed, if \(h_n = 1/n\), then
\begin{equation*}
\begin{split}
\frac{f(0 + h_n) - f(0)}{h_n} 
= \frac{|0 + 1/n| - |0|}{1/n} \to 1
\end{split}
\end{equation*}
\sphinxAtStartPar
On the other hand, if \(h_n = -1/n\), then
\begin{equation*}
\begin{split}
\frac{f(0 + h_n) - f(0)}{h_n} 
= \frac{|0 - 1/n| - |0|}{-1/n} \to -1
\end{split}
\end{equation*}\end{sphinxadmonition}


\subsection{Taylor series}
\label{\detokenize{04.basic_analysis:taylor-series}}
\sphinxAtStartPar
Loosely speaking, if \(f \colon \mathbb{R} \to \mathbb{R}\) is suitably
differentiable at \(a\), then
\begin{equation*}
\begin{split}
f(x) \approx f(a) + f'(a)(x-a) 
\end{split}
\end{equation*}
\sphinxAtStartPar
for \(x\) very close to \(a\),
\begin{equation*}
\begin{split}
f(x) \approx f(a) + f'(a)(x-a) + \frac{f''(a)}{2!}(x-a)^2 
\end{split}
\end{equation*}
\sphinxAtStartPar
on a slightly wider interval, etc.

\sphinxAtStartPar
These are the 1st and 2nd order \sphinxstyleemphasis{\sphinxstylestrong{Taylor series approximations}}
to \(f\) at \(a\) respectively

\sphinxAtStartPar
As the order goes higher we get better approximation

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{taylor_4}.png}
\caption{4th order Taylor series for \(f(x) = \sin(x)/x\) at 0}\label{\detokenize{04.basic_analysis:taylor-4}}\end{figure}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{taylor_6}.png}
\caption{6th order Taylor series for \(f(x) = \sin(x)/x\) at 0}\label{\detokenize{04.basic_analysis:taylor-6}}\end{figure}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{taylor_8}.png}
\caption{8th order Taylor series for \(f(x) = \sin(x)/x\) at 0}\label{\detokenize{04.basic_analysis:taylor-8}}\end{figure}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{taylor_10}.png}
\caption{10th order Taylor series for \(f(x) = \sin(x)/x\) at 0}\label{\detokenize{04.basic_analysis:taylor-10}}\end{figure}


\section{Analysis in \protect\(\mathbb{R}^K\protect\)}
\label{\detokenize{04.basic_analysis:analysis-in-mathbb-r-k}}
\sphinxAtStartPar
Now we switch from studying points \(x \in \mathbb{R}\) to vectors
\({\bf x} \in \mathbb{R}^K\)
\begin{itemize}
\item {} 
\sphinxAtStartPar
Replace distance \(|x - y|\) with \(\| {\bf x} - {\bf y} \|\)

\end{itemize}

\sphinxAtStartPar
Many of the same results go through \sphinxstyleemphasis{\sphinxstylestrong{otherwise unchanged}}

\sphinxAtStartPar
We state the analogous results briefly since
\begin{itemize}
\item {} 
\sphinxAtStartPar
You already have the intuition from \(\mathbb{R}\)

\item {} 
\sphinxAtStartPar
Similar arguments, just replacing \(|\cdot|\) with \(\| \cdot \|\)

\end{itemize}

\sphinxAtStartPar
We’ll spend longer on things that are different


\subsection{Norm and distance}
\label{\detokenize{04.basic_analysis:norm-and-distance}}
\begin{sphinxadmonition}{note}{Definition}

\sphinxAtStartPar
The (Euclidean) \sphinxstyleemphasis{\sphinxstylestrong{norm}} of \({\bf x} \in \mathbb{R}^N\) is defined as
\begin{equation*}
\begin{split}
\| {\bf x} \| 
:= \sqrt{{\bf x}' {\bf x} } 
= \left( \sum_{n=1}^N x_n^2 \right)^{1/2}
\end{split}
\end{equation*}\end{sphinxadmonition}

\sphinxAtStartPar
Interpretation:
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(\| {\bf x} \|\) represents the \sphinxstyleemphasis{length} of \({\bf x}\)

\item {} 
\sphinxAtStartPar
\(\| {\bf x} - {\bf y} \|\) represents distance between \({\bf x}\) and \({\bf y}\)

\end{itemize}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{vec}.png}
\caption{Length of red line \(= \sqrt{x_1^2 + x_2^2} =: \|{\bf x}\|\)}\label{\detokenize{04.basic_analysis:vec}}\end{figure}

\sphinxAtStartPar
\(\| {\bf x} - {\bf y} \|\) represents distance between \({\bf x}\) and \({\bf y}\)

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{vec_minus}.png}
\caption{Length of red line \(= \|{\bf x} - {\bf y}\|\)}\label{\detokenize{04.basic_analysis:vec-minus}}\end{figure}

\begin{sphinxadmonition}{note}{Fact}

\sphinxAtStartPar
For any \(\alpha \in \mathbb{R}\) and any \({\bf x}, {\bf y} \in \mathbb{R}^N\), the following statements are true:
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(\| {\bf x} \| \geq 0\) and \(\| {\bf x} \| = 0\) if and only if
\({\bf x} = {\bf 0}\)

\item {} 
\sphinxAtStartPar
\(\| \alpha {\bf x} \| = |\alpha| \| {\bf x} \|\)

\item {} 
\sphinxAtStartPar
\(\| {\bf x} + {\bf y} \| \leq  \| {\bf x} \| + \| {\bf y} \|\)
(\sphinxstyleemphasis{\sphinxstylestrong{triangle inequality}})

\item {} 
\sphinxAtStartPar
\(| {\bf x}' {\bf y} | \leq  \| {\bf x} \| \| {\bf y} \|\)
(\sphinxstyleemphasis{\sphinxstylestrong{Cauchy\sphinxhyphen{}Schwarz inequality}})

\end{itemize}
\end{sphinxadmonition}

\sphinxAtStartPar
For example, let’s show that \(\| {\bf x} \| = 0 \iff {\bf x} = {\bf 0}\)

\sphinxAtStartPar
First let’s assume that \(\| {\bf x} \| = 0\) and show \({\bf x} = {\bf 0}\)

\sphinxAtStartPar
Since \(\| {\bf x} \| = 0\) we have \(\| {\bf x} \|^2 = 0\) and hence
\(\sum_{n=1}^N x^2_n = 0\)

\sphinxAtStartPar
That is \(x_n = 0\) for all \(n\), or, equivalently, \({\bf x} = {\bf 0}\)

\sphinxAtStartPar
Next let’s assume that \({\bf x} = {\bf 0}\) and show \(\| {\bf x} \| = 0\)

\sphinxAtStartPar
This is immediate from the definition of the norm


\subsection{Bounded sets and \protect\(\epsilon\protect\)\sphinxhyphen{}balls}
\label{\detokenize{04.basic_analysis:bounded-sets-and-epsilon-balls}}
\begin{sphinxadmonition}{note}{Definition}

\sphinxAtStartPar
A set \(A \subset \mathbb{R}^K\) called \sphinxstyleemphasis{\sphinxstylestrong{bounded}} if
\begin{equation*}
\begin{split}
\exists \, M \in \mathbb{R} 
\; \mathrm{such\;that} \;
\|{\bf x}\| \leq M, \quad \forall \; {\bf x} \in A
\end{split}
\end{equation*}\end{sphinxadmonition}

\sphinxAtStartPar
Remarks:
\begin{itemize}
\item {} 
\sphinxAtStartPar
A \sphinxstyleemphasis{\sphinxstylestrong{generalization}} of the scalar definition

\item {} 
\sphinxAtStartPar
When \(K=1\), the norm \(\| \cdot \|\) reduces to \(|\cdot|\)

\end{itemize}

\begin{sphinxadmonition}{note}{Fact}

\sphinxAtStartPar
If \(A\) and \(B\) are bounded sets then so is \(C := A \cup B\)
\end{sphinxadmonition}

\sphinxAtStartPar
\sphinxstylestrong{Proof:}  Same as the scalar case — just replace \(|\cdot|\) with \(\| \cdot \|\)

\sphinxAtStartPar
\sphinxstylestrong{Exercise:} Check it

\begin{sphinxadmonition}{note}{Definition}

\sphinxAtStartPar
For \(\epsilon > 0\), the \(\epsilon\)\sphinxhyphen{}ball \(B_{\epsilon}({\bf a})\) around
\({\bf a} \in \mathbb{R}^K\) is all \({\bf x} \in \mathbb{R}^K\) such that \(\|{\bf a} - {\bf x}\|
< \epsilon\)
\end{sphinxadmonition}

\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics[scale=0.8]{{eps_ball2D}.png}
\end{figure}

\begin{sphinxadmonition}{note}{Fact}

\sphinxAtStartPar
If \({\bf x}\) is in every \(\epsilon\)\sphinxhyphen{}ball around \({\bf a}\) then
\({\bf x}={\bf a}\)
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Fact}

\sphinxAtStartPar
If \({\bf a} \ne {\bf b}\), then \(\exists \, \epsilon > 0\) such that
\(B_\epsilon({\bf a}) \cap B_\epsilon({\bf b}) = \emptyset\)
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Definition}

\sphinxAtStartPar
A \sphinxstyleemphasis{\sphinxstylestrong{sequence}} \(\{{\bf x}_n\}\) in \(\mathbb{R}^K\) is a function from \(\mathbb{N}\) to \(\mathbb{R}^K\)
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Definition}

\sphinxAtStartPar
Sequence \(\{{\bf x}_n\}\) is said to \sphinxstyleemphasis{\sphinxstylestrong{converge}} to \({\bf a} \in \mathbb{R}^K\) if
\begin{equation*}
\begin{split}
\forall \epsilon > 0, 
\;
\exists \, N \in \mathbb{N}
\; 
\text{ such that }  n \geq N \implies {\bf x}_n \in B_{\epsilon}({\bf a})
\end{split}
\end{equation*}\end{sphinxadmonition}

\sphinxAtStartPar
We say: “\(\{{\bf x}_n\}\) is eventually in any \(\epsilon\)\sphinxhyphen{}neighborhood of \({\bf a}\)”

\sphinxAtStartPar
In this case \({\bf a}\) is called the \sphinxstyleemphasis{\sphinxstylestrong{limit}} of the sequence, and we write
\begin{equation*}
\begin{split} 
{\bf x}_n \to {\bf a} \; \text{ as } \; n \to \infty
\quad \text{or} \quad
\lim_{n \to \infty} {\bf x}_n = {\bf a}
\end{split}
\end{equation*}
\begin{sphinxadmonition}{note}{Definition}

\sphinxAtStartPar
We call \(\{ {\bf x}_n \}\) \sphinxstyleemphasis{\sphinxstylestrong{convergent}} if it converges to some limit in \(\mathbb{R}^K\)
\end{sphinxadmonition}

\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics[scale=0.8]{{convergence}.png}
\end{figure}

\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics[scale=0.8]{{convergence2}.png}
\end{figure}

\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics[scale=0.8]{{convergence3}.png}
\end{figure}


\subsection{Vector vs Componentwise Convergence}
\label{\detokenize{04.basic_analysis:vector-vs-componentwise-convergence}}
\begin{sphinxadmonition}{note}{Fact}

\sphinxAtStartPar
A sequence \(\{{\bf x}_n\}\) in \(\mathbb{R}^K\) converges to \({\bf a} \in \mathbb{R}^K\)
if and only if each component sequence converges in \(\mathbb{R}\)

\sphinxAtStartPar
That is,
\begin{equation*}
\begin{split}
\begin{pmatrix}
x^1_n \\
\vdots \\
x^K_n 
\end{pmatrix}
\to
\begin{pmatrix}
a^1 \\
\vdots \\
a^K 
\end{pmatrix}
\quad \text{in } \mathbb{R}^K
\quad \iff \quad
\begin{array}{cc}
x^1_n \to a^1 &  \quad \text{in } \mathbb{R} \\
\vdots        &  \\
x^K_n \to a^K &  \quad \text{in } \mathbb{R} 
\end{array}
\end{split}
\end{equation*}
\sphinxAtStartPar
\$\$
\end{sphinxadmonition}

\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics{{norm_and_pointwise}.png}
\end{figure}


\section{From Scalar to Vector Analysis}
\label{\detokenize{04.basic_analysis:from-scalar-to-vector-analysis}}
\sphinxAtStartPar
More definitions analogous to scalar case:

\begin{sphinxadmonition}{note}{Definition}

\sphinxAtStartPar
A sequence \(\{{\bf x}_n\}\) is called \sphinxstyleemphasis{\sphinxstylestrong{Cauchy}} if
\begin{equation*}
\begin{split}
\forall \; \epsilon > 0, \;\; \exists \; N \in \mathbb{N} 
\; \mathrm{such\;that}\;  n, m \geq N \implies \| {\bf x}_n - {\bf x}_m \| < \epsilon
\end{split}
\end{equation*}\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Definition}

\sphinxAtStartPar
A sequence \(\{{\bf x}_{n_k} \}\) is called a \sphinxstyleemphasis{\sphinxstylestrong{subsequence}} of \(\{{\bf x}_n\}\) if
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
\(\{{\bf x}_{n_k} \}\) is a subset of \(\{{\bf x}_n\}\)

\item {} 
\sphinxAtStartPar
the indices \(n_k\) are strictly increasing

\end{enumerate}
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Fact}

\sphinxAtStartPar
Analogous to the scalar case,
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
\({\bf x}_n \to {\bf a}\) in \(\mathbb{R}^K\) if and only if \(\|{\bf x}_n -
{\bf a}\| \to 0\) in \(\mathbb{R}\)

\item {} 
\sphinxAtStartPar
If \({\bf x}_n \to {\bf x}\) and \({\bf y}_n \to {\bf y}\) then \({\bf x}_n +
{\bf y}_n \to {\bf x} +  {\bf y}\)

\item {} 
\sphinxAtStartPar
If \({\bf x}_n \to {\bf x}\) and \(\alpha \in \mathbb{R}\) then \(\alpha {\bf x}_n 
\to \alpha {\bf x}\)

\item {} 
\sphinxAtStartPar
If \({\bf x}_n \to {\bf x}\) and \({\bf z} \in \mathbb{R}^K\) then \({\bf z}' {\bf x}_n 
\to {\bf z}' {\bf x}\)

\item {} 
\sphinxAtStartPar
Each sequence in \(\mathbb{R}^K\) has at most one limit

\item {} 
\sphinxAtStartPar
Every convergent sequence in \(\mathbb{R}^K\) is bounded

\item {} 
\sphinxAtStartPar
Every convergent sequence in \(\mathbb{R}^K\) is Cauchy

\item {} 
\sphinxAtStartPar
Every Cauchy sequence in \(\mathbb{R}^K\) is convergent

\end{enumerate}
\end{sphinxadmonition}

\sphinxAtStartPar
\sphinxstylestrong{Exercise:} Adapt proofs given for the scalar case to these results

\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
Let’s check that
\begin{equation*}
\begin{split}
{\bf x}_n \to {\bf a} \text{ in } \mathbb{R}^K
\; \iff \;
\|{\bf x}_n - {\bf a}\| \to 0 \text{ in } \mathbb{R}
\end{split}
\end{equation*}\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Proof}
\begin{itemize}
\item {} 
\sphinxAtStartPar
\({\bf x}_n \to {\bf a}\) in \(\mathbb{R}^K\) means that

\end{itemize}
\begin{equation*}
\begin{split}
\forall \, \epsilon > 0, 
\;
\exists \, N \in \mathbb{N}
\; \mathrm{such\;that}  \; 
n \geq N \implies \| {\bf x}_n - {\bf a} \| < \epsilon
\end{split}
\end{equation*}\begin{itemize}
\item {} 
\sphinxAtStartPar
\(\|{\bf x}_n - {\bf a}\| \to 0\) in \(\mathbb{R}\) means that

\end{itemize}
\begin{equation*}
\begin{split}
\forall\,  \epsilon > 0, 
\;
\exists \, N \in \mathbb{N}
\; \mathrm{such\;that}  \;
n \geq N \implies | \| {\bf x}_n - {\bf a} \| - 0 | < \epsilon
\end{split}
\end{equation*}
\sphinxAtStartPar
Obviously equivalent
\end{sphinxadmonition}

\sphinxAtStartPar
Reminder — these facts are more general than scalar ones!
\begin{itemize}
\item {} 
\sphinxAtStartPar
True for any finite \(K\)

\item {} 
\sphinxAtStartPar
So true for \(K = 1\)

\item {} 
\sphinxAtStartPar
This recovers the corresponding scalar fact

\end{itemize}

\sphinxAtStartPar
\sphinxstyleemphasis{You can forget the scalar fact if you remember the vector one}

\begin{sphinxadmonition}{note}{Fact}

\sphinxAtStartPar
If \(\{ {\bf x}_n \}\) converges to \({\bf x}\) in \(\mathbb{R}^K\), then every
subsequence of \(\{{\bf x}_n\}\) also converges to \({\bf x}\)
\end{sphinxadmonition}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[scale=0.8]{{subseqconverg}.png}
\caption{Convergence of subsequences}\label{\detokenize{04.basic_analysis:subseqconverg}}\end{figure}


\subsection{Infinite Sums in \protect\(\mathbb{R}^K\protect\)}
\label{\detokenize{04.basic_analysis:infinite-sums-in-mathbb-r-k}}
\sphinxAtStartPar
Analogous to the scalar case, an infinite sum in \(\mathbb{R}^K\) is the limit of the partial sum

\begin{sphinxadmonition}{note}{Definition}

\sphinxAtStartPar
If \(\{{\bf x}_n\}\) is a sequence in \(\mathbb{R}^K\), then
\begin{equation*}
\begin{split}
\sum_{n=1}^{\infty} {\bf x}_n := \lim_{J\to \infty} \sum_{n=1}^J {\bf x}_n  
\text{ if the limit exists}
\end{split}
\end{equation*}\end{sphinxadmonition}

\sphinxAtStartPar
In other words,
\begin{equation*}
\begin{split}
{\bf y} = \sum_{n=1}^{\infty} {\bf x}_n 
\quad \iff \quad
\lim_{J \to \infty}
\;
\left\| \sum_{n=1}^J {\bf x}_n  - {\bf y} \right\|
\to 0
\end{split}
\end{equation*}

\section{Open and Closed Sets}
\label{\detokenize{04.basic_analysis:open-and-closed-sets}}
\sphinxAtStartPar
Let \(G \subset \mathbb{R}^K\)

\begin{sphinxadmonition}{note}{Definition}

\sphinxAtStartPar
We call \({\bf x} \in G\) \sphinxstyleemphasis{\sphinxstylestrong{interior}} to \(G\) if
\(\exists \; \epsilon > 0\) with \(B_\epsilon({\bf x}) \subset G\)
\end{sphinxadmonition}

\sphinxAtStartPar
Loosely speaking, interior means “not on the boundary”

\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics[scale=0.5]{{interior}.png}
\end{figure}

\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
If \(G = (a, b)\) for some \(a < b\), then any \(x \in (a, b)\) is interior
\end{sphinxadmonition}

\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics{{x_interior}.png}
\end{figure}

\begin{sphinxadmonition}{note}{Proof}

\sphinxAtStartPar
Fix any \(a < b\) and any \(x \in (a, b)\)

\sphinxAtStartPar
Let \(\epsilon := \min\{x - a, b - x\}\)

\sphinxAtStartPar
If \(y \in B_\epsilon(x)\) then \(y < b\) because
\begin{equation*}
\begin{split}
y 
= y + x - x
\leq |y - x| + x
< \epsilon + x 
\leq b - x + x = b
\end{split}
\end{equation*}
\sphinxAtStartPar
\sphinxstylestrong{Exercise:} Show \(y \in B_\epsilon(x) \implies y > a\)
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
If \(G = [-1, 1]\), then \(1\) is not interior
\end{sphinxadmonition}

\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics{{not_interior}.png}
\end{figure}

\sphinxAtStartPar
Intuitively, any \(\epsilon\)\sphinxhyphen{}ball centered on \(1\) will contain points \(> 1\)

\sphinxAtStartPar
More formally, pick any \(\epsilon  > 0\) and consider \(B_\epsilon(1)\)

\sphinxAtStartPar
There exists a \(y \in B_\epsilon(1)\) such that \(y \notin [-1, 1]\)

\sphinxAtStartPar
For example, consider the point \(y := 1 + \epsilon/2\)

\sphinxAtStartPar
\sphinxstylestrong{Exercise:} Check this point: lies in \(B_\epsilon(1)\) but not in \([-1, 1]\)

\begin{sphinxadmonition}{note}{Definition}

\sphinxAtStartPar
A set \(G\subset \mathbb{R}^K\) is called \sphinxstyleemphasis{\sphinxstylestrong{open}} if all of its points are interior
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
Open sets:
\begin{itemize}
\item {} 
\sphinxAtStartPar
any “open” interval \((a,b) \subset \mathbb{R}\), since we showed all points are interior

\item {} 
\sphinxAtStartPar
any “open” ball \(B_\epsilon({\bf a}) = {\bf x} \in
\mathbb{R}^K : \|{\bf x} - {\bf a} \| < \epsilon\)

\item {} 
\sphinxAtStartPar
\(\mathbb{R}^K\) itself

\end{itemize}
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
Sets that are not open
\begin{itemize}
\item {} 
\sphinxAtStartPar
\((a,b]\) because \(b\) is not interior

\item {} 
\sphinxAtStartPar
\([a,b)\) because \(a\) is not interior

\end{itemize}
\end{sphinxadmonition}


\subsection{Closed Sets}
\label{\detokenize{04.basic_analysis:closed-sets}}
\begin{sphinxadmonition}{note}{Definition}

\sphinxAtStartPar
A set \(F \subset \mathbb{R}^K\) is called \sphinxstyleemphasis{\sphinxstylestrong{closed}} if every convergent sequence in \(F\) converges to a point in \(F\)
\end{sphinxadmonition}

\sphinxAtStartPar
Rephrased: If \(\{{\bf x}_n\} \subset F\) and \({\bf x}_n \to {\bf x}\) for some
\({\bf x} \in \mathbb{R}^K\), then \({\bf x} \in F\)

\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
All of \(\mathbb{R}^K\) is closed because every sequence converging to a point in \(\mathbb{R}^K\) converges to a point in \(\mathbb{R}^K\)… right?
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
If \((-1, 1) \subset \mathbb{R}\) is \{\textbackslash{}bf not\} closed
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Proof}

\sphinxAtStartPar
True because
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
\(x_n := 1-1/n\) is a sequence in \((-1, 1)\) converging to \(1\),

\item {} 
\sphinxAtStartPar
and yet \(1 \notin (-1, 1)\)

\end{enumerate}
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
If \(F = [a, b] \subset \mathbb{R}\) then \(F\) is closed in \(\mathbb{R}\)
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Proof}

\sphinxAtStartPar
Take any sequence \(\{x_n\}\) such that
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(x_n \in F\) for all \(n\)

\item {} 
\sphinxAtStartPar
\(x_n \to x\) for some \(x \in \mathbb{R}\)

\end{itemize}

\sphinxAtStartPar
We claim that \(x \in F\)

\sphinxAtStartPar
Recall that (weak) inequalities are preserved under limits:
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(x_n \leq b\) for all \(n\) and \(x_n \to x\), so \(x \leq b\)

\item {} 
\sphinxAtStartPar
\(x_n \geq a\) for all \(n\) and \(x_n \to x\), so \(x \geq a\)

\end{itemize}

\sphinxAtStartPar
therefore \(x \in [a, b] =: F\)
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
Any “hyperplane” of the form
\begin{equation*}
\begin{split}
H = \{ {\bf x} \in \mathbb{R}^K : {\bf x}' {\bf a} = c \}
\end{split}
\end{equation*}
\sphinxAtStartPar
is closed
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Proof}

\sphinxAtStartPar
Fix \({\bf a} \in \mathbb{R}^K\) and \(c \in \mathbb{R}\) and let \(H\) be as above

\sphinxAtStartPar
Let \(\{{\bf x}_n\} \subset H\) with \({\bf x}_n \to {\bf x} \in \mathbb{R}^K\)

\sphinxAtStartPar
We claim that \({\bf x} \in H\)

\sphinxAtStartPar
Since \({\bf x}_n \in H\) and \({\bf x}_n \to {\bf x}\) we have
\begin{equation*}
\begin{split}
{\bf x}_n ' {\bf a} \to {\bf x}' {\bf a} \text{ in } \mathbb{R}
\quad \text{and} \quad
{\bf x}_n' {\bf a} = c \text{ for all } n
\end{split}
\end{equation*}\begin{equation*}
\begin{split}
\text{therefore } 
{\bf x}' {\bf a} = \lim_{n} {\bf x}_n' {\bf a} 
= \lim_n c
= c
\end{split}
\end{equation*}\begin{equation*}
\begin{split}
\text{therefore } 
{\bf x} \in H
\end{split}
\end{equation*}\end{sphinxadmonition}


\section{Properties of Open and Closed Sets}
\label{\detokenize{04.basic_analysis:properties-of-open-and-closed-sets}}
\begin{sphinxadmonition}{note}{Fact}

\sphinxAtStartPar
\(G \subset \mathbb{R}^K\) is open \(\iff \; G^c\) is closed
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Proof}

\sphinxAtStartPar
\(\implies\)

\sphinxAtStartPar
First prove necessity

\sphinxAtStartPar
Pick any \(G\) and let \(F := G^c\)

\sphinxAtStartPar
Suppose to the contrary that \(G\) is open but \(F\) is not closed, so

\sphinxAtStartPar
\(\exists\) a sequence \(\{{\bf x}_n\} \subset F\) with limit \({\bf x} \notin F\)

\sphinxAtStartPar
Then \({\bf x} \in G\), and since \(G\) open, \(\exists \, \epsilon > 0\) such
that \(B_\epsilon({\bf x}) \subset G\)

\sphinxAtStartPar
Since \({\bf x}_n \to {\bf x}\) we can choose an \(N \in \mathbb{N}\) with \({\bf x}_N \in
B_\epsilon({\bf x})\)

\sphinxAtStartPar
This contradicts \({\bf x}_n \in F\) for all \(n\)

\sphinxAtStartPar
\(\Longleftarrow\)

\sphinxAtStartPar
Next prove sufficiency

\sphinxAtStartPar
Pick any closed \(F\) and let \(G := F^c\), need to prove that \(G\) is open

\sphinxAtStartPar
Suppose to the contrary that \(G\) is not open

\sphinxAtStartPar
Then exists some non\sphinxhyphen{}interior \({\bf x} \in G\), that is no \(\epsilon\)\sphinxhyphen{}ball around \(x\) lies entirely in \(G\)

\sphinxAtStartPar
Then it is possible to find a sequence \(\{{\bf x}_n\}\) which converges to \(x \in G\), but every element of which lies in the \(B_{1/n}({\bf x}) \cap F\)

\sphinxAtStartPar
This contradicts the fact that \(F\) is closed
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
Any singleton \(\{ {\bf x} \} \subset \mathbb{R}^K\) is closed
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Proof}

\sphinxAtStartPar
Let’s prove this by showing that \(\{{\bf x}\}^c\) is open

\sphinxAtStartPar
Pick any \({\bf y} \in \{{\bf x}\}^c\)

\sphinxAtStartPar
We claim that \({\bf y}\) is interior to \(\{{\bf x}\}^c\)

\sphinxAtStartPar
Since \({\bf y} \in \{{\bf x}\}^c\) it must be that \({\bf y} \ne {\bf x}\)

\sphinxAtStartPar
Therefore, exists \(\epsilon > 0\) such that \(B_\epsilon({\bf y}) \cap B_\epsilon({\bf x}) = \emptyset\)

\sphinxAtStartPar
In particular, \({\bf x} \notin B_\epsilon({\bf y})\), and hence \(B_\epsilon({\bf y}) \subset \{{\bf x}\}^c\)

\sphinxAtStartPar
Therefore \({\bf y}\) is interior as claimed

\sphinxAtStartPar
Since \({\bf y}\) was arbitrary it follows that \(\{{\bf x}\}^c\) is open and \(\{{\bf x}\}\) is closed
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Fact}
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
Any \sphinxstyleemphasis{union} of open sets is open

\item {} 
\sphinxAtStartPar
Any \sphinxstyleemphasis{intersection} of closed sets is closed

\end{enumerate}
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Proof}

\sphinxAtStartPar
\sphinxstyleemphasis{Proof of first fact:}

\sphinxAtStartPar
Let \(G := \cup_{\lambda \in \Lambda} G_\lambda\), where each \(G_\lambda\) is
open

\sphinxAtStartPar
We claim that any given \({\bf x} \in G\) is interior to \(G\)

\sphinxAtStartPar
Pick any \({\bf x} \in G\)

\sphinxAtStartPar
By definition, \({\bf x} \in G_\lambda\) for some \(\lambda\)

\sphinxAtStartPar
Since \(G_\lambda\) is open, \(\exists \, \epsilon > 0\) such that \(B_\epsilon({\bf x})
\subset G_\lambda\)

\sphinxAtStartPar
But \(G_\lambda \subset G\), so \(B_\epsilon({\bf x}) \subset G\) also holds

\sphinxAtStartPar
In other words, \({\bf x}\) is interior to \(G\)
\end{sphinxadmonition}

\sphinxAtStartPar
But be careful:
\begin{itemize}
\item {} 
\sphinxAtStartPar
An \sphinxstylestrong{infinite} intersection of open sets is not necessarily open

\item {} 
\sphinxAtStartPar
An \sphinxstylestrong{infinite} union of closed sets is not necessarily closed

\end{itemize}

\sphinxAtStartPar
For example, if \(G_n := (-1/n, 1/n)\),  then \(\cap_{n \in \mathbb{N}} G_n = \{0\} \)

\sphinxAtStartPar
To see this, suppose that \(x \in \cap_n G_n\)

\sphinxAtStartPar
Then
\begin{equation*}
\begin{split}
-1/n < x < 1/n, \quad \forall n \in \mathbb{N}
\end{split}
\end{equation*}
\sphinxAtStartPar
Therefore \(x = 0\), and hence \(x \in \{0\}\)

\sphinxAtStartPar
On the other hand, if \(x \in \{0\}\) then \(x \in \cap_n G_n\)

\begin{sphinxadmonition}{note}{Fact}

\sphinxAtStartPar
If \(A\) is closed and bounded then every sequence in
\(A\) has a subsequence which converges to a point of \(A\)
\end{sphinxadmonition}

\sphinxAtStartPar
Take any sequence \(\{{\bf x}_n\}\) contained in \(A\)

\sphinxAtStartPar
Since \(A\) is bounded, \(\{{\bf x}_n\}\) is bounded

\sphinxAtStartPar
Therefore it has a convergent subsequence

\sphinxAtStartPar
Since the subsequence is also contained in \(A\),
and \(A\) is closed, the limit must lie in \(A\).

\begin{sphinxadmonition}{note}{Definition}

\sphinxAtStartPar
Bounded and closed sets are called \sphinxstylestrong{compact sets} or \sphinxstylestrong{compacts}
\end{sphinxadmonition}


\section{Continuity}
\label{\detokenize{04.basic_analysis:continuity}}
\sphinxAtStartPar
One of the most fundamental properties of functions

\sphinxAtStartPar
Related to existence of
\begin{itemize}
\item {} 
\sphinxAtStartPar
optima

\item {} 
\sphinxAtStartPar
roots

\item {} 
\sphinxAtStartPar
fixed points

\item {} 
\sphinxAtStartPar
etc

\end{itemize}

\sphinxAtStartPar
as well as a variety of other useful concepts

\begin{sphinxadmonition}{note}{Definition}

\sphinxAtStartPar
A function \(F\) is called \sphinxstyleemphasis{\sphinxstylestrong{bounded}} if its range is a bounded set.
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Fact}

\sphinxAtStartPar
If \(F\) and \(G\) are bounded, then so are \(F+G\), \(F \cdot G\) and \(\alpha F\) for any finite \(\alpha\)
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Proof}

\sphinxAtStartPar
Proof for the case \(F + G\):

\sphinxAtStartPar
Let \(F\) and \(G\) be bounded functions

\sphinxAtStartPar
\(\exists\) \(M_F\) and \(M_G\) s.t.
\(\| F({\bf x}) \| \leq M_F\) and \(\| G({\bf x}) \| \leq M_G\)
for all \({\bf x}\)

\sphinxAtStartPar
Fix any \({\bf x}\) and let \(M := M_F + M_G\)

\sphinxAtStartPar
Applying the triangle inequality gives
\begin{equation*}
\begin{split}
\| (F + G)({\bf x}) \|
:= \| F({\bf x}) + G({\bf x}) \|
\leq \| F({\bf x}) \| + \| G({\bf x}) \| 
\leq M
\end{split}
\end{equation*}
\sphinxAtStartPar
Since \({\bf x}\) was arbitrary this bound holds for all \({\bf x}\)
\end{sphinxadmonition}

\sphinxAtStartPar
Let \(F \colon A \to \mathbb{R}^J\) where \(A\) is a subset of \(\mathbb{R}^K\)

\begin{sphinxadmonition}{note}{Definition}

\sphinxAtStartPar
\(F\) is called \sphinxstyleemphasis{\sphinxstylestrong{continuous at}} \({\bf x} \in A\) if as \(n \to \infty\)
\begin{equation*}
\begin{split}
{\bf x}_n \to {\bf x}
\quad \implies \quad
F({\bf x}_n) \to F({\bf x}) 
\end{split}
\end{equation*}\end{sphinxadmonition}

\sphinxAtStartPar
Requires that
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(F({\bf x}_n)\) converges for each choice of \({\bf x}_n \to {\bf x}\),

\item {} 
\sphinxAtStartPar
The limit is always the same, and that limit is \(F({\bf x})\)

\end{itemize}

\begin{sphinxadmonition}{note}{Definition}

\sphinxAtStartPar
\(F\) is called \sphinxstyleemphasis{\sphinxstylestrong{continuous}} if it is continuous at every \({\bf x} \in
A\)
\end{sphinxadmonition}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{cont_func}.png}
\caption{Continuity}\label{\detokenize{04.basic_analysis:cont-func}}\end{figure}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{discont_func}.png}
\caption{Discontinuity at \(x\)}\label{\detokenize{04.basic_analysis:discont-func}}\end{figure}

\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
Let \({\bf A}\) be an \(J \times K\) matrix and let \(F({\bf x}) = {\bf A}
{\bf x}\)

\sphinxAtStartPar
The function \(F\) is continuous at every \({\bf x} \in \mathbb{R}^K\)
\end{sphinxadmonition}

\sphinxAtStartPar
To see this take
\begin{itemize}
\item {} 
\sphinxAtStartPar
any \({\bf x} \in \mathbb{R}^K\)

\item {} 
\sphinxAtStartPar
any \({\bf x}_n \to {\bf x}\)

\end{itemize}

\sphinxAtStartPar
By the definition of the matrix norm \(\| {\bf A} \|\), we have
\begin{equation*}
\begin{split}
\| {\bf A} {\bf x}_n - {\bf A} {\bf x} \|
= \| {\bf A} ({\bf x}_n - {\bf x}) \|
\leq \| {\bf A} \| \| {\bf x}_n - {\bf x} \|
\end{split}
\end{equation*}\begin{equation*}
\begin{split}
\text{therefore }
{\bf x}_n \to {\bf x} \implies
{\bf A} {\bf x}_n \to {\bf A} {\bf x} 
\end{split}
\end{equation*}
\sphinxAtStartPar
\sphinxstyleemphasis{\sphinxstylestrong{Exercise:}} Exactly what rules are we using here?

\begin{sphinxadmonition}{note}{Fact}

\sphinxAtStartPar
If \(f \colon \mathbb{R} \to \mathbb{R}\) is differentiable at \(x\), then \(f\) is continuous at \(x\)
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Fact}

\sphinxAtStartPar
Some functions known to be continuous on their domains:
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(x \mapsto x^\alpha\)

\item {} 
\sphinxAtStartPar
\(x \mapsto |x|\)

\item {} 
\sphinxAtStartPar
\(x \mapsto \log(x)\)

\item {} 
\sphinxAtStartPar
\(x \mapsto \exp(x)\)

\item {} 
\sphinxAtStartPar
\(x \mapsto \sin(x)\)

\item {} 
\sphinxAtStartPar
\(x \mapsto \cos(x)\)

\end{itemize}
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
Discontinuous at zero: \(x \mapsto \mathbb{1}\{x > 0\}\).
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Fact}

\sphinxAtStartPar
Let \(F\) and \(G\) be functions and let \(\alpha \in \mathbb{R}\)
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
If \(F\) and \(G\) are continuous at \({\bf x}\) then so is \(F + G\),
where

\end{enumerate}
\begin{equation*}
\begin{split}
(F + G)({\bf x}) := F({\bf x}) + G({\bf x})
\end{split}
\end{equation*}\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\setcounter{enumi}{1}
\item {} 
\sphinxAtStartPar
If \(F\) is continuous at \({\bf x}\) then so is \(\alpha F\), where

\end{enumerate}
\begin{equation*}
\begin{split}
(\alpha F)({\bf x}) := \alpha F({\bf x})
\end{split}
\end{equation*}\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\setcounter{enumi}{2}
\item {} 
\sphinxAtStartPar
If \(F\) and \(G\) are continuous at \({\bf x}\) and real valued then so is
\(FG\), where

\end{enumerate}
\begin{equation*}
\begin{split}
(FG)({\bf x}) := F({\bf x}) \cdot G({\bf x})
\end{split}
\end{equation*}
\sphinxAtStartPar
In the latter case, if in addition \(G({\bf x}) \ne 0\), then \(F/G\) is also continuous.
\end{sphinxadmonition}

\sphinxAtStartPar
As a result, set of continuous functions is “closed” under elementary
arithmetic operations

\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
The function \(F \colon \mathbb{R} \to \mathbb{R}\) defined by
\begin{equation*}
\begin{split}
F(x) = \frac{\exp(x) + \sin(x)}{2 + \cos(x)} + \frac{x^4}{2}
- \frac{\cos^3(x)}{8!}
\end{split}
\end{equation*}
\sphinxAtStartPar
is continuous
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Proof}

\sphinxAtStartPar
Just repeatedly apply the rules on the previous slide

\sphinxAtStartPar
Let’s just check that
\begin{equation*}
\begin{split}
\text{$F$ and $G$ continuous at ${\bf x}$}
\implies 
\text{$F + G$ continuous at ${\bf x}$}
\end{split}
\end{equation*}
\sphinxAtStartPar
Let \(F\) and \(G\) be continuous at \({\bf x}\)

\sphinxAtStartPar
Pick any \({\bf x}_n \to {\bf x}\)

\sphinxAtStartPar
We claim that
\(F({\bf x}_n) + G({\bf x}_n) \to F({\bf x}) + G({\bf x})\)

\sphinxAtStartPar
By assumption, \(F({\bf x}_n) \to F({\bf x})\) and \(G({\bf x}_n) \to G({\bf x})\)

\sphinxAtStartPar
From this and the triangle inequality we get
\begin{equation*}
\begin{split}
\| F({\bf x}_n) + G({\bf x}_n) - (F({\bf x}) + G({\bf x})) \|
\leq 
\end{split}
\end{equation*}\begin{equation*}
\begin{split}
\leq 
\| F({\bf x}_n) - F({\bf x}) \|
+
\| G({\bf x}_n) - G({\bf x}) \|
\to 0
\end{split}
\end{equation*}\end{sphinxadmonition}


\section{Extra material}
\label{\detokenize{04.basic_analysis:extra-material}}
\sphinxAtStartPar
Watch \sphinxhref{https://youtu.be/kfF40MiS7zA}{excellent video} by Grant Sanderson (3blue1brown) on limits, and continue onto his \sphinxhref{https://www.youtube.com/watch?v=WUvTyaaNkzM\&list=PLZHQObOWTQDMsr9K-rj53DwVRMYO3t5Yr\&pp=iAQB}{whole amazing series on calculus}

\sphinxstepscope


\chapter{Elements of linear algebra}
\label{\detokenize{05.linear_algebra:elements-of-linear-algebra}}\label{\detokenize{05.linear_algebra::doc}}
\sphinxAtStartPar
\sphinxstylestrong{ECON2125/6012 Lecture 5}\\
Fedor Iskhakov


\section{Announcements \& Reminders}
\label{\detokenize{05.linear_algebra:announcements-reminders}}\begin{itemize}
\item {} 
\sphinxAtStartPar
Tests due last night: feedback soon

\item {} 
\sphinxAtStartPar
This lecture is recorded

\item {} 
\sphinxAtStartPar
Next week we return to the class

\end{itemize}


\section{Plan for this lecture}
\label{\detokenize{05.linear_algebra:plan-for-this-lecture}}
\sphinxAtStartPar
Review of some concepts in linear algebra
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
Vector spaces

\end{enumerate}
\begin{itemize}
\item {} 
\sphinxAtStartPar
Linear combinations, span, linear independence

\item {} 
\sphinxAtStartPar
Linear subspaces, bases and dimension

\item {} 
\sphinxAtStartPar
Linear maps and independence

\end{itemize}
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\setcounter{enumi}{1}
\item {} 
\sphinxAtStartPar
Linear equations

\end{enumerate}
\begin{itemize}
\item {} 
\sphinxAtStartPar
Basic operations with matrices

\item {} 
\sphinxAtStartPar
Square and invertible matrices

\item {} 
\sphinxAtStartPar
Determinant

\end{itemize}
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\setcounter{enumi}{2}
\item {} 
\sphinxAtStartPar
Quadratic forms

\end{enumerate}
\begin{itemize}
\item {} 
\sphinxAtStartPar
Eigenvalues and diagonalization

\item {} 
\sphinxAtStartPar
Symmetric matrices

\item {} 
\sphinxAtStartPar
Positive and negative definiteness

\end{itemize}

\sphinxAtStartPar
\sphinxstylestrong{Supplementary reading:}
\begin{itemize}
\item {} 
\sphinxAtStartPar
Stachurski: 2.1, 3.1, 3.2

\item {} 
\sphinxAtStartPar
Simon \& Blume: 6.1, 6.2, 10.1, 10.2, 10.3, 10.4, 10.5, 10.6, 11, 16, 23.7, 23.8

\item {} 
\sphinxAtStartPar
Sundaram: 1.3, Appendix C.1, C.2

\item {} 
\sphinxAtStartPar
{\hyperref[\detokenize{05.linear_algebra:extra-study-material}]{\sphinxcrossref{\DUrole{std,std-ref}{Extra study material in the bottom of this document}}}}

\end{itemize}


\section{Intro to Linear Algebra}
\label{\detokenize{05.linear_algebra:intro-to-linear-algebra}}
\sphinxAtStartPar
Linear algebra is used to study linear models

\sphinxAtStartPar
Foundational for many disciplines related to economics
\begin{itemize}
\item {} 
\sphinxAtStartPar
Economic theory

\item {} 
\sphinxAtStartPar
Econometrics and statistics

\item {} 
\sphinxAtStartPar
Finance

\item {} 
\sphinxAtStartPar
Operations research

\end{itemize}

\begin{sphinxadmonition}{note}{Example of linear model}

\sphinxAtStartPar
Equilibrium in a single market with price \(p\)
\begin{equation*}
\begin{split}
q_d = a + b p
\\
q_s = c + d p
\\
q_s = q_d
\end{split}
\end{equation*}
\sphinxAtStartPar
What price \(p\) clears the market, and at what quantity \(q = q_s = q_d\)?
\end{sphinxadmonition}

\sphinxAtStartPar
Here \(a, b, c, d\) are the model \sphinxstyleemphasis{parameters} or \sphinxstyleemphasis{coefficients}

\sphinxAtStartPar
Treated as fixed for a single computation but might vary between computations to better fit the data

\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
Determination of income
\begin{equation*}
\begin{split}
C = a + b(Y - T)
\\
E = C + I
\\
G = T
\\
Y = E
%
\end{split}
\end{equation*}
\sphinxAtStartPar
\sphinxstylestrong{Question:} discuss what the variables are

\sphinxAtStartPar
Solve for \(Y\) as a function of \(I\) and \(G\)
\end{sphinxadmonition}

\sphinxAtStartPar
Bigger, more complex systems found in problems related to
\begin{itemize}
\item {} 
\sphinxAtStartPar
Regression and forecasting

\item {} 
\sphinxAtStartPar
Portfolio analysis

\item {} 
\sphinxAtStartPar
Ranking systems

\item {} 
\sphinxAtStartPar
Etc., etc. — any number of applications

\end{itemize}

\begin{sphinxadmonition}{note}{Definition}

\sphinxAtStartPar
A general system of equations can be written as
\begin{equation*}
\begin{split}
\begin{array}{c}
a_{11} x_1 + a_{12} x_2 + \cdots + a_{1K} x_K = b_1 \\
a_{21} x_1 + a_{22} x_2 + \cdots + a_{2K} x_K = b_2 \\
\vdots \\
a_{N1} x_1 + a_{N2} x_2 + \cdots + a_{NK} x_K = b_N 
\end{array}
\end{split}
\end{equation*}\end{sphinxadmonition}

\sphinxAtStartPar
Typically
\begin{itemize}
\item {} 
\sphinxAtStartPar
the \(a_{ij}\) and \(b_i\) are exogenous / given / parameters

\item {} 
\sphinxAtStartPar
the values \(x_j\) are endogenous

\end{itemize}

\sphinxAtStartPar
Key question: What values of \(x_1, \ldots, x_K\) solve this system?

\sphinxAtStartPar
More often we write the system in \sphinxstyleemphasis{\sphinxstylestrong{matrix form}}
\begin{equation*}
\begin{split}
\left(
\begin{array}{cccc}
a_{11} & a_{12} & \cdots & a_{1K} \\
a_{21} & a_{22} & \cdots & a_{2K} \\
\vdots & \vdots & & \vdots \\
a_{N1} & a_{N2} & \cdots & a_{NK} 
\end{array}
\right)
\left(
\begin{array}{c}
x_1 \\
x_2 \\
\vdots \\
x_K
\end{array}
\right)
=
\left(
\begin{array}{c}
b_1 \\
b_2 \\
\vdots \\
b_K
\end{array}
\right)
%
\end{split}
\end{equation*}
\sphinxAtStartPar
or
\begin{equation*}
\begin{split}
%
{\bf A} {\bf x} = {\bf b}
%
\end{split}
\end{equation*}
\sphinxAtStartPar
Notice bold font to indicate that the variables are \sphinxstyleemphasis{vectors}.

\sphinxAtStartPar
Let’s solve this system on a computer:

\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{import} \PYG{n+nn}{numpy} \PYG{k}{as} \PYG{n+nn}{np}
\PYG{k+kn}{from} \PYG{n+nn}{scipy}\PYG{n+nn}{.}\PYG{n+nn}{linalg} \PYG{k+kn}{import} \PYG{n}{solve}
\PYG{n}{A} \PYG{o}{=} \PYG{p}{[}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{,} \PYG{l+m+mi}{2}\PYG{p}{,} \PYG{l+m+mi}{4}\PYG{p}{]}\PYG{p}{,}
     \PYG{p}{[}\PYG{l+m+mi}{1}\PYG{p}{,} \PYG{l+m+mi}{4}\PYG{p}{,} \PYG{l+m+mi}{8}\PYG{p}{]}\PYG{p}{,}
     \PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{,} \PYG{l+m+mi}{3}\PYG{p}{,} \PYG{l+m+mi}{7}\PYG{p}{]}\PYG{p}{]}
\PYG{n}{b} \PYG{o}{=} \PYG{p}{(}\PYG{l+m+mi}{1}\PYG{p}{,} \PYG{l+m+mi}{2}\PYG{p}{,} \PYG{l+m+mi}{0}\PYG{p}{)}
\PYG{n}{A}\PYG{p}{,} \PYG{n}{b} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{asarray}\PYG{p}{(}\PYG{n}{A}\PYG{p}{)}\PYG{p}{,} \PYG{n}{np}\PYG{o}{.}\PYG{n}{asarray}\PYG{p}{(}\PYG{n}{b}\PYG{p}{)}
\PYG{n}{x}\PYG{o}{=}\PYG{n}{solve}\PYG{p}{(}\PYG{n}{A}\PYG{p}{,} \PYG{n}{b}\PYG{p}{)}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+sa}{f}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Solutions is x=}\PYG{l+s+si}{\PYGZob{}}\PYG{n}{x}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
Solutions is x=[\PYGZhy{}1.77635684e\PYGZhy{}15  3.50000000e+00 \PYGZhy{}1.50000000e+00]
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\sphinxAtStartPar
This tells us that the solution is \(x = (0. , 3.5, -1.5)\)

\sphinxAtStartPar
That is,
\begin{equation*}
\begin{split}
%
{\bf x} =
\left(
\begin{array}{c}
x_1 \\
x_2 \\
x_3
\end{array}
\right)
=
\left(
\begin{array}{c}
0 \\
3.5 \\
-1.5
\end{array}
\right)
%
\end{split}
\end{equation*}
\sphinxAtStartPar
The usual question: if computers can do it so easily — what do we need to study for?

\sphinxAtStartPar
But now let’s try this similar looking problem

\sphinxAtStartPar
\sphinxstylestrong{Question:} what changed?

\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{import} \PYG{n+nn}{numpy} \PYG{k}{as} \PYG{n+nn}{np}
\PYG{k+kn}{from} \PYG{n+nn}{scipy}\PYG{n+nn}{.}\PYG{n+nn}{linalg} \PYG{k+kn}{import} \PYG{n}{solve}
\PYG{n}{A} \PYG{o}{=} \PYG{p}{[}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{,} \PYG{l+m+mi}{2}\PYG{p}{,} \PYG{l+m+mi}{4}\PYG{p}{]}\PYG{p}{,}
     \PYG{p}{[}\PYG{l+m+mi}{1}\PYG{p}{,} \PYG{l+m+mi}{4}\PYG{p}{,} \PYG{l+m+mi}{8}\PYG{p}{]}\PYG{p}{,}
     \PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{,} \PYG{l+m+mi}{3}\PYG{p}{,} \PYG{l+m+mi}{6}\PYG{p}{]}\PYG{p}{]}
\PYG{n}{b} \PYG{o}{=} \PYG{p}{(}\PYG{l+m+mi}{1}\PYG{p}{,} \PYG{l+m+mi}{2}\PYG{p}{,} \PYG{l+m+mi}{0}\PYG{p}{)}
\PYG{n}{A}\PYG{p}{,} \PYG{n}{b} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{asarray}\PYG{p}{(}\PYG{n}{A}\PYG{p}{)}\PYG{p}{,} \PYG{n}{np}\PYG{o}{.}\PYG{n}{asarray}\PYG{p}{(}\PYG{n}{b}\PYG{p}{)}
\PYG{n}{x}\PYG{o}{=}\PYG{n}{solve}\PYG{p}{(}\PYG{n}{A}\PYG{p}{,} \PYG{n}{b}\PYG{p}{)}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+sa}{f}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Solutions is x=}\PYG{l+s+si}{\PYGZob{}}\PYG{n}{x}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
Solutions is x=[ 0.00000000e+00 \PYGZhy{}9.00719925e+15  4.50359963e+15]
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
/var/folders/5d/cjhpvdlx7lg8zt1ypw5fcyy40000gn/T/ipykernel\PYGZus{}98027/3978225594.py:8: LinAlgWarning: Ill\PYGZhy{}conditioned matrix (rcond=4.11194e\PYGZhy{}18): result may not be accurate.
  x=solve(A, b)
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\sphinxAtStartPar
This is the output that we get:
\sphinxcode{\sphinxupquote{LinAlgWarning: Ill\sphinxhyphen{}conditioned matrix}}
\begin{itemize}
\item {} 
\sphinxAtStartPar
What does this mean?

\item {} 
\sphinxAtStartPar
How can we fix it?

\end{itemize}

\sphinxAtStartPar
\sphinxstylestrong{We still need to understand the concepts after all!}


\section{Vector Space}
\label{\detokenize{05.linear_algebra:vector-space}}
\sphinxAtStartPar
Recall that \(\mathbb{R}^N := \) set of all \(N\)\sphinxhyphen{}vectors

\begin{sphinxadmonition}{note}{Definition}

\sphinxAtStartPar
An \(N\)\sphinxhyphen{}vector \({\bf x}\) is a tuple of \(N\) real numbers:
\begin{equation*}
\begin{split}
{\bf x} = (x_1, \ldots, x_N) \in \mathbb{R}^N
\quad
\text{ where } 
\quad x_n \in \mathbb{R} \text{ for each } n
\end{split}
\end{equation*}\end{sphinxadmonition}

\sphinxAtStartPar
We typically think of vectors as columns, and can write \({\bf x}\) vertically, like so:
\begin{equation*}
\begin{split}
%
{\bf x} = 
\left(
\begin{array}{c}
x_1 \\
x_2 \\
\vdots \\
x_N
\end{array}
\right)
%
\end{split}
\end{equation*}
\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{vec}.png}
\caption{Visualization of vector \({\bf x}\) in \(\mathbb{R}^2\)}\label{\detokenize{05.linear_algebra:f-vec}}\end{figure}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{vecs}.png}
\caption{Three vectors in \(\mathbb{R}^2\)}\label{\detokenize{05.linear_algebra:id2}}\end{figure}

\sphinxAtStartPar
The vector of ones will be denoted \({\bf 1}\)
\begin{equation*}
\begin{split}
%
{\bf 1} := 
\left(
\begin{array}{c}
1 \\
\vdots \\
1
\end{array}
\right)
%
\end{split}
\end{equation*}
\sphinxAtStartPar
Vector of zeros will be denoted \({\bf 0}\)
\begin{equation*}
\begin{split}
%
{\bf 0} := 
\left(
\begin{array}{c}
0 \\
\vdots \\
0
\end{array}
\right)
%
\end{split}
\end{equation*}

\subsection{Linear Operations}
\label{\detokenize{05.linear_algebra:linear-operations}}
\sphinxAtStartPar
Two fundamental algebraic operations:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
Vector addition

\item {} 
\sphinxAtStartPar
Scalar multiplication

\end{enumerate}

\begin{sphinxadmonition}{note}{Definition}

\sphinxAtStartPar
\sphinxstyleemphasis{\sphinxstylestrong{Sum}} of \({\bf x} \in \mathbb{R}^N\) and \({\bf y} \in \mathbb{R}^N\) defined by
\begin{equation*}
\begin{split}
%
{\bf x} + {\bf y} 
:=: 
\left(
\begin{array}{c}
x_1 \\
x_2 \\
\vdots \\
x_N
\end{array}
\right)
+
\left(
\begin{array}{c}
y_1 \\
y_2 \\
\vdots \\
y_N
\end{array}
\right)
:=
\left(
\begin{array}{c}
x_1 + y_1 \\
x_2 + y_2 \\
\vdots \\
x_N + y_N
\end{array}
\right)
%
\end{split}
\end{equation*}\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Example}
\begin{equation*}
\begin{split}
%
\left(
\begin{array}{c}
1 \\
2 \\
3 \\
4
\end{array}
\right)
+
\left(
\begin{array}{c}
2 \\
4 \\
6 \\
8
\end{array}
\right)
:=
\left(
\begin{array}{c}
3 \\
6 \\
9 \\
12
\end{array}
\right)
%
\end{split}
\end{equation*}\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Example}
\begin{equation*}
\begin{split}
%
\left(
\begin{array}{c}
1 \\
2 \\
3 \\
4
\end{array}
\right)
+
\left(
\begin{array}{c}
1 \\
1 \\
1 \\
1
\end{array}
\right)
:=
\left(
\begin{array}{c}
2 \\
3 \\
4 \\
5
\end{array}
\right)
%
\end{split}
\end{equation*}\end{sphinxadmonition}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{vec_add}.png}
\caption{Vector addition}\label{\detokenize{05.linear_algebra:f-vec-add}}\end{figure}

\begin{sphinxadmonition}{note}{Definition}

\sphinxAtStartPar
\sphinxstyleemphasis{\sphinxstylestrong{Scalar product}} of \(\alpha \in \mathbb{R}\) and \({\bf x} \in \mathbb{R}^N\) defined by
\begin{equation*}
\begin{split}
%
\alpha {\bf x} 
=
\alpha \left(
\begin{array}{c}
x_1 \\
x_2 \\
\vdots \\
x_N
\end{array}
\right)
:=
\left(
\begin{array}{c}
\alpha x_1 \\
\alpha x_2 \\
\vdots \\
\alpha x_N
\end{array}
\right)
%
\end{split}
\end{equation*}\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Example}
\begin{equation*}
\begin{split}
%
0.5 
\left(
\begin{array}{c}
1 \\
2 \\
3 \\
4
\end{array}
\right)
:=
\left(
\begin{array}{c}
0.5 \\
1.0 \\
1.5 \\
2.0 
\end{array}
\right)
%
\end{split}
\end{equation*}\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Example}
\begin{equation*}
\begin{split}
%
-1
\left(
\begin{array}{c}
1 \\
2 \\
3 \\
4
\end{array}
\right)
:=
\left(
\begin{array}{c}
-1 \\
-2 \\
-3 \\
-4
\end{array}
\right)
%
\end{split}
\end{equation*}\end{sphinxadmonition}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{vec_scalar}.png}
\caption{Scalar multiplication}\label{\detokenize{05.linear_algebra:f-vec-scalar}}\end{figure}

\sphinxAtStartPar
Subtraction performed element by element, analogous to addition
\begin{equation*}
\begin{split}
%
{\bf x} - {\bf y} 
:=
\left(
\begin{array}{c}
x_1 - y_1 \\
x_2 - y_2 \\
\vdots \\
x_N - y_N
\end{array}
\right)
%
\end{split}
\end{equation*}
\sphinxAtStartPar
Def can be given in terms of addition and scalar multiplication:
\begin{equation*}
\begin{split}
%
{\bf x} - {\bf y} := {\bf x} + (-1) {\bf y} 
%
\end{split}
\end{equation*}
\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{vec_minus}.png}
\caption{Difference between vectors}\label{\detokenize{05.linear_algebra:f-vec-minus}}\end{figure}

\sphinxAtStartPar
Incidentally, most high level numerical libraries treat vector addition
and scalar multiplication in the same way — element\sphinxhyphen{}wise

\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{import} \PYG{n+nn}{numpy} \PYG{k}{as} \PYG{n+nn}{np}
\PYG{n}{x} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{array}\PYG{p}{(}\PYG{p}{(}\PYG{l+m+mi}{2}\PYG{p}{,} \PYG{l+m+mi}{4}\PYG{p}{,} \PYG{l+m+mi}{6}\PYG{p}{)}\PYG{p}{)}
\PYG{n}{y} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{array}\PYG{p}{(}\PYG{p}{(}\PYG{l+m+mi}{10}\PYG{p}{,} \PYG{l+m+mi}{10}\PYG{p}{,} \PYG{l+m+mi}{10}\PYG{p}{)}\PYG{p}{)}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{n}{x} \PYG{o}{+} \PYG{n}{y}\PYG{p}{)} \PYG{c+c1}{\PYGZsh{} Vector addition}

\PYG{n}{x} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{array}\PYG{p}{(}\PYG{p}{[}\PYG{l+m+mi}{12}\PYG{p}{,} \PYG{l+m+mi}{14}\PYG{p}{,} \PYG{l+m+mi}{16}\PYG{p}{]}\PYG{p}{)}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{l+m+mi}{2} \PYG{o}{*} \PYG{n}{x}\PYG{p}{)} \PYG{c+c1}{\PYGZsh{} Scalar multiplication}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
[12 14 16]
[24 28 32]
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\begin{sphinxadmonition}{note}{Definition}

\sphinxAtStartPar
A \sphinxstyleemphasis{\sphinxstylestrong{linear combination}} of vectors \({\bf x}_1,\ldots, {\bf x}_K\) in \(\mathbb{R}^N\)
is a vector
\begin{equation*}
\begin{split}
%
{\bf y} = \sum_{k=1}^K \alpha_k {\bf x}_k 
= \alpha_1 {\bf x}_1 + \cdots + \alpha_K {\bf x}_K 
%
\end{split}
\end{equation*}
\sphinxAtStartPar
where \(\alpha_1,\ldots, \alpha_K\) are scalars
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Example}
\begin{equation*}
\begin{split}
%
0.5 \left(
\begin{array}{c}
6.0 \\
2.0 \\
8.0
\end{array}
\right)
+
3.0 \left(
\begin{array}{c}
0 \\
1.0 \\
-1.0
\end{array}
\right)
=
\left(
\begin{array}{c}
3.0 \\
4.0 \\
1.0
\end{array}
\right)
%
\end{split}
\end{equation*}\end{sphinxadmonition}


\subsection{Inner Product}
\label{\detokenize{05.linear_algebra:inner-product}}
\begin{sphinxadmonition}{note}{Definition}

\sphinxAtStartPar
The \sphinxstyleemphasis{\sphinxstylestrong{inner product}} of two vectors \({\bf x}\) and \({\bf y}\) in \(\mathbb{R}^N\) is
\begin{equation*}
\begin{split}
%
{\bf x}' {\bf y} :=
\sum_{n=1}^N x_n y_n
%
\end{split}
\end{equation*}\end{sphinxadmonition}

\sphinxAtStartPar
The notation \(\bullet '\) flips the vector from column\sphinxhyphen{}vector to row\sphinxhyphen{}vector, this will make sense when we talk later about matrices for which vectors are special case.

\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
\({\bf x} = (2, 3)\) and \({\bf y} = (-1, 1)\) implies that
\begin{equation*}
\begin{split}
%
{\bf x}' {\bf y} 
= 2 \times (-1) + 3 \times 1 
= 1
%
\end{split}
\end{equation*}\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
\({\bf x} = \tfrac{1}{N} {\bf 1}\) and \({\bf y} = (y_1, \ldots, y_N)\) implies
\begin{equation*}
\begin{split}
%
{\bf x}' {\bf y} 
= \frac{1}{N} \sum_{n=1}^N y_n
%
\end{split}
\end{equation*}\end{sphinxadmonition}

\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{import} \PYG{n+nn}{numpy} \PYG{k}{as} \PYG{n+nn}{np}
\PYG{n}{x} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{array}\PYG{p}{(}\PYG{p}{(}\PYG{l+m+mi}{1}\PYG{p}{,} \PYG{l+m+mi}{2}\PYG{p}{,} \PYG{l+m+mi}{3}\PYG{p}{,} \PYG{l+m+mi}{4}\PYG{p}{)}\PYG{p}{)}
\PYG{n}{y} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{array}\PYG{p}{(}\PYG{p}{(}\PYG{l+m+mi}{2}\PYG{p}{,} \PYG{l+m+mi}{4}\PYG{p}{,} \PYG{l+m+mi}{6}\PYG{p}{,} \PYG{l+m+mi}{8}\PYG{p}{)}\PYG{p}{)}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Product =}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}\PYG{n}{x} \PYG{o}{*} \PYG{n}{y}\PYG{p}{)}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Inner product =}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}\PYG{n}{np}\PYG{o}{.}\PYG{n}{sum}\PYG{p}{(}\PYG{n}{x} \PYG{o}{*} \PYG{n}{y}\PYG{p}{)}\PYG{p}{)}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Inner product =}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}\PYG{n}{x} \PYG{o}{@} \PYG{n}{y}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
Product = [ 2  8 18 32]
Inner product = 60
Inner product = 60
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\begin{sphinxadmonition}{note}{Fact}

\sphinxAtStartPar
For any \(\alpha, \beta \in \mathbb{R}\) and any \({\bf x}, {\bf y} \in \mathbb{R}^N\), the following statements are true:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
\({\bf x}' {\bf y} = {\bf y}' {\bf x}\)

\item {} 
\sphinxAtStartPar
\((\alpha {\bf x})' (\beta {\bf y}) = \alpha \beta ({\bf x}' {\bf y})\)

\item {} 
\sphinxAtStartPar
\({\bf x}' ({\bf y} + {\bf z}) = {\bf x}' {\bf y} + {\bf x}' {\bf z}\)

\end{enumerate}
\end{sphinxadmonition}

\sphinxAtStartPar
For example, item 2 is true because
\begin{equation*}
\begin{split}
%
(\alpha {\bf x})' (\beta {\bf y}) 
= \sum_{n=1}^N \alpha x_n \beta y_n
= \alpha \beta \sum_{n=1}^N x_n y_n
= \alpha \beta ({\bf x}' {\bf y})
%
\end{split}
\end{equation*}
\sphinxAtStartPar
\sphinxstylestrong{Exercise:} Use above rules to show that
\((\alpha {\bf y} + \beta {\bf z})'{\bf x} = \alpha {\bf x}' {\bf y} + \beta {\bf x}' {\bf z}\)

\sphinxAtStartPar
The next result is a generalization

\begin{sphinxadmonition}{note}{Fact}

\sphinxAtStartPar
Inner products of linear combinations satisfy
\begin{equation*}
\begin{split}
%
\left(
\sum_{k=1}^K \alpha_k {\bf x}_k
\right)' 
\left(
\sum_{j=1}^J \beta_j {\bf y}_j 
\right)
=
\sum_{k=1}^K \sum_{j=1}^J \alpha_k \beta_j {\bf x}_k' {\bf y}_j 
%
\end{split}
\end{equation*}\end{sphinxadmonition}


\subsection{(Reminder about) Norms and Distance}
\label{\detokenize{05.linear_algebra:reminder-about-norms-and-distance}}
\sphinxAtStartPar
The (Euclidean) \sphinxstyleemphasis{\sphinxstylestrong{norm}} of \({\bf x} \in \mathbb{R}^N\) is defined as
\begin{equation*}
\begin{split}
%
\| {\bf x} \| 
:= \sqrt{{\bf x}' {\bf x} } 
= \left( \sum_{n=1}^N x_n^2 \right)^{1/2}
%
\end{split}
\end{equation*}
\sphinxAtStartPar
Interpretation:
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(\| {\bf x} \|\) represents the ``length’’ of \({\bf x}\)

\item {} 
\sphinxAtStartPar
\(\| {\bf x} - {\bf y} \|\) represents distance between \({\bf x}\) and \({\bf y}\)

\end{itemize}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{vec}.png}
\caption{Length of red line \(= \sqrt{x_1^2 + x_2^2}
=: \|{\bf x}\|\)}\label{\detokenize{05.linear_algebra:f-vec-rpt}}\end{figure}

\sphinxAtStartPar
\(\| {\bf x} - {\bf y} \|\) represents distance between \({\bf x}\) and \({\bf y}\)

\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics{{vec_minus}.png}
\end{figure}

\begin{sphinxadmonition}{note}{Fact}

\sphinxAtStartPar
For any \(\alpha \in \mathbb{R}\) and any \({\bf x}, {\bf y} \in \mathbb{R}^N\), the following statements are true:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
\(\| {\bf x} \| \geq 0\) and \(\| {\bf x} \| = 0\) if and only if
\({\bf x} = {\bf 0}\)

\end{enumerate}
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(\| \alpha {\bf x} \| = |\alpha| \| {\bf x} \|\)

\item {} 
\sphinxAtStartPar
\(\| {\bf x} + {\bf y} \| \leq \| {\bf x} \| + \| {\bf y} \|\)
(\sphinxstyleemphasis{\sphinxstylestrong{triangle inequality}})

\item {} 
\sphinxAtStartPar
\(| {\bf x}' {\bf y} | \leq \| {\bf x} \| \| {\bf y} \|\)
(\sphinxstyleemphasis{\sphinxstylestrong{Cauchy\sphinxhyphen{}Schwarz inequality}})

\end{itemize}
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Proof}

\sphinxAtStartPar
See the  previous lecture
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Fact}

\sphinxAtStartPar
If \({\bf x} \in \mathbb{R}^N\) is nonzero, then the solution to the optimization problem
\begin{equation*}
\begin{split}
%
\max_{{\bf y}} {\bf x}'{\bf y} 
\quad \text{ subject to } \quad
{\bf y} \in \mathbb{R}^N \text{ and } \| {\bf y} \| = 1 
%
\end{split}
\end{equation*}
\sphinxAtStartPar
is \({\hat{\bf x}} := {\bf x} / \| {\bf x} \|\)
\end{sphinxadmonition}

\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics{{max_inner_prod}.png}
\end{figure}

\begin{sphinxadmonition}{note}{Proof}

\sphinxAtStartPar
Fix nonzero \({\bf x} \in \mathbb{R}^N\)

\sphinxAtStartPar
Let \({\hat{\bf x}} := \alpha {\bf x}\) when \(\alpha := 1/\|{\bf x}\|\), that is \({\hat{\bf x}} := {\bf x} / \| {\bf x} \|\)

\sphinxAtStartPar
Evidently \(\| {\hat{\bf x}} \| = 1\)

\sphinxAtStartPar
Pick any other \({\bf y} \in \mathbb{R}^N\) satisfying \(\| {\bf y} \| = 1\)

\sphinxAtStartPar
The Cauchy\sphinxhyphen{}Schwarz inequality yields
\begin{equation*}
\begin{split}
%
{\bf y}' {\bf x}
\leq |{\bf y}' {\bf x}|
\leq \| {\bf y} \| \| {\bf x} \|
= \| {\bf x} \|
= \frac{{\bf x}' {\bf x}}{ \| {\bf x} \| }
= {\hat{\bf x}}' {\bf x}
%
\end{split}
\end{equation*}
\sphinxAtStartPar
Hence \({\hat{\bf x}}\) is the maximizer, as claimed
\end{sphinxadmonition}


\subsection{Span}
\label{\detokenize{05.linear_algebra:span}}
\sphinxAtStartPar
Let \(X \subset \mathbb{R}^N\) be any nonempty set (of points in \(\mathbb{R}^N\), i.e. vectors)

\begin{sphinxadmonition}{note}{Definition}

\sphinxAtStartPar
Set of all possible linear combinations of elements of \(X\) is
called the \sphinxstyleemphasis{\sphinxstylestrong{span}} of \(X\), denoted by \(\mathrm{span}(X)\)
\end{sphinxadmonition}

\sphinxAtStartPar
For finite \(X := \{{\bf x}_1,\ldots, {\bf x}_K\}\) the span can be expressed
as
\begin{equation*}
\begin{split}
\mathrm{span}(X):= \left\{ \text{ all } \sum_{k=1}^K \alpha_k {\bf x}_k 
\text{ such that }
(\alpha_1,\ldots, \alpha_K) \in \mathbb{R}^K \right\}
\end{split}
\end{equation*}
\sphinxAtStartPar
We are mainly interested in the span of finite sets…

\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
Let’s start with the span of a singleton

\sphinxAtStartPar
Let \(X = \{ {\bf 1} \} \subset \mathbb{R}^2\), where \({\bf 1} := (1,1)\)

\sphinxAtStartPar
The span of \(X\) is all vectors of the form
\begin{equation*}
\begin{split}
%
\alpha {\bf 1} 
=
\left(
\begin{array}{c}
\alpha \\
\alpha
\end{array}
\right)
\quad \text{ with } \quad \alpha \in \mathbb{R} 
%
\end{split}
\end{equation*}
\sphinxAtStartPar
Constitutes a line in the plane that passes through
\begin{itemize}
\item {} 
\sphinxAtStartPar
the vector \({\bf 1}\) (set \(\alpha = 1\))

\item {} 
\sphinxAtStartPar
the origin \({\bf 0}\) (set \(\alpha = 0\))

\end{itemize}
\end{sphinxadmonition}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{span_of_one_vec}.png}
\caption{The span of \({\bf 1} := (1,1)\) in \(\mathbb{R}^2\)}\label{\detokenize{05.linear_algebra:id3}}\end{figure}

\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
Let \({\bf x}_1 = (3, 4, 2)\) and let \({\bf x}_2 = (3, -4, 0.4)\)

\sphinxAtStartPar
By definition, the span is all vectors of the form
\begin{equation*}
\begin{split}
%
{\bf y} = 
\alpha \left(
\begin{array}{c}
3 \\
4 \\
2
\end{array}
\right)
+
\beta \left(
\begin{array}{c}
3 \\
-4 \\
0.4
\end{array}
\right)
\quad \text{where} \quad
\alpha, \beta \in \mathbb{R}
%
\end{split}
\end{equation*}
\sphinxAtStartPar
It turns out to be a plane that passes through
\begin{itemize}
\item {} 
\sphinxAtStartPar
the vector \({\bf x}_1\)

\item {} 
\sphinxAtStartPar
the vector \({\bf x}_2\)

\item {} 
\sphinxAtStartPar
the origin \({\bf 0}\)

\end{itemize}
\end{sphinxadmonition}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{span_plane}.png}
\caption{Span of \({\bf x}_1, {\bf x}_2\)}\label{\detokenize{05.linear_algebra:f-span-plane}}\end{figure}

\begin{sphinxadmonition}{note}{Fact}

\sphinxAtStartPar
If \(X \subset Y\), then \(\mathrm{span}(X) \subset \mathrm{span}(Y)\)
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Proof}

\sphinxAtStartPar
Pick any nonempty \(X \subset Y \subset \mathbb{R}^N\)

\sphinxAtStartPar
Letting \({\bf z} \in \mathrm{span}(X)\), we have
\begin{equation*}
\begin{split}
%
{\bf z} = \sum_{k=1}^K \alpha_k {\bf x}_k 
\text{ for some }
{\bf x}_1, \ldots, {\bf x}_K \in X, \; 
\alpha_1, \ldots, \alpha_K \in \mathbb{R}
%
\end{split}
\end{equation*}
\sphinxAtStartPar
Since \(X \subset Y\), each \({\bf x}_k\) is also in \(Y\), giving us
\begin{equation*}
\begin{split}
%
{\bf z} = \sum_{k=1}^K \alpha_k {\bf x}_k 
\text{ for some }
{\bf x}_1, \ldots, {\bf x}_K \in Y, \; 
\alpha_1, \ldots, \alpha_K \in \mathbb{R}
%
\end{split}
\end{equation*}
\sphinxAtStartPar
Hence \({\bf z} \in \mathrm{span}(Y)\)
\end{sphinxadmonition}

\sphinxAtStartPar
Let \(Y\) be any subset of \(\mathbb{R}^N\), and let \(X:= \{{\bf x}_1,\ldots, {\bf x}_K\}\)

\sphinxAtStartPar
If \(Y \subset \mathrm{span}(X)\), we say that the vectors in \(X\) \sphinxstyleemphasis{\sphinxstylestrong{span the set}} \(Y\)

\sphinxAtStartPar
Alternatively, we say that \(X\) is a \sphinxstyleemphasis{\sphinxstylestrong{spanning set}} for \(Y\)

\sphinxAtStartPar
A nice situation: \(Y\) is large but \(X\) is small

\sphinxAtStartPar
\(\implies\) large set \(Y\) ``described’’ by the small number of vectors in \(X\)

\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
Consider the vectors \(\{{\bf e}_1, \ldots, {\bf e}_N\} \subset \mathbb{R}^N\), where
\begin{equation*}
\begin{split}
%
{\bf e}_1 := 
\left(
\begin{array}{c}
1 \\
0 \\
\vdots \\
0
\end{array}
\right),
\quad 
{\bf e}_2 := 
\left(
\begin{array}{c}
0 \\
1 \\
\vdots \\
0
\end{array}
\right),
\; 
\cdots,
\;
{\bf e}_N := 
\left(
\begin{array}{c}
0 \\
0 \\
\vdots \\
1
\end{array}
\right)
%
\end{split}
\end{equation*}
\sphinxAtStartPar
That is, \({\bf e}_n\) has all zeros except for a \(1\) as the \(n\)\sphinxhyphen{}th element
\end{sphinxadmonition}

\sphinxAtStartPar
Vectors \({\bf e}_1, \ldots, {\bf e}_N\) are called the \sphinxstyleemphasis{\sphinxstylestrong{canonical basis vectors}} of \(\mathbb{R}^N\)

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{vec_canon}.png}
\caption{Canonical basis vectors in \(\mathbb{R}^2\)}\label{\detokenize{05.linear_algebra:f-vec-canon}}\end{figure}

\begin{sphinxadmonition}{note}{Fact}

\sphinxAtStartPar
The span of \(\{{\bf e}_1, \ldots, {\bf e}_N\}\) is equal to all of \(\mathbb{R}^N\)
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Proof}

\sphinxAtStartPar
Proof for \(N=2\):

\sphinxAtStartPar
Pick any \({\bf y} \in \mathbb{R}^2\)

\sphinxAtStartPar
We have
\begin{equation*}
\begin{split}
%
{\bf y} 
:=
\left(
\begin{array}{c}
y_1 \\
y_2
\end{array}
\right)
=
\left(
\begin{array}{c}
y_1 \\
0
\end{array}
\right)
+
\left(
\begin{array}{c}
0 \\
y_1
\end{array}
\right)
\\
=
y_1
\left(
\begin{array}{c}
1 \\
0
\end{array}
\right)
+
y_2
\left(
\begin{array}{c}
0 \\
1
\end{array}
\right)
= y_1 {\bf e}_1 + y_2 {\bf e}_2
%
\end{split}
\end{equation*}
\sphinxAtStartPar
Thus, \({\bf y} \in \mathrm{span} \{{\bf e}_1, {\bf e}_2\}\)

\sphinxAtStartPar
Since \({\bf y}\) arbitrary, we have shown that \(\mathrm{span} \{{\bf e}_1,
{\bf e}_2\} = \mathbb{R}^2\)
\end{sphinxadmonition}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{vec_canon_x}.png}
\caption{Canonical basis vectors in \(\mathbb{R}^2\)}\label{\detokenize{05.linear_algebra:f-vec-canon2}}\end{figure}

\begin{sphinxadmonition}{note}{Fact}

\sphinxAtStartPar
Consider the set
\begin{equation*}
\begin{split}
%
P := \{ (x_1, x_2, 0) \in \mathbb{R}^3 \colon x_1, x_2 \in \mathbb{R \}}
%
\end{split}
\end{equation*}
\sphinxAtStartPar
Let \({\bf e}_1\) and \({\bf e}_2\) be the canonical basis vectors in \(\mathbb{R}^3\)

\sphinxAtStartPar
Then
\(\mathrm{span}\{{\bf e}_1, {\bf e}_2\} = P\)
\end{sphinxadmonition}

\sphinxAtStartPar
Graphically, \(P =\) flat plane in \(\mathbb{R}^3\), where height coordinate \(x_3=0\)

\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics{{flat_plane_no_vecs}.png}
\end{figure}

\begin{sphinxadmonition}{note}{Proof}

\sphinxAtStartPar
Let \({\bf x} = (x_1, x_2, 0)\) be any element of \(P\)

\sphinxAtStartPar
We can write \({\bf x}\) as
\begin{equation*}
\begin{split}
%
{\bf x} = 
\left(
\begin{array}{c}
x_1 \\
x_2 \\
0
\end{array}
\right)
=
x_1
\left(
\begin{array}{c}
1 \\
0 \\
0
\end{array}
\right)
+ 
x_2
\left(
\begin{array}{c}
0 \\
1 \\
0
\end{array}
\right)
= x_1 {\bf e}_1 + x_2 {\bf e}_2
%
\end{split}
\end{equation*}
\sphinxAtStartPar
In other words, \(P \subset \mathrm{span}\{{\bf e}_1, {\bf e}_2\}\)

\sphinxAtStartPar
Conversely (check it) we have \(\mathrm{span}\{{\bf e}_1, {\bf e}_2\} \subset P\)
\end{sphinxadmonition}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{flat_plane_e_vecs}.png}
\caption{\(\mathrm{span}\{{\bf e}_1, {\bf e}_2\} = P\)}\label{\detokenize{05.linear_algebra:id4}}\end{figure}


\section{Linear Subspaces}
\label{\detokenize{05.linear_algebra:linear-subspaces}}
\begin{sphinxadmonition}{note}{Definition}

\sphinxAtStartPar
A nonempty \(S \subset \mathbb{R}^N\) called a \sphinxstyleemphasis{\sphinxstylestrong{linear
subspace}} of \(\mathbb{R}^N\) if
\begin{equation*}
\begin{split}
%
{\bf x}, {\bf y} \in S \; \text{ and } \;\alpha, \beta \in \mathbb{R}
\quad \implies \quad
\alpha {\bf x} + \beta {\bf y} \in S 
%
\end{split}
\end{equation*}\end{sphinxadmonition}

\sphinxAtStartPar
In other words, \(S \subset \mathbb{R}^N\) is “closed” under vector addition
and scalar multiplication

\sphinxAtStartPar
Note: Sometimes we just say \sphinxstyleemphasis{\sphinxstylestrong{subspace}} and drop “linear”

\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
\(\mathbb{R}^N\) itself is a linear subspace of \(\mathbb{R}^N\)
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Fact}

\sphinxAtStartPar
Fix \({\bf a} \in \mathbb{R}^N\) and let \(A := \{ {\bf x} \in \mathbb{R}^N \colon {\bf a }'{\bf x} = 0 \}\)

\sphinxAtStartPar
The set \(A\) is a linear subspace of \(\mathbb{R}^N\)
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Proof}

\sphinxAtStartPar
Let \({\bf x}, {\bf y} \in A\) and let \(\alpha, \beta \in \mathbb{R}\)

\sphinxAtStartPar
We must show that \({\bf z} := \alpha {\bf x} + \beta {\bf y} \in A\)

\sphinxAtStartPar
Equivalently, that \({\bf a}' {\bf z} = 0\)

\sphinxAtStartPar
True because
\begin{equation*}
\begin{split}
%
{\bf a}' {\bf z} =
{\bf a}' (\alpha {\bf x} + \beta {\bf y}) = \alpha
{\bf a}' {\bf x} + \beta {\bf a}' {\bf y} = 0 + 0 = 0
%
\end{split}
\end{equation*}\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Fact}

\sphinxAtStartPar
If \(Z\) is a nonempty subset of \(\mathbb{R}^N\), then \(\mathrm{span}(Z)\) is a linear subspace
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Proof}

\sphinxAtStartPar
If \({\bf x}, {\bf y} \in \mathrm{span}(Z)\), then \(\exists\) vectors \({\bf z}_k\) in \(Z\)
and scalars \(\gamma_k\) and \(\delta_k\) such that
\begin{equation*}
\begin{split}
{\bf x} = \sum_{k=1}^K \gamma_k {\bf z}_k
\quad \text{and} \quad
{\bf y} = \sum_{k=1}^K \delta_k {\bf z}_k
\end{split}
\end{equation*}\begin{equation*}
\begin{split}
\implies
\alpha {\bf x} = \sum_{k=1}^K \alpha \gamma_k {\bf z}_k
\quad \text{and} \quad
\beta {\bf y} = \sum_{k=1}^K \beta \delta_k {\bf z}_k 
\end{split}
\end{equation*}\begin{equation*}
\begin{split}
\implies
\alpha {\bf x} + \beta {\bf y} 
= \sum_{k=1}^K (\alpha \gamma_k + \beta \delta_k) {\bf z}_k 
\end{split}
\end{equation*}
\sphinxAtStartPar
This vector clearly lies in \(\mathrm{span}(Z)\)
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Fact}

\sphinxAtStartPar
If \(S\) and \(S'\) are two linear subspaces of \(\mathbb{R}^N\), then \(S \cap S'\) is also a linear subspace of \(\mathbb{R}^N\).
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Proof}

\sphinxAtStartPar
Let \(S\) and \(S'\) be two linear subspaces of \(\mathbb{R}^N\)

\sphinxAtStartPar
Fix \({\bf x}, {\bf y} \in S \cap S'\) and \(\alpha, \beta \in \mathbb{R}\)

\sphinxAtStartPar
We claim that \({\bf z} := \alpha {\bf x} + \beta {\bf y} \in S \cap S'\)
\begin{itemize}
\item {} 
\sphinxAtStartPar
Since \({\bf x}, {\bf y} \in S\) and \(S\) is a linear subspace we have \({\bf z} \in S\)

\item {} 
\sphinxAtStartPar
Since \({\bf x}, {\bf y} \in S'\) and \(S'\) is a linear subspace we have \({\bf z} \in S'\)

\end{itemize}

\sphinxAtStartPar
Therefore \({\bf z} \in S \cap S'\)
\end{sphinxadmonition}

\sphinxAtStartPar
Other examples of linear subspaces
\begin{itemize}
\item {} 
\sphinxAtStartPar
The singleton \(\{{\bf 0}\}\) in \(\mathbb{R}^N\)

\item {} 
\sphinxAtStartPar
Lines through the origin in \(\mathbb{R}^2\) and \(\mathbb{R}^3\)

\item {} 
\sphinxAtStartPar
Planes through the origin in \(\mathbb{R}^3\)

\end{itemize}

\sphinxAtStartPar
\sphinxstylestrong{Exercise:} Let \(S\) be a linear subspace of \(\mathbb{R}^N\). Show that
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
\({\bf 0} \in S\)

\item {} 
\sphinxAtStartPar
If \(X \subset S\), then \(\mathrm{span}(X) \subset S\)

\item {} 
\sphinxAtStartPar
\(\mathrm{span}(S) = S\)

\end{enumerate}


\subsection{Linear Independence}
\label{\detokenize{05.linear_algebra:linear-independence}}
\sphinxAtStartPar
Important applied questions
\begin{itemize}
\item {} 
\sphinxAtStartPar
When does a set of linear equations have a solution?

\item {} 
\sphinxAtStartPar
When is that solution unique?

\item {} 
\sphinxAtStartPar
When do regression arguments suffer from collinearity?

\item {} 
\sphinxAtStartPar
How can we approximate complex functions parsimoniously?

\item {} 
\sphinxAtStartPar
What is the rank of a matrix?

\item {} 
\sphinxAtStartPar
When is a matrix invertible?

\end{itemize}

\sphinxAtStartPar
All of these questions closely related to linear independence

\begin{sphinxadmonition}{note}{Definition}

\sphinxAtStartPar
A nonempty collection of vectors \(X := \{{\bf x}_1,\ldots, {\bf x}_K\}
\subset \mathbb{R}^N\) is called \sphinxstyleemphasis{\sphinxstylestrong{linearly independent}} if
\begin{equation*}
\begin{split}
%
\sum_{k=1}^K \alpha_k {\bf x}_k
= {\bf 0} 
\; \implies \;
\alpha_1 = \cdots = \alpha_K = 0
%
\end{split}
\end{equation*}\end{sphinxadmonition}

\sphinxAtStartPar
As we’ll see, linear independence of a set of vectors determines how large
a space they span

\sphinxAtStartPar
Loosely speaking, linearly independent sets span large spaces

\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
Let \({\bf x} := (1, 2)\) and \({\bf y} := (-5, 3)\)

\sphinxAtStartPar
The set \(X = \{{\bf x}, {\bf y}\}\) is linearly independent in \(\mathbb{R}^2\)

\sphinxAtStartPar
Indeed, suppose \(\alpha_1\) and \(\alpha_2\) are scalars with
\begin{equation*}
\begin{split}
%
\alpha_1
\left(
\begin{array}{c}
1 \\
2
\end{array}
\right)
+ 
\alpha_2
\left(
\begin{array}{c}
-5 \\
3
\end{array}
\right)
=
{\bf 0}
%
\end{split}
\end{equation*}
\sphinxAtStartPar
Equivalently,
\begin{equation*}
\begin{split}
%
\alpha_1 = 5 \alpha_2
\\
2 \alpha_1 = -3 \alpha_2
%
\end{split}
\end{equation*}
\sphinxAtStartPar
Then \(2(5\alpha_2) = 10 \alpha_2 = -3 \alpha_2\), implying \(\alpha_2 = 0\)
and hence \(\alpha_1 = 0\)
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
The set of canonical basis vectors \(\{{\bf e}_1, \ldots, {\bf e}_N\}\)
is linearly independent in \(\mathbb{R}^N\)
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Proof}

\sphinxAtStartPar
Let \(\alpha_1, \ldots, \alpha_N\) be coefficients such that
\(\sum_{k=1}^N \alpha_k {\bf e}_k = {\bf 0}\)

\sphinxAtStartPar
Then
\begin{equation*}
\begin{split}
%
\left(
\begin{array}{c}
\alpha_1 \\
\alpha_2 \\
\vdots \\
\alpha_N
\end{array}
\right)
= \sum_{k=1}^N \alpha_k {\bf e}_k 
= {\bf 0}
=
\left(
\begin{array}{c}
0 \\
0 \\
\vdots \\
0
\end{array}
\right)
%
\end{split}
\end{equation*}
\sphinxAtStartPar
In particular, \(\alpha_k = 0\) for all \(k\)

\sphinxAtStartPar
Hence \(\{{\bf e}_1, \ldots, {\bf e}_N\}\) linearly independent
\end{sphinxadmonition}

\sphinxAtStartPar
As a first step to better understanding linear independence let’s look at some equivalences

\begin{sphinxadmonition}{note}{Fact}

\sphinxAtStartPar
Take \(X := \{{\bf x}_1,\ldots, {\bf x}_K\} \subset \mathbb{R}^N\).
For \(K > 1\) all of following statements are equivalent
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
\(X\) is linearly independent

\item {} 
\sphinxAtStartPar
No \({\bf x}_i \in X\) can be written as linear combination of the others

\item {} 
\sphinxAtStartPar
\(X_0 \subsetneq X \implies \mathrm{span}(X_0) \subsetneq \mathrm{span}(X)\)

\end{enumerate}
\end{sphinxadmonition}
\begin{itemize}
\item {} 
\sphinxAtStartPar
Here \(X_0 \subsetneq X\) means \(X_0 \subset X\) and \(X_0 \ne X\)

\item {} 
\sphinxAtStartPar
We say that \(X_0\) is a \sphinxstyleemphasis{\sphinxstylestrong{proper subset}} of \(X\)

\end{itemize}

\sphinxAtStartPar
As an exercise, let’s show that the first two statements are equivalent, first
\begin{equation}\label{equation:05.linear_algebra:eq:cli}
\begin{split}
\sum_{k=1}^K \alpha_k {\bf x}_k
= {\bf 0} 
\; \implies \;
\alpha_1 = \cdots = \alpha_K = 0
\end{split}
\end{equation}
\sphinxAtStartPar
and the second
\begin{equation}\label{equation:05.linear_algebra:eq:cli2}
\begin{split}
\text{no ${\bf x}_i \in X$ can be written as linear combination of others}
\end{split}
\end{equation}
\sphinxAtStartPar
We now show that
\begin{itemize}
\item {} 
\sphinxAtStartPar
\eqref{equation:05.linear_algebra:eq:cli} \(\implies\) \eqref{equation:05.linear_algebra:eq:cli2}, and

\item {} 
\sphinxAtStartPar
\eqref{equation:05.linear_algebra:eq:cli2} \(\implies\) \eqref{equation:05.linear_algebra:eq:cli}

\end{itemize}

\sphinxAtStartPar
To show that \eqref{equation:05.linear_algebra:eq:cli} \(\implies\) \eqref{equation:05.linear_algebra:eq:cli2} let’s suppose to the contrary that
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
\(\sum_{k=1}^K \alpha_k {\bf x}_k = {\bf 0} \implies \alpha_1 = \cdots = \alpha_K = 0\)

\item {} 
\sphinxAtStartPar
and yet some \({\bf x}_i\) can be written as a linear combination of the other elements of \(X\)

\end{enumerate}

\sphinxAtStartPar
In particular, suppose that
\begin{equation*}
\begin{split}
%
{\bf x}_i = \sum_{k \ne i} \alpha_k {\bf x}_k 
%
\end{split}
\end{equation*}
\sphinxAtStartPar
Then, rearranging,
\begin{equation*}
\begin{split}
%
\alpha_1 {\bf x}_1 + \cdots + (-1) {\bf x}_i 
+ \cdots + \alpha_K {\bf x}_K = {\bf 0}
%
\end{split}
\end{equation*}
\sphinxAtStartPar
This contradicts 1., and hence \eqref{equation:05.linear_algebra:eq:cli2} holds

\sphinxAtStartPar
To show that \eqref{equation:05.linear_algebra:eq:cli2} \(\implies\) \eqref{equation:05.linear_algebra:eq:cli} let’s suppose to
the contrary that
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
no \({\bf x}_i\) can be written as a linear combination of others

\item {} 
\sphinxAtStartPar
and yet \(\exists\) \(\alpha_1, \ldots, \alpha_K\) not all zero with \(\alpha_1 {\bf x}_1 + \cdots + \alpha_K {\bf x}_K = {\bf 0}\)

\end{enumerate}

\sphinxAtStartPar
Suppose without loss of generality that \(\alpha_1 \ne 0\)
(similar argument works for any \(\alpha_j\))

\sphinxAtStartPar
Then
\begin{equation*}
\begin{split}
%
{\bf x}_1 = \frac{\alpha_2}{-\alpha_1} {\bf x}_2 
+ \cdots + \frac{\alpha_K}{-\alpha_1} {\bf x}_K 
%
\end{split}
\end{equation*}
\sphinxAtStartPar
This contradicts 1., and hence \eqref{equation:05.linear_algebra:eq:cli} holds.

\sphinxAtStartPar
Let’s show one more part of the proof as an exercise:
\begin{equation*}
\begin{split}
%
X \text{ linearly independent } 
\implies
\text{ proper subsets of $X$ have smaller span}
%
\end{split}
\end{equation*}
\begin{sphinxadmonition}{note}{Proof}

\sphinxAtStartPar
Suppose to the contrary that
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
\(X\) is linearly independent,

\end{enumerate}
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(X_0 \subsetneq X\) and yet

\end{itemize}
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\setcounter{enumi}{8}
\item {} 
\sphinxAtStartPar
\(\mathrm{span}(X_0) = \mathrm{span}(X)\)

\end{enumerate}

\sphinxAtStartPar
Let \({\bf x}_j\) be in \(X\) but not \(X_0\)

\sphinxAtStartPar
Since \({\bf x}_j \in \mathrm{span}(X)\), we also have \({\bf x}_j \in \mathrm{span}(X_0)\)

\sphinxAtStartPar
But then \({\bf x}_j\) can be written as a linear combination of the other elements of \(X\)

\sphinxAtStartPar
This contradicts linear independence
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
Dropping any of the canonical basis vectors reduces span
\end{sphinxadmonition}

\sphinxAtStartPar
Consider the \(N=2\) case

\sphinxAtStartPar
We know that \(\mathrm{span} \{{\bf e}_1, {\bf e}_2\} =\) all of \(\mathbb{R}^2\)

\sphinxAtStartPar
Removing either element of \(\mathrm{span} \{{\bf e}_1, {\bf e}_2\}\) reduces the span to a line

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{vec_h_axis}.png}
\caption{The span of \(\{{\bf e}_1\}\) alone is the horizonal axis}\label{\detokenize{05.linear_algebra:f-vec-h-axis}}\end{figure}

\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
As another visual example of linear independence, consider the pair
\end{sphinxadmonition}
\begin{equation*}
\begin{split}
%
{\bf x}_1 =
\begin{pmatrix}
3 \\
4 \\
2
\end{pmatrix}
\quad \text{and} \quad
{\bf x}_2 =
\begin{pmatrix}
3 \\
-4 \\
1
\end{pmatrix}
%
\end{split}
\end{equation*}
\sphinxAtStartPar
The span of this pair is a plane in \(\mathbb{R}^3\)

\sphinxAtStartPar
But if we drop either one the span reduces to a line

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{nonredundant1}.png}
\caption{The span of \(\{{\bf x}_1, {\bf x}_2\}\) is a plane}\label{\detokenize{05.linear_algebra:id5}}\end{figure}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{nonredundant2}.png}
\caption{The span of \(\{{\bf x}_1\}\) alone is a line}\label{\detokenize{05.linear_algebra:id6}}\end{figure}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{nonredundant3}.png}
\caption{The span of \(\{{\bf x}_2\}\) alone is a line}\label{\detokenize{05.linear_algebra:id7}}\end{figure}


\subsection{Linear Dependence}
\label{\detokenize{05.linear_algebra:linear-dependence}}
\begin{sphinxadmonition}{note}{Definition}

\sphinxAtStartPar
If \(X\) is not linearly independent then it is called \sphinxstyleemphasis{\sphinxstylestrong{linearly dependent}}
\end{sphinxadmonition}

\sphinxAtStartPar
We saw above that: linear independence \(\iff\) dropping any elements reduces span.

\sphinxAtStartPar
Hence \(X\) is linearly dependent when some
elements can be removed without changing \(\mathrm{span}(X)\)

\sphinxAtStartPar
That is,
\(\exists \, X_0 \subsetneq X \; \text{ such that } \; \mathrm{span}(X_0) = \mathrm{span}(X)\)

\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
As an example with redundacy, consider \(\{{\bf x}_1, {\bf x}_2\} \subset \mathbb{R}^2\) where
\begin{itemize}
\item {} 
\sphinxAtStartPar
\({\bf x}_1 = {\bf e}_1 := (1, 0)\)

\item {} 
\sphinxAtStartPar
\({\bf x}_2 = (-2, 0)\)

\end{itemize}

\sphinxAtStartPar
We claim that \(\mathrm{span} \{{\bf x}_1, {\bf x}_2\} = \mathrm{span}\{{\bf x}_1\}\)
\end{sphinxadmonition}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{vec_noncanon}.png}
\caption{The vectors \({\bf x}_1\) and \({\bf x}_2\)}\label{\detokenize{05.linear_algebra:f-vec-noncanon}}\end{figure}

\begin{sphinxadmonition}{note}{Proof}

\sphinxAtStartPar
\(\mathrm{span} \{{\bf x}_1\} \subset \mathrm{span}\{{\bf x}_1, {\bf x}_2\}\) is clear (why?)

\sphinxAtStartPar
To see the reverse, pick any \({\bf y} \in \mathrm{span} \{{\bf x}_1, {\bf x}_2\}\)

\sphinxAtStartPar
By definition,
\begin{equation*}
\begin{split}
%
\exists \;
\alpha_1,\alpha_2 \; \text{ such that } \;
{\bf y} 
= \alpha_1 {\bf x}_1 + \alpha_2 {\bf x}_2
=
\alpha_1 
\begin{pmatrix}
1 \\
0
\end{pmatrix}
+ \alpha_2 
\begin{pmatrix}
-2 \\
0
\end{pmatrix}
%
\end{split}
\end{equation*}\begin{equation*}
\begin{split}
%
\implies
{\bf y} 
= \alpha_1 
\begin{pmatrix}
1 \\
0
\end{pmatrix}
- 2 \alpha_2 
\begin{pmatrix}
1 \\
0
\end{pmatrix}
= (\alpha_1 - 2 \alpha_2)
\begin{pmatrix}
1 \\
0
\end{pmatrix}
= (\alpha_1 -2 \alpha_2 ) {\bf x}_1 
%
\end{split}
\end{equation*}
\sphinxAtStartPar
The right hand side is clearly in \(\mathrm{span} \{{\bf x}_1\}\)

\sphinxAtStartPar
Hence \(\mathrm{span} \{{\bf x}_1, {\bf x}_2\} \subset \mathrm{span} \{{\bf x}_1\}\) as claimed
\end{sphinxadmonition}


\subsection{Implications of Independence}
\label{\detokenize{05.linear_algebra:implications-of-independence}}
\sphinxAtStartPar
Let \(X := \{{\bf x}_1,\ldots, {\bf x}_K\} \subset \mathbb{R}^N\)

\begin{sphinxadmonition}{note}{Fact}

\sphinxAtStartPar
If \(X\) is linearly independent, then \(X\) does not contain \({\bf 0}\)
\end{sphinxadmonition}

\sphinxAtStartPar
\sphinxstylestrong{Exercise:} Prove it

\begin{sphinxadmonition}{note}{Fact}

\sphinxAtStartPar
If \(X\) is linearly independent, then every subset of \(X\) is linearly independent
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Proof}

\sphinxAtStartPar
Sketch of proof: Suppose for example that \(\{{\bf x}_1,\ldots,
{\bf x}_{K-1}\} \subset X\) is linearly dependent

\sphinxAtStartPar
Then \(\exists \; \alpha_1, \ldots, \alpha_{K-1}\) not all zero with
\(\sum_{k=1}^{K-1} \alpha_k {\bf x}_k = {\bf 0}\)

\sphinxAtStartPar
Setting \(\alpha_K =0\) we can write this as \(\sum_{k=1}^K \alpha_k {\bf x}_k = {\bf 0}\)

\sphinxAtStartPar
Not all scalars zero so contradicts linear independence of \(X\)
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Fact}

\sphinxAtStartPar
If \(X:= \{{\bf x}_1,\ldots, {\bf x}_K\} \subset \mathbb{R}^N\) is linearly independent and \({\bf z}\) is an \(N\)\sphinxhyphen{}vector not in \(\mathrm{span}(X)\), then \(X \cup \{ {\bf z} \}\) is linearly independent
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Proof}

\sphinxAtStartPar
Suppose to the contrary that \(X \cup \{ {\bf z} \}\) is linearly
dependent:
\begin{equation}\label{equation:05.linear_algebra:eq:m}
\begin{split}
%
\exists \; \alpha_1, \ldots, \alpha_K, \beta
\text{ not all zero with }
\sum_{k=1}^K \alpha_k {\bf x}_k + \beta {\bf z} = {\bf 0}
%
\end{split}
\end{equation}
\sphinxAtStartPar
If \(\beta=0\), then by \eqref{equation:05.linear_algebra:eq:m} we have \(\sum_{k=1}^K \alpha_k {\bf x}_k = {\bf 0}\) and
\(\alpha_k \ne 0\) for some \(k\), a contradiction

\sphinxAtStartPar
If \(\beta \ne0\), then by \eqref{equation:05.linear_algebra:eq:m} we have
\begin{equation*}
\begin{split}
%
{\bf z} = \sum_{k=1}^K \frac{-\alpha_k}{\beta} {\bf x}_k 
%
\end{split}
\end{equation*}
\sphinxAtStartPar
Hence \({\bf z} \in \mathrm{span}(X)\) — contradiction
\end{sphinxadmonition}


\subsection{Unique Representations}
\label{\detokenize{05.linear_algebra:unique-representations}}
\sphinxAtStartPar
Let
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(X := \{{\bf x}_1,\ldots,{\bf x}_K\} \subset \mathbb{R}^N\)

\item {} 
\sphinxAtStartPar
\({\bf y} \in \mathbb{R}^N\)

\end{itemize}

\sphinxAtStartPar
We know that if \({\bf y} \in \mathrm{span}(X)\), then exists representation
\begin{equation*}
\begin{split}
%
{\bf y} = \sum_{k=1}^K \alpha_k {\bf x}_k
%
\end{split}
\end{equation*}
\sphinxAtStartPar
But when is this representation unique?

\sphinxAtStartPar
Answer: When \(X\) is linearly independent

\begin{sphinxadmonition}{note}{Fact}

\sphinxAtStartPar
If \(X = \{{\bf x}_1,\ldots, {\bf x}_K\} \subset \mathbb{R}^N\) is linearly independent and
\({\bf y} \in \mathbb{R}^N\), then there is at most one set of scalars \(\alpha_1,\ldots,\alpha_K\) such
that \({\bf y} = \sum_{k=1}^K \alpha_k {\bf x}_k\)
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Proof}

\sphinxAtStartPar
Suppose there are two such sets of scalars

\sphinxAtStartPar
That is,
\begin{equation*}
\begin{split}
%
\exists \;
\alpha_1, \ldots, \alpha_K
\text{ and } \beta_1, \ldots, \beta_K
\; \text{ such that } \; 
{\bf y} 
= \sum_{k=1}^K \alpha_k {\bf x}_k
= \sum_{k=1}^K \beta_k {\bf x}_k
%
\end{split}
\end{equation*}\begin{equation*}
\begin{split}
%
\implies \sum_{k=1}^K (\alpha_k - \beta_k) {\bf x}_k = {\bf 0}
%
\end{split}
\end{equation*}\begin{equation*}
\begin{split}
%
\implies
\alpha_k = \beta_k 
\quad \text{for all} \quad k
%
\end{split}
\end{equation*}\end{sphinxadmonition}


\subsection{Span and Independence}
\label{\detokenize{05.linear_algebra:span-and-independence}}
\sphinxAtStartPar
Here’s one of the most fundamental results in linear algebra

\begin{sphinxadmonition}{note}{Exchange Lemma}

\sphinxAtStartPar
Let \(S\) be a linear subspace of \(\mathbb{R}^N\), and be spanned by \(K\) vectors. \\
Then any linearly independent subset of \(S\) has at most \(K\)
vectors
\end{sphinxadmonition}

\sphinxAtStartPar
Proof: Omitted

\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
If \(X := \{{\bf x}_1, {\bf x}_2, {\bf x}_3\} \subset \mathbb{R}^2\),
then \(X\) is linearly dependent
\begin{itemize}
\item {} 
\sphinxAtStartPar
because \(\mathbb{R}^2\) is spanned by the two vectors \({\bf e}_1, {\bf e}_2\)

\end{itemize}
\end{sphinxadmonition}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{vecs}.png}
\caption{Must be linearly dependent}\label{\detokenize{05.linear_algebra:id8}}\end{figure}

\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
Recall the plane (flat plane in \(\mathbb{R}^3\) where height coordinate \(x_3\) is zero)
\begin{equation*}
\begin{split}
P := \{ (x_1, x_2, 0) \in \mathbb{R}^3 \colon x_1, x_2 \in \mathbb{R \}}
\end{split}
\end{equation*}
\sphinxAtStartPar
We showed before that \(\mathrm{span}\{{\bf e}_1, {\bf e}_2\} = P\) for
\begin{equation*}
\begin{split}
%
{\bf e}_1 := 
\left(
\begin{array}{c}
1 \\
0 \\
0
\end{array}
\right),
\quad 
{\bf e}_2 := 
\left(
\begin{array}{c}
0 \\
1 \\
0
\end{array}
\right)
%
\end{split}
\end{equation*}
\sphinxAtStartPar
Therefore any three vectors lying in \(P\) are linearly dependent
\end{sphinxadmonition}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{flat_plane}.png}
\caption{Any three vectors in \(P\) are linearly dependent}\label{\detokenize{05.linear_algebra:id9}}\end{figure}


\subsection{When Do \protect\(N\protect\) Vectors Span \protect\(\mathbb{R}^N\protect\)?}
\label{\detokenize{05.linear_algebra:when-do-n-vectors-span-mathbb-r-n}}
\sphinxAtStartPar
In general, linearly independent vectors have a relatively “large” span
\begin{itemize}
\item {} 
\sphinxAtStartPar
No vector is redundant, so each contributes to the span

\end{itemize}

\sphinxAtStartPar
This helps explain the following fact:

\begin{sphinxadmonition}{note}{Fact}

\sphinxAtStartPar
Let \(X := \{ {\bf x}_1, \ldots, {\bf x}_N \}\) be any \(N\) vectors in \(\mathbb{R}^N\)

\sphinxAtStartPar
\(\mathrm{span}(X) = \mathbb{R}^N\) if and only if \(X\) is linearly independent
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
The vectors \({\bf x} = (1, 2)\) and \({\bf y} = (-5, 3)\) span \(\mathbb{R}^2\)
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Proof}

\sphinxAtStartPar
Let prove that

\sphinxAtStartPar
\(X= \{ {\bf x}_1, \ldots, {\bf x}_N \}\) linearly independent \(\implies\) \(\mathrm{span}(X) = \mathbb{R}^N\)

\sphinxAtStartPar
Seeking a contradiction, suppose that
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
\(X \) is linearly independent

\item {} 
\sphinxAtStartPar
and yet \(\exists \, {\bf z} \in \mathbb{R}^N\) with \({\bf z} \notin \mathrm{span}(X)\)

\end{enumerate}

\sphinxAtStartPar
But then \(X \cup \{{\bf z}\} \subset \mathbb{R}^N\) is linearly independent (why?)

\sphinxAtStartPar
This set has \(N+1\) elements

\sphinxAtStartPar
And yet \(\mathbb{R}^N\) is spanned by the \(N\) canonical basis vectors

\sphinxAtStartPar
Contradiction (of what?)

\sphinxAtStartPar
Next let’s show the converse

\sphinxAtStartPar
\(\mathrm{span}(X) = \mathbb{R}^N\)
\(\implies\)
\(X= \{ {\bf x}_1, \ldots, {\bf x}_N \}\) linearly independent

\sphinxAtStartPar
Seeking a contradiction, suppose that
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
\(\mathrm{span}(X) = \mathbb{R}^N\)

\item {} 
\sphinxAtStartPar
and yet \(X\) is linearly dependent

\end{enumerate}

\sphinxAtStartPar
Since \(X\) not independent, \(\exists X_0 \subsetneq X\) with \(\mathrm{span}(X_0) =
\mathrm{span}(X)\)

\sphinxAtStartPar
But by 1 this implies that \(\mathbb{R}^N\) is spanned by \(K < N\) vectors

\sphinxAtStartPar
But then the \(N\) canonical basis vectors must be linearly dependent

\sphinxAtStartPar
Contradiction
\end{sphinxadmonition}


\subsection{Bases}
\label{\detokenize{05.linear_algebra:bases}}
\begin{sphinxadmonition}{note}{Definition}

\sphinxAtStartPar
Let \(S\) be a linear subspace of \(\mathbb{R}^N\)

\sphinxAtStartPar
A set of vectors \(B := \{{\bf b}_1, \ldots, {\bf b}_K\} \subset S\) is
called a \sphinxstyleemphasis{\sphinxstylestrong{basis of \(S\)}} if
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
\(B\) is linearly independent

\item {} 
\sphinxAtStartPar
\(\mathrm{span}(B) = S\)

\end{enumerate}
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
Canonical basis vectors form a basis of \(\mathbb{R}^N\)
\end{sphinxadmonition}

\sphinxAtStartPar
Indeed, if \(E := \{{\bf e}_1, \ldots, {\bf e}_N\} \subset \mathbb{R}^N\), then
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(E\) is linearly independent – we showed this earlier

\item {} 
\sphinxAtStartPar
\(\mathrm{span}(E) = \mathbb{R}^N\) – we showed this earlier

\end{itemize}

\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
Recall the plane
\begin{equation*}
\begin{split}
%
P := \{ (x_1, x_2, 0) \in \mathbb{R}^3 \colon x_1, x_2 \in \mathbb{R \}}
%
\end{split}
\end{equation*}
\sphinxAtStartPar
We showed before that \(\mathrm{span}\{{\bf e}_1, {\bf e}_2\} = P\) for
\begin{equation*}
\begin{split}
%
{\bf e}_1 := 
\left(
\begin{array}{c}
1 \\
0 \\
0
\end{array}
\right),
\quad 
{\bf e}_2 := 
\left(
\begin{array}{c}
0 \\
1 \\
0
\end{array}
\right)
%
\end{split}
\end{equation*}
\sphinxAtStartPar
Moreover, \(\{{\bf e}_1, {\bf e}_2\}\) is linearly independent (why?)

\sphinxAtStartPar
Hence \(\{{\bf e}_1, {\bf e}_2\}\) is a basis for \(P\)
\end{sphinxadmonition}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{flat_plane_e_vecs}.png}
\caption{The pair \(\{{\bf e}_1, {\bf e}_2\}\) form a basis for \(P\)}\label{\detokenize{05.linear_algebra:id10}}\end{figure}

\sphinxAtStartPar
What are the implications of \(B\) being a basis of \(S\)?

\sphinxAtStartPar
In short, every element of \(S\) can be represented uniquely from the
smaller set \(B\)

\sphinxAtStartPar
In more detail:
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(B\) spans \(S\) and, by linear independence, every element is needed to span \(S\) — a “minimal” spanning set

\item {} 
\sphinxAtStartPar
Since \(B\) spans \(S\), every \({\bf y}\) in \(S\) can be represented as
a linear combination of the basis vectors

\item {} 
\sphinxAtStartPar
By independence, this representation is unique

\end{itemize}

\sphinxAtStartPar
It’s obvious given the definition that

\begin{sphinxadmonition}{note}{Fact}

\sphinxAtStartPar
If \(B \subset \mathbb{R}^N\) is linearly independent, then \(B\) is a basis of \(\mathrm{span}(B)\)
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
Let \(B := \{{\bf x}_1, {\bf x}_2\}\) where
\begin{equation*}
\begin{split}
%
{\bf x}_1 =
\begin{pmatrix}
3 \\
4 \\
2
\end{pmatrix}
\quad \text{and} \quad
{\bf x}_2 =
\begin{pmatrix}
3 \\
-4 \\
1
\end{pmatrix}
%
\end{split}
\end{equation*}\end{sphinxadmonition}

\sphinxAtStartPar
We saw earlier that
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(S := \mathrm{span}(B)\) is the plane in \(\mathbb{R}^3\) passing through
\({\bf x}_1\), \({\bf x}_2\) and \({\bf 0}\)

\item {} 
\sphinxAtStartPar
\(B\) is linearly independent in \(\mathbb{R}^3\) (dropping either reduces span)

\end{itemize}

\sphinxAtStartPar
Hence \(B\) is a basis for the plane \(S\)

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{nonredundant1}.png}
\caption{The pair \(\{{\bf x}_1, {\bf x}_2\}\) is a basis of its span}\label{\detokenize{05.linear_algebra:id11}}\end{figure}


\subsection{Fundamental Properties of Bases}
\label{\detokenize{05.linear_algebra:fundamental-properties-of-bases}}
\begin{sphinxadmonition}{note}{Fact}

\sphinxAtStartPar
If \(S\) is a linear subspace of \(\mathbb{R}^N\) distinct from \(\{{\bf 0}\}\), then
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
\(S\) has at least one basis, and

\item {} 
\sphinxAtStartPar
every basis of \(S\) has the same number of elements

\end{enumerate}
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Proof}

\sphinxAtStartPar
Proof of part 2: Let \(B_i\) be a basis of \(S\) with \(K_i\) elements, \(i=1, 2\)

\sphinxAtStartPar
By definition, \(B_2\) is a linearly independent subset of \(S\)

\sphinxAtStartPar
Moreover, \(S\) is spanned by the set \(B_1\), which has \(K_1\) elements

\sphinxAtStartPar
Hence \(K_2 \leq K_1\)

\sphinxAtStartPar
Reversing the roles of \(B_1\) and \(B_2\) gives \(K_1 \leq K_2\)
\end{sphinxadmonition}


\subsection{Dimension}
\label{\detokenize{05.linear_algebra:dimension}}
\begin{sphinxadmonition}{note}{Definition}

\sphinxAtStartPar
Let \(S\) be a linear subspace of \(\mathbb{R}^N\)

\sphinxAtStartPar
We now know that every basis of \(S\) has the same number of elements

\sphinxAtStartPar
This common number is called the \sphinxstyleemphasis{\sphinxstylestrong{dimension}} of \(S\)
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
\(\mathbb{R}^N\) is \(N\) dimensional because the \(N\) canonical basis vectors form a basis
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
\(P := \{ (x_1, x_2, 0) \in \mathbb{R}^3 \colon x_1, x_2 \in \mathbb{R \}}\) is
two dimensional because the first two canonical basis vectors of \(\mathbb{R}^3\) form a basis
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
In \(\mathbb{R}^3\), a line through the origin is one\sphinxhyphen{}dimensional, while a plane through the origin is two\sphinxhyphen{}dimensional
\end{sphinxadmonition}


\subsection{Dimension of Spans}
\label{\detokenize{05.linear_algebra:dimension-of-spans}}
\begin{sphinxadmonition}{note}{Fact}

\sphinxAtStartPar
Let \(X := \{{\bf x}_1,\ldots,{\bf x}_K\} \subset \mathbb{R}^N\)

\sphinxAtStartPar
The following statements are true:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
\(\mathrm{dim}(\mathrm{span}(X)) \leq K\)

\item {} 
\sphinxAtStartPar
\(\mathrm{dim}(\mathrm{span}(X)) = K\) \(\;\iff\;\) \(X\) is linearly independent

\end{enumerate}
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Proof}

\sphinxAtStartPar
Proof that \(\mathrm{dim}(\mathrm{span}(X)) \leq K\)

\sphinxAtStartPar
If not then \(\mathrm{span}(X)\) has a basis with \(M > K\) elements

\sphinxAtStartPar
Hence \(\mathrm{span}(X)\) contains \(M > K\) linearly independent vectors

\sphinxAtStartPar
This is impossible, given that \(\mathrm{span}(X)\) is spanned by \(K\) vectors

\sphinxAtStartPar
Now consider the second claim:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
\(X\) is linearly independent \(\implies\) \(\dim(\mathrm{span}(X)) = K\)

\end{enumerate}

\sphinxAtStartPar
Proof: True because the vectors \({\bf x}_1,\ldots,{\bf x}_K\) form
a basis of \(\mathrm{span}(X)\)
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\setcounter{enumi}{1}
\item {} 
\sphinxAtStartPar
\(\mathrm{dim}(\mathrm{span}(X)) = K\) \(\implies\) \(X\) linearly independent

\end{enumerate}

\sphinxAtStartPar
Proof: If not then \(\exists \, X_0 \subsetneq X\) such that \(\mathrm{span}(X_0) = \mathrm{span}(X)\)

\sphinxAtStartPar
By this equality and part 1 of the theorem,
\begin{equation*}
\begin{split}\dim(\mathrm{span}(X)) = \dim(\mathrm{span}(X_0)) \leq \# X_0 \leq K - 1\end{split}
\end{equation*}
\sphinxAtStartPar
Contradiction
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Fact}

\sphinxAtStartPar
If \(S\) a linear subspace of \(\mathbb{R}^N\), then
\begin{equation*}
\begin{split}
%
\dim(S) = N \; \iff \; S = \mathbb{R}^N
%
\end{split}
\end{equation*}\end{sphinxadmonition}

\sphinxAtStartPar
Useful implications
\begin{itemize}
\item {} 
\sphinxAtStartPar
The only \(N\)\sphinxhyphen{}dimensional subspace of \(\mathbb{R}^N\) is \(\mathbb{R}^N\)

\item {} 
\sphinxAtStartPar
To show \(S = \mathbb{R}^N\) just need to show that \(\dim(S) = N\)

\end{itemize}

\sphinxAtStartPar
Proof: omitted


\section{Linear Maps}
\label{\detokenize{05.linear_algebra:linear-maps}}
\sphinxAtStartPar
In this section we investigate one of the most important classes of functions: so\sphinxhyphen{}called linear functions
\begin{itemize}
\item {} 
\sphinxAtStartPar
Linear functions play a fundamental role in all fields of science

\item {} 
\sphinxAtStartPar
Linear functions are in one\sphinxhyphen{}to\sphinxhyphen{}one correspondence with matrices

\item {} 
\sphinxAtStartPar
Even nonlinear functions can often be rewritten as partially linear

\item {} 
\sphinxAtStartPar
The properties of linear functions are closely tied to notions such as
\begin{itemize}
\item {} 
\sphinxAtStartPar
linear combinations, span

\item {} 
\sphinxAtStartPar
linear independence, bases, etc.

\end{itemize}

\end{itemize}

\begin{sphinxadmonition}{note}{Definition}

\sphinxAtStartPar
A function \(T \colon \mathbb{R}^K \to \mathbb{R}^N\) is called
\sphinxstyleemphasis{\sphinxstylestrong{linear}} if
\begin{equation*}
\begin{split}
%
T(\alpha {\bf x} + \beta {\bf y}) = \alpha T{\bf x} + \beta T{\bf y}
\qquad
\forall \, 
{\bf x}, {\bf y} \in \mathbb{R}^K, \;
\forall \,
\alpha, \beta \in \mathbb{R}
%
\end{split}
\end{equation*}\end{sphinxadmonition}

\sphinxAtStartPar
Notation:
\begin{itemize}
\item {} 
\sphinxAtStartPar
Linear functions often written with upper case letters

\item {} 
\sphinxAtStartPar
Typically omit parenthesis around arguments when convenient

\end{itemize}

\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
\(T \colon \mathbb{R} \to \mathbb{R}\) defined by \(Tx = 2x\) is linear
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Proof}

\sphinxAtStartPar
Take any \(\alpha, \beta, x, y\) in \(\mathbb{R}\) and observe that
\begin{equation*}
\begin{split}
%
T(\alpha x + \beta y)
= 2(\alpha x + \beta y)
= \alpha 2 x + \beta 2 y
= \alpha Tx + \beta Ty 
%
\end{split}
\end{equation*}\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
The function \(f \colon \mathbb{R} \to \mathbb{R}\) defined by \(f(x) = x^2\) is
\sphinxstyleemphasis{\sphinxstylestrong{non}}linear
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Proof}

\sphinxAtStartPar
Set \(\alpha = \beta = x = y = 1\)

\sphinxAtStartPar
Then
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(f(\alpha x + \beta y) = f(2) = 4\)

\item {} 
\sphinxAtStartPar
But \(\alpha f(x) + \beta f(y) = 1 + 1 = 2\)

\end{itemize}
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
Given constants \(c_1\) and \(c_2\), the
function \(T \colon \mathbb{R}^2 \to \mathbb{R}\) defined by
\begin{equation*}
\begin{split}
%
T {\bf x} = T (x_1, x_2) = c_1 x_1 + c_2 x_2 
%
\end{split}
\end{equation*}
\sphinxAtStartPar
is linear
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Proof}

\sphinxAtStartPar
If we take any \(\alpha, \beta\) in \(\mathbb{R}\) and
\({\bf x}, {\bf y}\) in \(\mathbb{R}^2\), then
\begin{equation*}
\begin{split}
%
T(\alpha {\bf x} + \beta {\bf y})
= c_1 [\alpha x_1 + \beta y_1] + c_2 [\alpha x_2 + \beta y_2]
\\
= \alpha [c_1 x_1 + c_2 x_2] + \beta [c_1 y_1 + c_2 y_2]
\\
= \alpha T {\bf x} + \beta T {\bf y} 
%
\end{split}
\end{equation*}\end{sphinxadmonition}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{linfunc}.png}
\caption{The graph of \(T {\bf x} = c_1 x_1 + c_2 x_2\) is a plane
through the origin}\label{\detokenize{05.linear_algebra:id12}}\end{figure}

\sphinxAtStartPar
Remark: Thinking of linear functions as those whose graph is a straight
line is not correct

\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
Function \(f \colon \mathbb{R} \to \mathbb{R}\) defined by \(f(x) = 1 + 2x\) is \sphinxstyleemphasis{\sphinxstylestrong{nonlinear}}
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Proof}

\sphinxAtStartPar
Take \(\alpha = \beta = x = y = 1\)

\sphinxAtStartPar
Then
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(f(\alpha x + \beta y) = f(2) = 5\)

\item {} 
\sphinxAtStartPar
But \(\alpha f(x) + \beta f(y) = 3 + 3 = 6\)

\end{itemize}
\end{sphinxadmonition}

\sphinxAtStartPar
This kind of function is called an \sphinxstyleemphasis{\sphinxstylestrong{affine}} function

\sphinxAtStartPar
Let \({\bf a}_1, \ldots, {\bf a}_K\) be vectors in \(\mathbb{R}^N\)

\sphinxAtStartPar
Let \(T \colon \mathbb{R}^K \to \mathbb{R}^N\) be defined by
\begin{equation*}
\begin{split}
%
T{\bf x} 
=
T
\begin{pmatrix}
x_1 \\
\vdots \\
x_K
\end{pmatrix}
=
x_1 {\bf a}_1 + \ldots + x_K {\bf a}_K
%
\end{split}
\end{equation*}
\sphinxAtStartPar
\sphinxstylestrong{Exercise:} Show that this function is linear

\sphinxAtStartPar
Remarks
\begin{itemize}
\item {} 
\sphinxAtStartPar
This is a generalization of the previous linear examples

\item {} 
\sphinxAtStartPar
In a sense it is the most general representation of a linear map
from \(\mathbb{R}^K\) to \(\mathbb{R}^N\)

\item {} 
\sphinxAtStartPar
It is also “the same” as the \(N \times K\) matrix with
columns \({\bf a}_1, \ldots, {\bf a}_K\) — more on this later

\end{itemize}


\subsection{Implications of Linearity}
\label{\detokenize{05.linear_algebra:implications-of-linearity}}
\begin{sphinxadmonition}{note}{Fact}

\sphinxAtStartPar
If \(T \colon \mathbb{R}^K \to \mathbb{R}^N\) is a linear map and \({\bf x}_1,\ldots, {\bf x}_J\) are vectors in \(\mathbb{R}^K\), then for any linear combination we have
\begin{equation*}
\begin{split}
T
\left[ \alpha_1 {\bf x}_1 + \cdots + \alpha_J {\bf x}_J \right]
= \alpha_1 T {\bf x}_1 + \cdots + \alpha_J T {\bf x}_J
\end{split}
\end{equation*}\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Proof}

\sphinxAtStartPar
Proof for \(J=3\): Applying the def of linearity twice,
\begin{equation*}
\begin{split}
%
T
\left[ \alpha_1 {\bf x}_1 + \alpha_2 {\bf x}_2 + \alpha_3 {\bf x}_3 \right]
= T\left[ (\alpha_1 {\bf x}_1 + \alpha_2 {\bf x}_2) + \alpha_3 {\bf x}_3 \right]
\\
= T\left[ \alpha_1 {\bf x}_1 + \alpha_2 {\bf x}_2 \right] + \alpha_3 T {\bf x}_3 
\\
= \alpha_1 T {\bf x}_1 + \alpha_2 T {\bf x}_2 + \alpha_3 T {\bf x}_3 
%
\end{split}
\end{equation*}\end{sphinxadmonition}

\sphinxAtStartPar
\sphinxstylestrong{Exercise:} Show that if \(T\) is any linear function then \(T{\bf 0} = {\bf 0}\)

\begin{sphinxadmonition}{note}{Fact}

\sphinxAtStartPar
If \(T \colon \mathbb{R}^K \to \mathbb{R}^N\) is a linear map, then
\begin{equation*}
\begin{split}
%
\mathrm{rng}(T) = \mathrm{span}(V) 
\quad \text{where} \quad
V := \{T{\bf e}_1, \ldots, T{\bf e}_K\}
%
\end{split}
\end{equation*}
\sphinxAtStartPar
Here \({\bf e}_k\) is the \(k\)\sphinxhyphen{}th canonical basis vector in \(\mathbb{R}^K\)
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Proof}

\sphinxAtStartPar
Any \({\bf x} \in \mathbb{R}^K\) can be expressed as \(\sum_{k=1}^K \alpha_k {\bf e}_k\)

\sphinxAtStartPar
Hence \(\mathrm{rng}(T)\) is the set of all points of the form
\begin{equation*}
\begin{split}
%
T{\bf x}
= T \left[ \sum_{k=1}^K \alpha_k {\bf e}_k \right]
= \sum_{k=1}^K \alpha_k T {\bf e}_k 
%
\end{split}
\end{equation*}
\sphinxAtStartPar
as we vary \(\alpha_1, \ldots, \alpha_K\) over all combinations

\sphinxAtStartPar
This coincides with the definition of \(\mathrm{span}(V)\)
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
Let \(T \colon \mathbb{R}^2 \to \mathbb{R}^2\) be defined by
\begin{equation*}
\begin{split}
%
T{\bf x} 
=
T(x_1, x_2)
=
x_1 
\begin{pmatrix}
1 \\
2
\end{pmatrix}
+
x_2 
\begin{pmatrix}
0 \\
-2
\end{pmatrix}
%
\end{split}
\end{equation*}
\sphinxAtStartPar
Then
\begin{equation*}
\begin{split}
%
T{\bf e}_1
=
\begin{pmatrix}
1 \\
2
\end{pmatrix}
\quad \text{and} \quad
T{\bf e}_2
=
\begin{pmatrix}
0 \\
-2
\end{pmatrix}
%
\end{split}
\end{equation*}
\sphinxAtStartPar
\sphinxstylestrong{Exercise:} Show that \(V := \{T{\bf e}_1, T{\bf e}_2\}\) is linearly independent

\sphinxAtStartPar
We conclude that the range of \(T\) is all of \(\mathbb{R}^2\) (why?)
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Definition}

\sphinxAtStartPar
The \sphinxstyleemphasis{\sphinxstylestrong{null space}} or \sphinxstyleemphasis{\sphinxstylestrong{kernel}} of linear map \(T \colon \mathbb{R}^K \to
\mathbb{R}^N\) is
\begin{equation*}
\begin{split}
%
\mathrm{kernel}(T) := \{ {\bf x} \in \mathbb{R}^K \colon T{\bf x} = {\bf 0}\}
%
\end{split}
\end{equation*}\end{sphinxadmonition}

\sphinxAtStartPar
\sphinxstylestrong{Exercise:} Show that \(\mathrm{kernel}(T)\) is a linear subspace of \(\mathbb{R}^K\)

\begin{sphinxadmonition}{note}{Fact}

\sphinxAtStartPar
\(\mathrm{kernel}(T) = \{{\bf 0}\}\) if and only if \(T\) is one\sphinxhyphen{}to\sphinxhyphen{}one
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Proof}

\sphinxAtStartPar
Proof of \(\implies\):

\sphinxAtStartPar
Suppose that \(T{\bf x} = T{\bf y}\) for arbitrary \({\bf x}, {\bf y} \in \mathbb{R}^K\)

\sphinxAtStartPar
Then \({\bf 0} = T{\bf x} - T{\bf y} = T({\bf x} - {\bf y})\)

\sphinxAtStartPar
In other words, \({\bf x} - {\bf y} \in \mathrm{kernel}(T)\)

\sphinxAtStartPar
Hence \(\mathrm{kernel}(T) = \{{\bf 0}\}\) \(\implies\) \({\bf x} = {\bf y}\)
\end{sphinxadmonition}


\subsection{Linearity and Bijections}
\label{\detokenize{05.linear_algebra:linearity-and-bijections}}
\sphinxAtStartPar
Recall that an arbitrary function can be
\begin{itemize}
\item {} 
\sphinxAtStartPar
one\sphinxhyphen{}to\sphinxhyphen{}one (injections)

\item {} 
\sphinxAtStartPar
onto (surjections)

\item {} 
\sphinxAtStartPar
both (bijections)

\item {} 
\sphinxAtStartPar
neither

\end{itemize}

\sphinxAtStartPar
For linear functions from \(\mathbb{R}^N\) to \(\mathbb{R}^N\), the first three are all
equivalent!

\sphinxAtStartPar
In particular,
\begin{equation*}
\begin{split}
%
\text{onto } \iff \text{ one-to-one } \iff \text{ bijection}
%
\end{split}
\end{equation*}
\begin{sphinxadmonition}{note}{Fact}

\sphinxAtStartPar
If \(T\) is a linear function from \(\mathbb{R}^N\) to \(\mathbb{R}^N\) then all of the following are equivalent:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
\(T\) is a bijection

\item {} 
\sphinxAtStartPar
\(T\) is onto/surjective

\item {} 
\sphinxAtStartPar
\(T\) is one\sphinxhyphen{}to\sphinxhyphen{}one/injective

\item {} 
\sphinxAtStartPar
\(\mathrm{kernel}(T) = \{ {\bf 0} \}\)

\item {} 
\sphinxAtStartPar
The set of vectors \(V := \{T{\bf e}_1, \ldots, T{\bf e}_N\}\) is linearly independent

\end{enumerate}
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Definition}

\sphinxAtStartPar
If any one of the above equivalent conditions is true, then \(T\) is called \sphinxstyleemphasis{\sphinxstylestrong{nonsingular}}
\end{sphinxadmonition}
\begin{itemize}
\item {} 
\sphinxAtStartPar
Don’t forget: We are talking about \(\mathbb{R}^N\) to \(\mathbb{R}^N\) here

\end{itemize}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{linbijec}.png}
\caption{The case of \(N=1\), nonsingular and singular}\label{\detokenize{05.linear_algebra:id13}}\end{figure}

\sphinxAtStartPar
Proof that \(T\) onto \(\iff\) \(V := \{T{\bf e}_1, \ldots, T{\bf e}_N\}\) is
linearly independent

\sphinxAtStartPar
Recall that for any linear map \(T\) we have \(\mathrm{rng}(T) = \mathrm{span}(V)\)

\sphinxAtStartPar
Using this fact and the definitions,
\begin{equation*}
\begin{split}
%
T \text{ is onto/surjective } 
\iff \mathrm{rng}(T) = \mathbb{R}^N
\\
\iff \mathrm{span}(V) = \mathbb{R}^N
\\
\iff V \text{ is linearly indepenent}
%
\end{split}
\end{equation*}
\sphinxAtStartPar
(We saw that \(N\) vectors span \(\mathbb{R}^N\) iff linearly indepenent)

\sphinxAtStartPar
\sphinxstyleemphasis{\sphinxstylestrong{Exercise:}} rest of proof

\begin{sphinxadmonition}{note}{Fact}

\sphinxAtStartPar
If \(T \colon \mathbb{R}^N \to \mathbb{R}^N\) is nonsingular then so is \(T^{-1}\).
\end{sphinxadmonition}

\sphinxAtStartPar
What is the implication here?

\sphinxAtStartPar
If \(T\) is a bijection then so is \(T^{-1}\)

\sphinxAtStartPar
Hence the only real claim is that \(T^{-1}\) is also linear

\sphinxAtStartPar
\sphinxstyleemphasis{\sphinxstylestrong{Exercise:}} prove this statement


\subsection{Maps Across Different Dimensions}
\label{\detokenize{05.linear_algebra:maps-across-different-dimensions}}
\sphinxAtStartPar
Remember that the above results apply to maps from \(\mathbb{R}^N\) to \(\mathbb{R}^N\)

\sphinxAtStartPar
Things change when we look at linear maps across dimensions

\sphinxAtStartPar
The general rules for linear maps are
\begin{itemize}
\item {} 
\sphinxAtStartPar
Maps from lower to higher dimensions cannot be onto

\item {} 
\sphinxAtStartPar
Maps from higher to lower dimensions cannot be one\sphinxhyphen{}to\sphinxhyphen{}one

\item {} 
\sphinxAtStartPar
In either case they cannot be bijections

\end{itemize}

\begin{sphinxadmonition}{note}{Fact}

\sphinxAtStartPar
For a linear map \(T\) from \(\mathbb{R}^K \to \mathbb{R}^N\), the following statements are true:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
If \(K < N\) then \(T\) is not onto

\item {} 
\sphinxAtStartPar
If \(K > N\) then \(T\) is not one\sphinxhyphen{}to\sphinxhyphen{}one

\end{enumerate}
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Proof}

\sphinxAtStartPar
Proof of part 1: Let \(K < N\) and let \(T \colon \mathbb{R}^K \to \mathbb{R}^N\) be linear

\sphinxAtStartPar
Letting \(V := \{T{\bf e}_1, \ldots, T{\bf e}_K\}\), we have
\begin{equation*}
\begin{split}
%
\dim(\mathrm{rng}(T)) = \dim(\mathrm{span}(V)) \leq K < N
%
\end{split}
\end{equation*}\begin{equation*}
\begin{split}
%
\implies 
\mathrm{rng}(T) \ne \mathbb{R}^N
%
\end{split}
\end{equation*}
\sphinxAtStartPar
Hence \(T\) is not onto

\sphinxAtStartPar
Proof of part 2: \(K > N\) \(\implies\) \(T\) is not one\sphinxhyphen{}to\sphinxhyphen{}one

\sphinxAtStartPar
Suppose to the contrary that \(T\) is one\sphinxhyphen{}to\sphinxhyphen{}one

\sphinxAtStartPar
Let \(\alpha_1, \ldots, \alpha_K\) be a collection of vectors such that
\begin{equation*}
\begin{split}
%
\alpha_1 T {\bf e}_1 + \cdots + \alpha_K T {\bf e}_K = {\bf 0}
%
\end{split}
\end{equation*}\begin{equation*}
\begin{split}
%
\implies 
T (\alpha_1 {\bf e}_1 + \cdots + \alpha_K {\bf e}_K) = {\bf 0}
\qquad (\text{by linearity})
%
\end{split}
\end{equation*}\begin{equation*}
\begin{split}
%
\implies
\alpha_1 {\bf e}_1 + \cdots + \alpha_K {\bf e}_K = {\bf 0}
\qquad (\text{since $\ker(T) = \{{\bf 0}\}$})
%
\end{split}
\end{equation*}\begin{equation*}
\begin{split}
%
\implies 
\alpha_1 = \cdots = \alpha_K = 0
\qquad (\text{by independence of $\{{\bf e}_1, \ldots {\bf e}_K\}$)}
%
\end{split}
\end{equation*}
\sphinxAtStartPar
We have shown that \(\{T{\bf e}_1, \ldots, T{\bf e}_K\}\) is linearly
independent

\sphinxAtStartPar
But then \(\mathbb{R}^N\) contains a linearly independent set
with \(K > N\) vectors — contradiction
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
Cost function \(c(k, \ell) = rk + w\ell\) cannot be one\sphinxhyphen{}to\sphinxhyphen{}one
\end{sphinxadmonition}

\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics{{cost_min_2}.png}
\end{figure}


\section{Matrices and Linear Equations}
\label{\detokenize{05.linear_algebra:matrices-and-linear-equations}}
\sphinxAtStartPar
As we’ll see, there’s an isomorphic relationship between
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
matrices

\item {} 
\sphinxAtStartPar
linear maps

\end{enumerate}

\sphinxAtStartPar
Often properties of matrices are best understood via those of linear maps


\bigskip\hrule\bigskip


\sphinxAtStartPar
Typical \sphinxstyleemphasis{\sphinxstylestrong{\(N \times K\) matrix}}:
\begin{equation*}
\begin{split}
%
{\bf A} = 
\left(
\begin{array}{cccc}
a_{11} & a_{12} & \cdots & a_{1K} \\
a_{21} & a_{22} & \cdots & a_{2K} \\
\vdots & \vdots & & \vdots \\
a_{N1} & a_{N2} & \cdots & a_{NK} 
\end{array}
\right)
%
\end{split}
\end{equation*}
\sphinxAtStartPar
Symbol \(a_{ij}\) stands for element in the
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(n\)\sphinxhyphen{}th row

\item {} 
\sphinxAtStartPar
\(j\)\sphinxhyphen{}th column

\end{itemize}

\sphinxAtStartPar
Matrices correspond to coefficients of a linear equation
\begin{equation*}
\begin{split}
%
\begin{array}{c}
a_{11} x_1 + a_{12} x_2 + \cdots + a_{1K} x_K = b_1 \\
a_{21} x_1 + a_{22} x_2 + \cdots + a_{2K} x_K = b_2 \\
\vdots \\
a_{N1} x_1 + a_{N2} x_2 + \cdots + a_{NK} x_K = b_N 
\end{array}
%
\end{split}
\end{equation*}\begin{itemize}
\item {} 
\sphinxAtStartPar
Given the \(a_{ij}\) and \(b_i\), what values of \(x_1, \ldots, x_K\) solve this system?

\end{itemize}

\sphinxAtStartPar
We now investigate this and other related questions

\sphinxAtStartPar
But first some background on matrices…

\sphinxAtStartPar
An \(N \times K\) matrix also called a
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleemphasis{\sphinxstylestrong{row vector}} if \(N = 1\)

\item {} 
\sphinxAtStartPar
\sphinxstyleemphasis{\sphinxstylestrong{column vector}} if \(K = 1\)

\end{itemize}

\begin{sphinxadmonition}{note}{Example}
\begin{equation*}
\begin{split}
%
{\bf b} 
= 
\begin{pmatrix}
b_1 \\
\vdots \\
b_N 
\end{pmatrix}
\text{ is }\; N \times 1,
\qquad
{\bf c} 
= 
\begin{pmatrix}
c_1 \cdots c_K 
\end{pmatrix}
\text{ is }\; 
1 \times K
%
\end{split}
\end{equation*}\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Definition}

\sphinxAtStartPar
If \(N = K\), then \({\bf A}\) is called \sphinxstyleemphasis{\sphinxstylestrong{square}} matrix
\end{sphinxadmonition}

\sphinxAtStartPar
We use
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(\mathrm{col}_k({\bf A})\) to denote the \(k\)\sphinxhyphen{}th column of \({\bf A}\)

\item {} 
\sphinxAtStartPar
\(\mathrm{row}_n({\bf A})\) to denote the \(n\)\sphinxhyphen{}th row of \({\bf A}\)

\end{itemize}

\begin{sphinxadmonition}{note}{Example}
\begin{equation*}
\begin{split}
%
\mathrm{col}_1({\bf A})
=
\mathrm{col}_1
\left(
\begin{array}{ccc}
a_{11} & \cdots & a_{1K} \\
a_{21} & \cdots & a_{2K} \\
\vdots & \vdots & \vdots \\
a_{N1} & \cdots & a_{NK} 
\end{array}
\right)
=
\left(
\begin{array}{c}
a_{11} \\
a_{21} \\
\vdots \\
a_{N1} 
\end{array}
\right)
%
\end{split}
\end{equation*}\end{sphinxadmonition}

\sphinxAtStartPar
The \sphinxstyleemphasis{\sphinxstylestrong{zero matrix}} is
\begin{equation*}
\begin{split}
%
{\bf 0} := 
\left(
\begin{array}{cccc}
0 & 0 & \cdots & 0 \\
0 & 0 & \cdots & 0 \\
\vdots & \vdots & & \vdots \\
0 & 0 & \cdots & 0 \\
\end{array}
\right)
%
\end{split}
\end{equation*}
\sphinxAtStartPar
The \sphinxstyleemphasis{\sphinxstylestrong{identity matrix}} is
\begin{equation*}
\begin{split}
%
{\bf I} := 
\left(
\begin{array}{cccc}
1 & 0 & \cdots & 0 \\
0 & 1 & \cdots & 0 \\
\vdots & \vdots & & \vdots \\
0 & 0 & \cdots & 1 \\
\end{array}
\right)
%
\end{split}
\end{equation*}

\subsection{Algebraic Operations for Matrices}
\label{\detokenize{05.linear_algebra:algebraic-operations-for-matrices}}
\sphinxAtStartPar
Addition and scalar multiplication are also defined for matrices

\sphinxAtStartPar
Both are element by element, as in the vector case

\sphinxAtStartPar
Scalar multiplication:
\begin{equation*}
\begin{split}
%
\gamma 
\left(
\begin{array}{cccc}
a_{11} & a_{12} & \cdots & a_{1K} \\
a_{21} & a_{22} & \cdots & a_{2K} \\
\vdots & \vdots & & \vdots \\
a_{N1} & a_{N2} & \cdots & a_{NK} \\
\end{array}
\right)
:=
\left(
\begin{array}{cccc}
\gamma a_{11} & \gamma a_{12} & \cdots & \gamma a_{1K} \\
\gamma a_{21} & \gamma a_{22} & \cdots & \gamma a_{2K} \\
\vdots & \vdots & & \vdots \\
\gamma a_{N1} & \gamma a_{N2} & \cdots & \gamma a_{NK} \\
\end{array}
\right)
%
\end{split}
\end{equation*}
\sphinxAtStartPar
Addition:
\begin{equation*}
\begin{split}
%
\left(
\begin{array}{ccc}
a_{11} & \cdots & a_{1K} \\
a_{21} & \cdots & a_{2K} \\
\vdots & \vdots & \vdots \\
a_{N1} & \cdots & a_{NK} \\
\end{array}
\right)
+
\left(
\begin{array}{ccc}
b_{11} & \cdots & b_{1K} \\
b_{21} & \cdots & b_{2K} \\
\vdots & \vdots & \vdots \\
b_{N1} & \cdots & b_{NK} \\
\end{array}
\right)
\\
:=
\left(
\begin{array}{ccc}
a_{11} + b_{11} & \cdots & a_{1K} + b_{1K} \\
a_{21} + b_{21} & \cdots & a_{2K} + b_{2K} \\
\vdots & \vdots & \vdots \\
a_{N1} + b_{N1} & \cdots & a_{NK} + b_{NK} \\
\end{array}
\right)
%
\end{split}
\end{equation*}
\sphinxAtStartPar
\sphinxstyleemphasis{\sphinxstylestrong{Note:}} that matrices must be same dimension

\sphinxAtStartPar
\sphinxstylestrong{Multiplication of matrices}

\sphinxAtStartPar
Product \({\bf A} {\bf B}\):
\(i,j\)\sphinxhyphen{}th element is inner product of \(i\)\sphinxhyphen{}th row of \({\bf A}\) and
\(j\)\sphinxhyphen{}th column of \({\bf B}\)
\begin{equation*}
\begin{split}
%
\left(
\begin{array}{ccc}
a_{11} & \cdots & a_{1K} \\
a_{21} & \cdots & a_{2K} \\
\vdots & \vdots & \vdots \\
a_{N1} & \cdots & a_{NK} \\
\end{array}
\right)
\left(
\begin{array}{ccc}
b_{11} & \cdots & b_{1J} \\
b_{21} & \cdots & b_{2J} \\
\vdots & \vdots & \vdots \\
b_{K1} & \cdots & b_{KJ} \\
\end{array}
\right)
=
\left(
\begin{array}{ccc}
c_{11} & \cdots & c_{1J} \\
c_{21} & \cdots & c_{2J} \\
\vdots & \vdots & \vdots \\
c_{N1} & \cdots & c_{NJ} \\
\end{array}
\right)
%
\end{split}
\end{equation*}
\sphinxAtStartPar
In this display,
\begin{equation*}
\begin{split}
%
c_{11} = \sum_{k=1}^K a_{1k} b_{k1}
%
\end{split}
\end{equation*}
\sphinxAtStartPar
Suppose \({\bf A}\) is \(N \times K\) and \({\bf B}\) is \(J \times M\)
\begin{itemize}
\item {} 
\sphinxAtStartPar
\({\bf A} {\bf B}\) defined only if \(K = J\)

\item {} 
\sphinxAtStartPar
Resulting matrix \({\bf A} {\bf B}\) is \(N \times M\)

\end{itemize}

\begin{sphinxadmonition}{note}{The rule to remember}
\begin{equation*}
\begin{split}
%
\text{product of } N \times K \text{ and } K \times M
\text{ is } N \times M
%
\end{split}
\end{equation*}\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Fact}

\sphinxAtStartPar
Important: Multiplication is not commutative: it is not in general true that \({\bf A} {\bf B} = {\bf B} {\bf A}\)
\end{sphinxadmonition}
\begin{itemize}
\item {} 
\sphinxAtStartPar
In fact \({\bf B} {\bf A}\) is not well\sphinxhyphen{}defined unless \(N = M\) also holds

\end{itemize}


\subsubsection{Multiplication of matrix and a vector}
\label{\detokenize{05.linear_algebra:multiplication-of-matrix-and-a-vector}}\begin{equation*}
\begin{split}
%
{\bf A} {\bf x}
= 
\left(
\begin{array}{cccc}
a_{11} & a_{12} & \cdots & a_{1K} \\
a_{21} & a_{22} & \cdots & a_{2K} \\
\vdots & \vdots & & \vdots \\
a_{N1} & a_{N2} & \cdots & a_{NK} 
\end{array}
\right)
\left(
\begin{array}{c}
x_1 \\
x_2 \\
\vdots \\
x_K
\end{array}
\right)
\\
=
x_1 \left(
\begin{array}{c}
a_{11} \\
a_{21} \\
\vdots \\
a_{N1} 
\end{array}
\right)
+
x_2 \left(
\begin{array}{c}
a_{12} \\
a_{22} \\
\vdots \\
a_{N2} 
\end{array}
\right)
+ \cdots + 
x_K \left(
\begin{array}{c}
a_{1K} \\
a_{2K} \\
\vdots \\
a_{NK} 
\end{array}
\right)
\\
= 
\sum_{k=1}^K x_k \mathrm{col}_k({\bf A})
%
\end{split}
\end{equation*}

\subsubsection{Rules of matrix multiplication}
\label{\detokenize{05.linear_algebra:rules-of-matrix-multiplication}}
\begin{sphinxadmonition}{note}{Fact}

\sphinxAtStartPar
Given scalar \(\alpha\) and \sphinxstyleemphasis{conformable} \({\bf A}\), \({\bf B}\) and \({\bf C}\), we have
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
\({\bf A} ({\bf B} {\bf C}) = ({\bf A} {\bf B}) {\bf C}\)

\item {} 
\sphinxAtStartPar
\({\bf A} ({\bf B} + {\bf C}) = {\bf A} {\bf B} + {\bf A} {\bf C}\)

\item {} 
\sphinxAtStartPar
\(({\bf A} + {\bf B}) {\bf C} = {\bf A} {\bf C} + {\bf B} {\bf C}\)

\item {} 
\sphinxAtStartPar
\({\bf A} \alpha {\bf B} = \alpha {\bf A} {\bf B}\)

\end{enumerate}
\end{sphinxadmonition}

\sphinxAtStartPar
Here ``conformable’’ means operation makes sense

\begin{sphinxadmonition}{note}{Definition}

\sphinxAtStartPar
The \sphinxstyleemphasis{\sphinxstylestrong{\(k\)\sphinxhyphen{}th power}} of a \sphinxstylestrong{square} matrix \({\bf A}\) is
\begin{equation*}
\begin{split} {\bf A}^k := \underbrace{{\bf A} \cdots {\bf A}}_{k \text{ terms}} \end{split}
\end{equation*}\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Definition}

\sphinxAtStartPar
If it exists, the \sphinxstyleemphasis{\sphinxstylestrong{square root}} of \({\bf A}\) is written \({\bf A}^{1/2}\)
defined as the matrix \({\bf B}\) such that \({\bf B}^2\) is \({\bf A}\)
\end{sphinxadmonition}

\sphinxAtStartPar
In matrix multiplication, \({\bf I}\) is the multiplicative unit

\sphinxAtStartPar
That is, assuming conformability, we always have
\begin{equation*}
\begin{split}
%
{\bf A} {\bf I} = {\bf I} {\bf A} = {\bf A}
%
\end{split}
\end{equation*}
\sphinxAtStartPar
\sphinxstylestrong{Exercise:} Check it using the definition of matrix multiplication

\sphinxAtStartPar
If \({\bf I}\) is \(K \times K\), then
\begin{equation*}
\begin{split}
%
\mathrm{col}_k({\bf I})
= {\bf e}_k
= \text{ $k$-th canonical basis vector in } \mathbb{R}^K
%
\end{split}
\end{equation*}
\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{import} \PYG{n+nn}{numpy} \PYG{k}{as} \PYG{n+nn}{np}
\PYG{n}{A} \PYG{o}{=} \PYG{p}{[}\PYG{p}{[}\PYG{l+m+mi}{2}\PYG{p}{,} \PYG{l+m+mi}{4}\PYG{p}{]}\PYG{p}{,}
     \PYG{p}{[}\PYG{l+m+mi}{4}\PYG{p}{,} \PYG{l+m+mi}{2}\PYG{p}{]}\PYG{p}{]}
\PYG{n}{A} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{array}\PYG{p}{(}\PYG{n}{A}\PYG{p}{)} \PYG{c+c1}{\PYGZsh{} Convert A to array}
\PYG{n}{B} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{identity}\PYG{p}{(}\PYG{l+m+mi}{2}\PYG{p}{)}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{n}{A}\PYG{p}{,}\PYG{n}{B}\PYG{p}{)}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Sum:}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}\PYG{n}{A}\PYG{o}{+}\PYG{n}{B}\PYG{p}{)}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Product:}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}\PYG{n}{np}\PYG{o}{.}\PYG{n}{dot}\PYG{p}{(}\PYG{n}{A}\PYG{p}{,}\PYG{n}{B}\PYG{p}{)}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
[[2 4]
 [4 2]] [[1. 0.]
 [0. 1.]]
Sum: [[3. 4.]
 [4. 3.]]
Product: [[2. 4.]
 [4. 2.]]
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}

\subsection{Matrices as Maps}
\label{\detokenize{05.linear_algebra:matrices-as-maps}}
\sphinxAtStartPar
Any \(N \times K\) matrix \({\bf A}\) can be thought of as a function
\({\bf x} \mapsto {\bf A} {\bf x}\)
\begin{itemize}
\item {} 
\sphinxAtStartPar
In \({\bf A} {\bf x}\) the \({\bf x}\) is understood to be
a column vector

\end{itemize}

\sphinxAtStartPar
It turns out that every such map is linear!

\sphinxAtStartPar
To see this fix \(N \times K\) matrix \({\bf A}\) and let \(T\) be defined by
\begin{equation*}
\begin{split}
%
T \colon \mathbb{R}^K \to \mathbb{R}^N, 
\qquad
T{\bf x} = {\bf A} {\bf x}
%
\end{split}
\end{equation*}
\sphinxAtStartPar
Pick any \({\bf x}\), \({\bf y}\) in \(\mathbb{R}^K\), and any scalars \(\alpha\) and \(\beta\)

\sphinxAtStartPar
The rules of matrix arithmetic tell us that
\begin{equation*}
\begin{split}
%
T(\alpha {\bf x} + \beta {\bf y}) 
:= {\bf A} (\alpha {\bf x} + \beta {\bf y})
= \alpha {\bf A} {\bf x} + \beta {\bf A} {\bf y}
=: \alpha T{\bf x} + \beta T{\bf y} 
%
\end{split}
\end{equation*}
\sphinxAtStartPar
So matrices make linear functions

\sphinxAtStartPar
How about examples of linear functions that don’t involve matrices?

\sphinxAtStartPar
There are none!

\begin{sphinxadmonition}{note}{Fact}

\sphinxAtStartPar
If \(T \colon \mathbb{R}^K \to \mathbb{R}^N\) then
\begin{equation*}
\begin{split}
T \text{ is linear }
\; \iff \;
\exists \; N \times K \text{ matrix } {\bf A} \text{ such that } T{\bf x} = {\bf A} {\bf x}, 
\;\forall \, {\bf x} \in \mathbb{R}^K
\end{split}
\end{equation*}\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Proof}
\begin{itemize}
\item {} 
\sphinxAtStartPar
Just above we showed the \(\Longleftarrow\) part

\item {} 
\sphinxAtStartPar
Let’s show the \(\implies\) part

\end{itemize}

\sphinxAtStartPar
Let \(T \colon \mathbb{R}^K \to \mathbb{R}^N\) be linear

\sphinxAtStartPar
We aim to construct an \(N \times K\) matrix \({\bf A}\) such that
\begin{equation*}
\begin{split} T{\bf x} = {\bf A} {\bf x}, \qquad \forall \, {\bf x} \in \mathbb{R}^K \end{split}
\end{equation*}
\sphinxAtStartPar
As usual, let
\({\bf e}_k\) be the \(k\)\sphinxhyphen{}th canonical basis vector in \(\mathbb{R}^K\)

\sphinxAtStartPar
Define a matrix \({\bf A}\) by \(\mathrm{col}_k({\bf A}) = T{\bf e}_k\)

\sphinxAtStartPar
Pick any \({\bf x} = (x_1, \ldots, x_K) \in \mathbb{R}^K\)

\sphinxAtStartPar
By linearity we have
\begin{equation*}
\begin{split}
%
T{\bf x} 
= T \left[\sum_{k=1}^K x_k {\bf e}_k \right]
= \sum_{k=1}^K x_k T {\bf e}_k
= \sum_{k=1}^K x_k \mathrm{col}_k({\bf A})
= {\bf A} {\bf x}
%
\end{split}
\end{equation*}\end{sphinxadmonition}


\subsubsection{Matrix Product as Composition}
\label{\detokenize{05.linear_algebra:matrix-product-as-composition}}
\begin{sphinxadmonition}{note}{Fact}

\sphinxAtStartPar
Let
\begin{itemize}
\item {} 
\sphinxAtStartPar
\({\bf A}\) be \(N \times K\) and \({\bf B}\) be \(K \times M\)

\item {} 
\sphinxAtStartPar
\(T \colon \mathbb{R}^K \to \mathbb{R}^N\) be the linear map \(T{\bf x} = {\bf A}{\bf x}\)

\item {} 
\sphinxAtStartPar
\(U \colon \mathbb{R}^M \to \mathbb{R}^K\) be the linear map \(U{\bf x} = {\bf B}{\bf x}\)

\end{itemize}

\sphinxAtStartPar
The matrix product \({\bf A} {\bf B}\) corresponds exactly to the
\sphinxstyleemphasis{\sphinxstylestrong{composition}} of \(T\) and \(U\)
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Proof}
\begin{equation*}
\begin{split}
%
(T \circ U) ({\bf x})
= T( U{\bf x})
= T( {\bf B} {\bf x})
= {\bf A} {\bf B} {\bf x}
%
\end{split}
\end{equation*}\end{sphinxadmonition}

\sphinxAtStartPar
This helps us understand a few things

\sphinxAtStartPar
For example, let
\begin{itemize}
\item {} 
\sphinxAtStartPar
\({\bf A}\) be \(N \times K\) and \({\bf B}\) be \(J \times M\)

\item {} 
\sphinxAtStartPar
\(T \colon \mathbb{R}^K \to \mathbb{R}^N\) be the linear map \(T{\bf x} = {\bf A}{\bf x}\)

\item {} 
\sphinxAtStartPar
\(U \colon \mathbb{R}^M \to \mathbb{R}^J\) be the linear map \(U{\bf x} = {\bf B}{\bf x}\)

\end{itemize}

\sphinxAtStartPar
Then \({\bf A} {\bf B}\) is only defined when \(K = J\)

\sphinxAtStartPar
This is because \({\bf A} {\bf B}\) corresponds to \(T \circ U\)

\sphinxAtStartPar
But for \(T \circ U\) to be well defined we need \(K = J\)

\sphinxAtStartPar
Then \(U\) maps \(\mathbb{R}^M\) to \(\mathbb{R}^K\) and \(T\) maps \(\mathbb{R}^K\) to \(\mathbb{R}^N\)


\subsection{Column Space}
\label{\detokenize{05.linear_algebra:column-space}}
\begin{sphinxadmonition}{note}{Definition}

\sphinxAtStartPar
Let \({\bf A}\) be an \(N \times K\) matrix. \\
The \sphinxstyleemphasis{\sphinxstylestrong{column space}} of \({\bf A}\) is defined as the span of its columns
\begin{equation*}
\begin{split}
%
\mathrm{span}({\bf A}) 
= \mathrm{span} \{ \mathrm{col}_1 ({\bf A}), \ldots, \mathrm{col}_K({\bf A}) \}
\\
= \text{all vectors of the form } \sum_{k=1}^K x_k \mathrm{col}_k({\bf A})
%
\end{split}
\end{equation*}\end{sphinxadmonition}

\sphinxAtStartPar
Equivalently,
\begin{equation*}
\begin{split}
%
\mathrm{span}({\bf A}) := \{ {\bf A}{\bf x } \colon {\bf x} \in \mathbb{R}^K \}
%
\end{split}
\end{equation*}
\sphinxAtStartPar
This is exactly the range of the associated linear map

\sphinxAtStartPar
\(T \colon \mathbb{R}^K \to \mathbb{R}^N\) defined by \(T {\bf x} = {\bf A} {\bf x}\)

\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
If
\begin{equation*}
\begin{split}
%
{\bf A} =
\begin{pmatrix}
1 & -5 \\
2 & 3
\end{pmatrix}
%
\end{split}
\end{equation*}
\sphinxAtStartPar
then the span is all linear combinations
\begin{equation*}
\begin{split}
%
x_1
\left(
\begin{array}{c}
1 \\
2
\end{array}
\right)
+ 
x_2
\left(
\begin{array}{c}
-5 \\
3
\end{array}
\right)
\quad
\text{where}
\quad
(x_1, x_2) \in \mathbb{R}^2
%
\end{split}
\end{equation*}
\sphinxAtStartPar
These columns are linearly independent (shown earlier)

\sphinxAtStartPar
Hence the column space is all of \(\mathbb{R}^2\) (why?)
\end{sphinxadmonition}

\sphinxAtStartPar
\sphinxstylestrong{Exercise:} Show that the column space of any \(N \times K\) matrix is a linear
subspace of \(\mathbb{R}^N\)


\subsection{Rank}
\label{\detokenize{05.linear_algebra:rank}}
\sphinxAtStartPar
Equivalent questions
\begin{itemize}
\item {} 
\sphinxAtStartPar
How large is the range of the linear map \(T {\bf x} = {\bf A} {\bf x}\)?

\item {} 
\sphinxAtStartPar
How large is the column space of \({\bf A}\)?

\end{itemize}

\sphinxAtStartPar
The obvious measure of size for a linear subspace is its dimension

\begin{sphinxadmonition}{note}{Definition}

\sphinxAtStartPar
The dimension of \(\mathrm{span}({\bf A})\) is known as the \sphinxstyleemphasis{\sphinxstylestrong{rank}} of \({\bf A}\)
\begin{equation*}
\begin{split}
%
\mathrm{rank}({\bf A}) := \mathrm{dim}(\mathrm{span}({\bf A}))
%
\end{split}
\end{equation*}\end{sphinxadmonition}

\sphinxAtStartPar
Because \(\mathrm{span}({\bf A})\) is the span of \(K\) vectors, we have
\begin{equation*}
\begin{split}
%
\mathrm{rank}({\bf A}) = \mathrm{dim}(\mathrm{span}({\bf A})) \leq K
%
\end{split}
\end{equation*}
\begin{sphinxadmonition}{note}{Definition}

\sphinxAtStartPar
\({\bf A}\) is said to have \sphinxstyleemphasis{\sphinxstylestrong{full column rank}} if
\begin{equation*}
\begin{split}
%
\mathrm{rank}({\bf A}) = \text{ number of columns of } {\bf A}
%
\end{split}
\end{equation*}\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Fact}

\sphinxAtStartPar
For any matrix \({\bf A}\), the following statements are equivalent:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
\({\bf A}\) is of full column rank

\item {} 
\sphinxAtStartPar
The columns of \({\bf A}\) are linearly independent

\item {} 
\sphinxAtStartPar
If \({\bf A} {\bf x} = {\bf 0}\), then \({\bf x} = {\bf 0}\)

\end{enumerate}
\end{sphinxadmonition}

\sphinxAtStartPar
\sphinxstylestrong{Exercise:} Check this, recalling that
\begin{equation*}
\begin{split}
%
\dim(\mathrm{span}\{{\bf a}_1, \ldots, {\bf a}_K\}) = K
\, \iff \,
\{{\bf a}_1, \ldots, {\bf a}_K\} \text{ linearly indepenent}
%
\end{split}
\end{equation*}
\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{import} \PYG{n+nn}{numpy} \PYG{k}{as} \PYG{n+nn}{np}
\PYG{n}{A} \PYG{o}{=} \PYG{p}{[}\PYG{p}{[}\PYG{l+m+mf}{2.0}\PYG{p}{,} \PYG{l+m+mf}{1.0}\PYG{p}{]}\PYG{p}{,}
     \PYG{p}{[}\PYG{l+m+mf}{6.5}\PYG{p}{,} \PYG{l+m+mf}{3.0}\PYG{p}{]}\PYG{p}{]}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+sa}{f}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Rank = }\PYG{l+s+si}{\PYGZob{}}\PYG{n}{np}\PYG{o}{.}\PYG{n}{linalg}\PYG{o}{.}\PYG{n}{matrix\PYGZus{}rank}\PYG{p}{(}\PYG{n}{A}\PYG{p}{)}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{n}{A} \PYG{o}{=} \PYG{p}{[}\PYG{p}{[}\PYG{l+m+mf}{2.0}\PYG{p}{,} \PYG{l+m+mf}{1.0}\PYG{p}{]}\PYG{p}{,}
     \PYG{p}{[}\PYG{l+m+mf}{6.0}\PYG{p}{,} \PYG{l+m+mf}{3.0}\PYG{p}{]}\PYG{p}{]}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+sa}{f}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Rank = }\PYG{l+s+si}{\PYGZob{}}\PYG{n}{np}\PYG{o}{.}\PYG{n}{linalg}\PYG{o}{.}\PYG{n}{matrix\PYGZus{}rank}\PYG{p}{(}\PYG{n}{A}\PYG{p}{)}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
Rank = 2
Rank = 1
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}

\section{\protect\(N \times N\protect\) Linear Equations}
\label{\detokenize{05.linear_algebra:n-times-n-linear-equations}}
\sphinxAtStartPar
Let’s look at solving linear equations such as \({\bf A} {\bf x} = {\bf b}\)

\sphinxAtStartPar
We start with the “best” case:  \sphinxstyleemphasis{number of equations \(=\) number of unknowns}

\sphinxAtStartPar
Thus,
\begin{itemize}
\item {} 
\sphinxAtStartPar
Take \(N \times N\) matrix \({\bf A}\) and \(N \times 1\) vector \({\bf b}\) as given

\item {} 
\sphinxAtStartPar
Search for an \(N \times 1\) solution \({\bf x}\)

\end{itemize}

\sphinxAtStartPar
But does such a solution exist? If so is it unique?

\sphinxAtStartPar
The best way to think about this is to consider
the corresponding linear map
\begin{equation*}
\begin{split}
%
T \colon \mathbb{R}^N \to \mathbb{R}^N,
\qquad T{\bf x} = {\bf A} {\bf x}
%
\end{split}
\end{equation*}
\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics{{linbijec}.png}
\end{figure}

\sphinxAtStartPar
Equivalent:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
\({\bf A} {\bf x} = {\bf b}\) has a unique solution \({\bf x}\) for any
given \({\bf b}\)

\item {} 
\sphinxAtStartPar
\(T {\bf x} = {\bf b}\) has a unique solution \({\bf x}\) for any
given \({\bf b}\)

\item {} 
\sphinxAtStartPar
\(T\) is a bijection

\end{enumerate}

\sphinxAtStartPar
We already have conditions for linear maps to be bijections

\sphinxAtStartPar
Just need to translate these into the matrix setting

\sphinxAtStartPar
Recall that \(T\) called nonsingular if \(T\) is a linear bijection

\begin{sphinxadmonition}{note}{Definition}

\sphinxAtStartPar
We say that \({\bf A}\) is \sphinxstyleemphasis{\sphinxstylestrong{nonsingular}} if \(T: {\bf x} \to {\bf A}{\bf x}\) is nonsingular
\end{sphinxadmonition}

\sphinxAtStartPar
Equivalent:
\begin{itemize}
\item {} 
\sphinxAtStartPar
\({\bf x} \mapsto {\bf A} {\bf x}\) is a bijection from \(\mathbb{R}^N\) to \(\mathbb{R}^N\)

\end{itemize}

\sphinxAtStartPar
We now list equivalent conditions for nonsingularity

\begin{sphinxadmonition}{note}{Fact}

\sphinxAtStartPar
Let \({\bf A}\) be an \(N \times N\) matrix \\
All of the following conditions are equivalent
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
\({\bf A}\) is nonsingular

\item {} 
\sphinxAtStartPar
The columns of \({\bf A}\) are linearly independent

\item {} 
\sphinxAtStartPar
\(\mathrm{rank}({\bf A}) = N\)

\item {} 
\sphinxAtStartPar
\(\mathrm{span}({\bf A}) = \mathbb{R}^N\)

\item {} 
\sphinxAtStartPar
If \({\bf A} {\bf x} = {\bf A} {\bf y}\), then \({\bf x} = {\bf y}\)

\item {} 
\sphinxAtStartPar
If \({\bf A} {\bf x} = {\bf 0}\), then \({\bf x} = {\bf 0}\)

\item {} 
\sphinxAtStartPar
For each \({\bf b} \in \mathbb{R}^N\), the equation \({\bf A} {\bf x} = {\bf b}\) has a solution

\item {} 
\sphinxAtStartPar
For each \({\bf b} \in \mathbb{R}^N\), the equation \({\bf A} {\bf x} = {\bf b}\) has a unique solution

\end{enumerate}
\end{sphinxadmonition}

\sphinxAtStartPar
All equivalent ways of saying that \(T{\bf x} = {\bf A} {\bf x}\) is a bijection!

\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
For condition 5 the equivalence is: \\
\({\bf A} {\bf x} = {\bf A} {\bf y}\), then \({\bf x} = {\bf y}\)
\(\iff\)
\(T {\bf x} = T {\bf y}\), then \({\bf x} = {\bf y}\)
\(\iff\)
\(T\) is one\sphinxhyphen{}to\sphinxhyphen{}one
\(\iff\)
Since \(T\) is a linear map from \(\mathbb{R}^N\) to \(\mathbb{R}^N\),
\(T\) is a bijection
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
For condition 6 the equivalence is: \\
if \({\bf A} {\bf x} = {\bf 0}\), then \({\bf x} = {\bf 0}\)
\(\iff\)
\(\{{\bf x}: {\bf A}{\bf x} = {\bf 0}\} = \{{\bf 0}\}\)
\(\iff\)
\(\{{\bf x}: T{\bf x} = {\bf 0}\} = \{{\bf 0}\}\)
\(\iff\)
\(\ker{T}=\{{\bf 0}\}\)
\(\iff\)
Since \(T\) is a linear map from \(\mathbb{R}^N\) to \(\mathbb{R}^N\),
\(T\) is a bijection
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
For condition 7 the equivalence is: \\
for each \({\bf b}\in\mathbb{R}^N\), the equation \({\bf A}{\bf x} = {\bf b}\) has a solution
\(\iff\)
every \({\bf b}\in\mathbb{R}^N\) has an \({\bf x}\) such that \({\bf A}{\bf x} = {\bf b}\)
\(\iff\)
every \({\bf b}\in\mathbb{R}^N\) has an \({\bf x}\) such that \(T{\bf x} = {\bf b}\)
\(\iff\)
\(T is onto/surjection\)
\(\iff\)
Since \(T\) is a linear map from \(\mathbb{R}^N\) to \(\mathbb{R}^N\),
\(T\) is a bijection
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
Now consider condition 2: \textbackslash{}

\sphinxAtStartPar
The columns of \({\bf A}\) are linearly independent.

\sphinxAtStartPar
Let \({\bf e}_j\) be the \(j\)\sphinxhyphen{}th canonical basis vector in \(\mathbb{R}^N\).

\sphinxAtStartPar
Observe that \({\bf A}{\bf e_j} = \mathrm{col}_j({\bf A})\)
\(\implies\)
\(T{\bf e_j} = \mathrm{col}_j({\bf A})\)
\(\implies\)
\(V := \{T {\bf e}_1, \ldots, T{\bf e}_N\}
=\) columns of \({\bf A}\), and \(V\) is linearly independent if and only if \(T\) is a bijection
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
Consider a one good linear market system
\begin{equation*}
\begin{split}
%
q = a - b p \qquad (\text{demand}) \\
q = c + d p \qquad (\text{supply})
%
\end{split}
\end{equation*}
\sphinxAtStartPar
Treating \(q\) and \(p\) as the unknowns, let’s write in matrix form as
\begin{equation*}
\begin{split}
%
\begin{pmatrix}
1 & b \\
1 & -d
\end{pmatrix}
\begin{pmatrix}
q\\
p
\end{pmatrix}
=
\begin{pmatrix}
a \\
c 
\end{pmatrix}
%
\end{split}
\end{equation*}
\sphinxAtStartPar
A unique solution exists whenever the columns are linearly independent
\begin{itemize}
\item {} 
\sphinxAtStartPar
so \((b, -d)\) is not a scalar multiple of \({\bf 1}\) \(\iff\) \(b \ne -d\)

\end{itemize}
\end{sphinxadmonition}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{not_multiple_of_one}.png}
\caption{\((b, -d)\) is not a scalar multiple of \({\bf 1}\)}\label{\detokenize{05.linear_algebra:id14}}\end{figure}

\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
Recall in the introduction we try to solve the system \({\bf A} {\bf x} = {\bf b}\)
of this form
\begin{equation*}
\begin{split}
A = \left[\begin{array}{cccc}
1 & 2 & 4 \\
1 & 4 & 8 \\
0 & 3 & 6 \\
\end{array}
\right]
\end{split}
\end{equation*}
\sphinxAtStartPar
The problem is that \({\bf A}\) is singular (not nonsingular)
\begin{itemize}
\item {} 
\sphinxAtStartPar
In particular, \(\mathrm{col}_3({\bf A}) = 2 \mathrm{col}_2({\bf A})\)

\end{itemize}
\end{sphinxadmonition}


\subsection{Inverse Matrices}
\label{\detokenize{05.linear_algebra:inverse-matrices}}
\begin{sphinxadmonition}{note}{Definition}

\sphinxAtStartPar
Given square matrix \({\bf A}\), suppose \(\exists\) square matrix \({\bf B}\) such that
\begin{equation*}
\begin{split}{\bf A} {\bf B} = {\bf B} {\bf A} = {\bf I}\end{split}
\end{equation*}
\sphinxAtStartPar
Then
\begin{itemize}
\item {} 
\sphinxAtStartPar
\({\bf B}\) is called the \sphinxstyleemphasis{\sphinxstylestrong{inverse}} of \({\bf A}\), and written \({\bf A}^{-1}\)

\item {} 
\sphinxAtStartPar
\({\bf A}\) is called \sphinxstyleemphasis{\sphinxstylestrong{invertible}}

\end{itemize}
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Fact}

\sphinxAtStartPar
A square matrix \({\bf A}\) is nonsingular if and only if it is invertible
\end{sphinxadmonition}

\sphinxAtStartPar
Remark: \({\bf A}^{-1}\) is just the matrix corresponding to the linear map \(T^{-1}\)

\begin{sphinxadmonition}{note}{Fact}

\sphinxAtStartPar
Given nonsingular \(N \times N\) matrix \({\bf A}\) and \({\bf b} \in \mathbb{R}^N\), the unique solution to \({\bf A} {\bf x} = {\bf b}\) is given by
\begin{equation*}
\begin{split} {\bf x}_b := {\bf A}^{-1} {\bf b} \end{split}
\end{equation*}\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Proof}

\sphinxAtStartPar
Since \({\bf A}\) is nonsingular we already know any solution is
unique
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(T\) is a bijection, and hence one\sphinxhyphen{}to\sphinxhyphen{}one

\item {} 
\sphinxAtStartPar
if \({\bf A} {\bf x} = {\bf A} {\bf y} = {\bf b}\) then \({\bf x} = {\bf y}\)

\end{itemize}

\sphinxAtStartPar
To show that \({\bf x}_b\) is indeed a solution we need to show that
\({\bf A} {\bf x}_b = {\bf b}\)

\sphinxAtStartPar
To see this, observe that
\begin{equation*}
\begin{split}
%
{\bf A} {\bf x}_b = {\bf A} {\bf A}^{-1} {\bf b} = {\bf I} {\bf b} = {\bf b}
%
\end{split}
\end{equation*}\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
Recall the one good linear market system
\begin{equation*}
\begin{split}
%
\begin{array}{c}
q = a - b p \\
q = c + d p
\end{array}
\quad \iff \quad
\begin{pmatrix}
1 & b \\
1 & -d
\end{pmatrix}
\begin{pmatrix}
q\\
p
\end{pmatrix}
=
\begin{pmatrix}
a \\
c 
\end{pmatrix}
%
\end{split}
\end{equation*}
\sphinxAtStartPar
Suppose that \(a=5\), \(b=2\), \(c=1\), \(d=1.5\)

\sphinxAtStartPar
The matrix system is \({\bf A} {\bf x} = {\bf b}\) where
\begin{equation*}
\begin{split}
%
{\bf A} :=
\begin{pmatrix}
1 & 2 \\
1 & -1.5
\end{pmatrix},
\;
{\bf x} :=
\begin{pmatrix}
q\\
p
\end{pmatrix},
\;
{\bf b} :=
\begin{pmatrix}
5 \\
1 
\end{pmatrix}
%
\end{split}
\end{equation*}
\sphinxAtStartPar
Since \(b \ne -d\) we can solve for the unique solution
\end{sphinxadmonition}

\sphinxAtStartPar
Easy by hand but let’s try on the computer

\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{import} \PYG{n+nn}{numpy} \PYG{k}{as} \PYG{n+nn}{np}
\PYG{k+kn}{from} \PYG{n+nn}{scipy}\PYG{n+nn}{.}\PYG{n+nn}{linalg} \PYG{k+kn}{import} \PYG{n}{inv}
\PYG{n}{A} \PYG{o}{=} \PYG{p}{[}\PYG{p}{[}\PYG{l+m+mi}{1}\PYG{p}{,} \PYG{l+m+mi}{2}\PYG{p}{]}\PYG{p}{,}
     \PYG{p}{[}\PYG{l+m+mi}{1}\PYG{p}{,} \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{1.5}\PYG{p}{]}\PYG{p}{]}
\PYG{n}{b} \PYG{o}{=} \PYG{p}{[}\PYG{l+m+mi}{5}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{]}
\PYG{n}{q}\PYG{p}{,} \PYG{n}{p} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{dot}\PYG{p}{(}\PYG{n}{inv}\PYG{p}{(}\PYG{n}{A}\PYG{p}{)}\PYG{p}{,} \PYG{n}{b}\PYG{p}{)} \PYG{c+c1}{\PYGZsh{} A\PYGZca{}\PYGZob{}\PYGZhy{}1\PYGZcb{} b}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+sa}{f}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{q=}\PYG{l+s+si}{\PYGZob{}}\PYG{n}{q}\PYG{l+s+si}{:}\PYG{l+s+s1}{.4f}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s1}{ p=}\PYG{l+s+si}{\PYGZob{}}\PYG{n}{p}\PYG{l+s+si}{:}\PYG{l+s+s1}{.4f}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
q=2.7143 p=1.1429
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{simple_mkt}.png}
\caption{Equilibrium \((p^*, q^*)\) in the one good case}\label{\detokenize{05.linear_algebra:id15}}\end{figure}

\begin{sphinxadmonition}{note}{Fact}

\sphinxAtStartPar
In the \(2 \times 2\) case, the inverse has the form
\begin{equation*}
\begin{split}
%
\left(
\begin{array}{cc}
a & b \\
c & d \\
\end{array}
\right)^{-1} = 
\frac{1}{ad - bc}
\left(
\begin{array}{cc}
d & -b \\
-c & a \\
\end{array}
\right)
%
\end{split}
\end{equation*}\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Example}
\begin{equation*}
\begin{split}
%
{\bf A} = 
\left(
\begin{array}{cc}
1 & 2 \\
1 & -1.5 \\
\end{array}
\right)
\quad \implies \quad
{\bf A}^{-1} = 
\frac{1}{-3.5}
\left(
\begin{array}{cc}
-1.5 & -2 \\
-1 & 1 \\
\end{array}
\right)
%
\end{split}
\end{equation*}\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
Consider the \(N\) good linear demand system
\begin{equation}\label{equation:05.linear_algebra:eq:ds}
\begin{split}
%
q_n = \sum_{k=1}^N a_{nk} p_k + b_n,
\quad n = 1, \ldots N
%
\end{split}
\end{equation}
\sphinxAtStartPar
Task: take quantities \(q_1, \ldots, q_N\) as given and find
corresponding prices \(p_1, \ldots, p_N\) — the “inverse demand curves”
\end{sphinxadmonition}

\sphinxAtStartPar
We can write \eqref{equation:05.linear_algebra:eq:ds} as
\begin{equation*}
\begin{split}
%
{\bf q} = {\bf A} {\bf p} + {\bf b}
%
\end{split}
\end{equation*}
\sphinxAtStartPar
where vectors are \(N\)\sphinxhyphen{}vectors and \({\bf A}\) is \(N \times N\)

\sphinxAtStartPar
If the columns of \({\bf A}\) are linearly independent then a unique solution
exists for each fixed \({\bf q}\) and \({\bf b}\), and is given by
\begin{equation*}
\begin{split}
%
{\bf p} = {\bf A}^{-1} ({\bf q} - {\bf b})
%
\end{split}
\end{equation*}

\subsection{Left and Right Inverses}
\label{\detokenize{05.linear_algebra:left-and-right-inverses}}
\begin{sphinxadmonition}{note}{Definition}

\sphinxAtStartPar
Given square matrix \({\bf A}\), a matrix \({\bf B}\) is called
\begin{itemize}
\item {} 
\sphinxAtStartPar
a \sphinxstyleemphasis{\sphinxstylestrong{left inverse}} of \({\bf A}\) if \({\bf B} {\bf A} = {\bf I}\)

\item {} 
\sphinxAtStartPar
a \sphinxstyleemphasis{\sphinxstylestrong{right inverse}} of \({\bf A}\) if \({\bf A} {\bf B} = {\bf I}\)

\item {} 
\sphinxAtStartPar
an \sphinxstyleemphasis{\sphinxstylestrong{inverse}} of \({\bf A}\) if \({\bf A} {\bf B} = {\bf B} {\bf A} = {\bf I}\)

\end{itemize}
\end{sphinxadmonition}

\sphinxAtStartPar
By definition, a matrix that is both an left inverse and a right inverse is an inverse

\begin{sphinxadmonition}{note}{Fact}

\sphinxAtStartPar
If square matrix \({\bf B}\) is either a left or right inverse for
\({\bf A}\), then \({\bf A}\) is nonsingular and \({\bf A}^{-1} = {\bf B}\)
\end{sphinxadmonition}

\sphinxAtStartPar
In other words, for square matrices, left inverse \(\iff\) right inverse \(\iff\) inverse


\subsection{Rules for Inverses}
\label{\detokenize{05.linear_algebra:rules-for-inverses}}
\begin{sphinxadmonition}{note}{Fact}

\sphinxAtStartPar
If \({\bf A}\) is nonsingular and \(\alpha \ne 0\), then
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
\({\bf A}^{-1}\) is nonsingular and \(({\bf A}^{-1})^{-1} = {\bf A}\)

\item {} 
\sphinxAtStartPar
\(\alpha {\bf A}\) is nonsingular and \((\alpha {\bf A})^{-1} = \alpha^{-1} {\bf A}^{-1}\)

\end{enumerate}
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Proof}

\sphinxAtStartPar
Proof of part 2:

\sphinxAtStartPar
It suffices to show that \(\alpha^{-1} {\bf A}^{-1}\) is the right inverse of
\(\alpha {\bf A}\)

\sphinxAtStartPar
This is true because
\begin{equation*}
\begin{split}
%
\alpha {\bf A} \alpha^{-1} {\bf A}^{-1} 
=
\alpha \alpha^{-1} {\bf A} {\bf A}^{-1} 
= {\bf I}
%
\end{split}
\end{equation*}\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Fact}

\sphinxAtStartPar
If \({\bf A}\) and \({\bf B}\) are \(N \times N\) and nonsingular then
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
\({\bf A} {\bf B}\) is also nonsingular

\item {} 
\sphinxAtStartPar
\(({\bf A} {\bf B})^{-1} = {\bf B}^{-1} {\bf A}^{-1}\)

\end{enumerate}
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Proof}

\sphinxAtStartPar
Proof I: Let \(T\) and \(U\) be the linear maps corresponding to \({\bf A}\) and
\({\bf B}\)

\sphinxAtStartPar
Recall that
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(T \circ U\) is the linear map corresponding to \({\bf A} {\bf B}\)

\item {} 
\sphinxAtStartPar
Compositions of linear maps are linear

\item {} 
\sphinxAtStartPar
Compositions of bijections are bijections

\end{itemize}

\sphinxAtStartPar
Hence \(T \circ U\) is a linear bijection with \((T \circ U)^{-1} = U^{-1} \circ T^{-1}\)

\sphinxAtStartPar
That is, \({\bf A}{\bf B}\) is nonsingular with inverse \({\bf B}^{-1} {\bf A}^{-1}\)

\sphinxAtStartPar
Proof II:

\sphinxAtStartPar
A different proof that \({\bf A} {\bf B}\) is nonsingular with inverse
\({\bf B}^{-1} {\bf A}^{-1}\)

\sphinxAtStartPar
Suffices to show that \({\bf B}^{-1} {\bf A}^{-1}\) is the right inverse of \({\bf A} {\bf B}\)

\sphinxAtStartPar
To see this, observe that
\begin{equation*}
\begin{split}
%
{\bf A} {\bf B} {\bf B}^{-1} {\bf A}^{-1}
= {\bf A} {\bf A}^{-1}
= {\bf I}
%
\end{split}
\end{equation*}
\sphinxAtStartPar
Hence \({\bf B}^{-1} {\bf A}^{-1}\) is a right inverse as claimed
\end{sphinxadmonition}


\subsection{When the Conditions Fail (Singular Case)}
\label{\detokenize{05.linear_algebra:when-the-conditions-fail-singular-case}}
\sphinxAtStartPar
Suppose as before we have
\begin{itemize}
\item {} 
\sphinxAtStartPar
an \(N \times N\) matrix \({\bf A}\)

\item {} 
\sphinxAtStartPar
an \(N \times 1\) vector \({\bf b}\)

\end{itemize}

\sphinxAtStartPar
We seek a solution \({\bf x}\) to the equation \({\bf A} {\bf x} = {\bf b}\)

\sphinxAtStartPar
What if \({\bf A}\) is \sphinxstyleemphasis{\sphinxstylestrong{singular}}?

\sphinxAtStartPar
Then \(T{\bf x} = {\bf A} {\bf x}\) is not a bijection, and in fact
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(T\) cannot be onto (otherwise it’s a bijection)

\item {} 
\sphinxAtStartPar
\(T\) cannot be one\sphinxhyphen{}to\sphinxhyphen{}one (otherwise it’s a bijection)

\end{itemize}

\sphinxAtStartPar
Hence neither existence nor uniqueness is guaranteed

\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
The matrix \({\bf A}\) with columns
\begin{equation*}
\begin{split}
%
{\bf a}_1 :=
\begin{pmatrix}
3 \\
4 \\
2
\end{pmatrix},
\quad
{\bf a}_2 :=
\begin{pmatrix}
3 \\
-4 \\
1
\end{pmatrix}
\quad \text{and} \quad
{\bf a}_3 :=
\begin{pmatrix}
-3 \\
4 \\
-1
\end{pmatrix}
%
\end{split}
\end{equation*}
\sphinxAtStartPar
is singular (\({\bf a}_3 = - {\bf a}_2\))

\sphinxAtStartPar
Its column space \(\mathrm{span}({\bf A})\) is just a plane in \(\mathbb{R}^2\)

\sphinxAtStartPar
Recall \({\bf b} \in \mathrm{span}({\bf A})\)
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(\iff\) \(\exists \, x_1, \ldots, x_N\) such that \(\sum_{k=1}^N
x_k \mathrm{col}_k({\bf A}) = {\bf b}\)

\item {} 
\sphinxAtStartPar
\(\iff\) \(\exists \, {\bf x}\) such that \({\bf A} {\bf x} = {\bf b}\)

\end{itemize}

\sphinxAtStartPar
Thus if \({\bf b}\) is not in this plane then \({\bf A} {\bf x} = {\bf b}\) has no
solution
\end{sphinxadmonition}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{not_in_span}.png}
\caption{The vector \({\bf b}\) is not in \(\mathrm{span}({\bf A})\)}\label{\detokenize{05.linear_algebra:id16}}\end{figure}

\sphinxAtStartPar
When \({\bf A}\) is \(N \times N\) and singular how rare is scenario \({\bf b} \in
\mathrm{span}({\bf A})\)?

\sphinxAtStartPar
Answer: In a sense, very rare

\sphinxAtStartPar
We know that \(\dim(\mathrm{span}({\bf A})) < N\)

\sphinxAtStartPar
Such sets are always “very small” subset of \(\mathbb{R}^N\) in terms of “volume”
\begin{itemize}
\item {} 
\sphinxAtStartPar
A \(K < N\) dimensional subspace has “measure zero” in \(\mathbb{R}^N\)

\item {} 
\sphinxAtStartPar
A “randomly chosen” \({\bf b}\) has zero probability of being in such
a set

\end{itemize}

\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
Consider the case where \(N = 3\) and \(K=2\)
\end{sphinxadmonition}

\sphinxAtStartPar
A two\sphinxhyphen{}dimensional linear subspace is a 2D plane in \(\mathbb{R}^3\)

\sphinxAtStartPar
This set has no volume because planes have no ``thickness’’

\sphinxAtStartPar
All this means that if \({\bf A}\) is singular then existence
of a solution to \({\bf A} {\bf x} = {\bf b}\) typically fails

\sphinxAtStartPar
In fact the problem is worse — uniqueness fails as well

\begin{sphinxadmonition}{note}{Fact}

\sphinxAtStartPar
If \({\bf A}\) is a singular matrix and \({\bf A} {\bf x} = {\bf b}\) has a
solution then it has an infinity (in fact a continuum) of solutions
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Proof}

\sphinxAtStartPar
Let \({\bf A}\) be singular and let \({\bf x}\) be a solution

\sphinxAtStartPar
Since \({\bf A}\) is singular there exists a nonzero \({\bf y}\) with \({\bf A}
{\bf y} = {\bf 0}\)

\sphinxAtStartPar
But then \(\alpha {\bf y} + {\bf x}\) is also a solution for any \(\alpha \in
\mathbb{R}\) because
\begin{equation*}
\begin{split} 
%
{\bf A}(\alpha {\bf y} + {\bf x}) 
= \alpha {\bf A} {\bf y} + {\bf A} {\bf x}
= {\bf A} {\bf x} = {\bf b}
%
\end{split}
\end{equation*}\end{sphinxadmonition}


\subsection{Determinants}
\label{\detokenize{05.linear_algebra:determinants}}
\sphinxAtStartPar
Let \(S(N)\) be set of all bijections from \(\{1, \ldots, N\}\) to itself

\sphinxAtStartPar
For \(\pi \in S(N)\) we define the \sphinxstyleemphasis{\sphinxstylestrong{signature}} of \(\pi\) as
\begin{equation*}
\begin{split}
%
\mathrm{sgn}(\pi) := \prod_{m < n} \frac{\pi(m) - \pi(n)}{m - n}
%
\end{split}
\end{equation*}
\sphinxAtStartPar
The \sphinxstyleemphasis{\sphinxstylestrong{determinant}} of \(N \times N\) matrix \({\bf A}\) is then given as
\begin{equation*}
\begin{split}
%
\det({\bf A}) 
:= \sum_{\pi \in S(N)} \mathrm{sgn}(\pi) \prod_{n=1}^N a_{\pi(n) n}
%
\end{split}
\end{equation*}\begin{itemize}
\item {} 
\sphinxAtStartPar
You don’t need to understand or remember this for our course

\end{itemize}

\begin{sphinxadmonition}{note}{Fact}

\sphinxAtStartPar
In the \(N = 2\) case this definition reduces to
\end{sphinxadmonition}
\begin{equation*}
\begin{split}
%
\det 
\left(
\begin{array}{cc}
a & b \\
c & d \\
\end{array}
\right)
= ad - bc
%
\end{split}
\end{equation*}\begin{itemize}
\item {} 
\sphinxAtStartPar
Remark: But you do need to remember this \(2 \times 2\) case

\end{itemize}

\begin{sphinxadmonition}{note}{Example}
\begin{equation*}
\begin{split}
%
\det 
\left(
\begin{array}{cc}
2 & 0 \\
7 & -1 \\
\end{array}
\right)
= (2 \times -1) - (7 \times 0) = -2
%
\end{split}
\end{equation*}\end{sphinxadmonition}

\sphinxAtStartPar
Important facts concerning the determinant

\begin{sphinxadmonition}{note}{Fact}

\sphinxAtStartPar
If \({\bf I}\) is the \(N \times N\) identity, \({\bf A}\) and \({\bf B}\) are \(N \times N\) matrices and \(\alpha \in \mathbb{R}\), then
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
\(\det({\bf I}) = 1\)

\item {} 
\sphinxAtStartPar
\({\bf A}\) is nonsingular if and only if \(\det({\bf A})
\ne 0\)

\item {} 
\sphinxAtStartPar
\(\det({\bf A}{\bf B}) = \det({\bf A})
\det({\bf B})\)

\item {} 
\sphinxAtStartPar
\(\det(\alpha {\bf A}) = \alpha^N \det({\bf A})\)

\item {} 
\sphinxAtStartPar
\(\det({\bf A}^{-1}) = (\det({\bf A}))^{-1}\)

\end{enumerate}
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
Thus singularity in the \(2 \times 2\) case is equivalent to
\begin{equation*}
\begin{split}
%
\det({\bf A})
=
\det 
\left(
\begin{array}{cc}
a_{11} & a_{12} \\
a_{21} & a_{22} \\
\end{array}
\right)
= a_{11}a_{22} - a_{12} a_{21} = 0
%
\end{split}
\end{equation*}\end{sphinxadmonition}

\sphinxAtStartPar
\sphinxstylestrong{Exercise:} Let \({\bf a}_i := \mathrm{col}_i({\bf A})\) and assume that \(a_{ij} \ne 0\) for each \(i, j\)

\sphinxAtStartPar
Show the following are equivalent:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
\(a_{11}a_{22} = a_{12} a_{21}\)

\item {} 
\sphinxAtStartPar
\({\bf a}_1 = \lambda {\bf a}_2\) for some \(\lambda \in \mathbb{R}\)

\end{enumerate}

\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{import} \PYG{n+nn}{numpy} \PYG{k}{as} \PYG{n+nn}{np}
\PYG{n}{A} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{random}\PYG{o}{.}\PYG{n}{randn}\PYG{p}{(}\PYG{l+m+mi}{2}\PYG{p}{,} \PYG{l+m+mi}{2}\PYG{p}{)} \PYG{c+c1}{\PYGZsh{} Random matrix}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+sa}{f}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{A=}\PYG{l+s+si}{\PYGZob{}}\PYG{n}{A}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+sa}{f}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{det(A)=}\PYG{l+s+si}{\PYGZob{}}\PYG{n}{np}\PYG{o}{.}\PYG{n}{linalg}\PYG{o}{.}\PYG{n}{det}\PYG{p}{(}\PYG{n}{A}\PYG{p}{)}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+sa}{f}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{det(inv(A))=}\PYG{l+s+si}{\PYGZob{}}\PYG{n}{np}\PYG{o}{.}\PYG{n}{linalg}\PYG{o}{.}\PYG{n}{det}\PYG{p}{(}\PYG{n}{np}\PYG{o}{.}\PYG{n}{linalg}\PYG{o}{.}\PYG{n}{inv}\PYG{p}{(}\PYG{n}{A}\PYG{p}{)}\PYG{p}{)}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
A=[[\PYGZhy{}0.17412201  1.21509467]
 [\PYGZhy{}0.3087902   1.08162961]]
det(A)=0.1868738001242868
det(inv(A))=5.351204927255271
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\sphinxAtStartPar
As an exercise, let’s now show that any right inverse is an inverse

\sphinxAtStartPar
Fix square \({\bf A}\) and suppose \({\bf B}\) is a right inverse:
\begin{equation}\label{equation:05.linear_algebra:eq:ud}
\begin{split}
%
{\bf A} {\bf B} = {\bf I}
%
\end{split}
\end{equation}
\sphinxAtStartPar
Applying the determinant to both sides gives \(\det({\bf A}) \det({\bf B}) = 1\)

\sphinxAtStartPar
Hence \({\bf B}\) is nonsingular (why?) and we can
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
multiply \eqref{equation:05.linear_algebra:eq:ud} by \({\bf B}\) to get \({\bf B} {\bf A} {\bf B} = {\bf B}\)

\item {} 
\sphinxAtStartPar
then postmultiply by \({\bf B}^{-1}\) to get \({\bf B} {\bf A} = {\bf I}\)

\end{enumerate}

\sphinxAtStartPar
We see that \({\bf B}\) is also left inverse, and therefore an inverse of \({\bf A}\)

\sphinxAtStartPar
\sphinxstylestrong{Exercise:} Do the left inverse case


\section{\protect\(M \times N\protect\) Linear Systems of Equations}
\label{\detokenize{05.linear_algebra:m-times-n-linear-systems-of-equations}}
\sphinxAtStartPar
So far we have considered the nice \(N \times N\) case for equations
\begin{itemize}
\item {} 
\sphinxAtStartPar
number of equations \(=\) number of unknowns

\end{itemize}

\sphinxAtStartPar
We have to deal with other cases too

\sphinxAtStartPar
Underdetermined systems:
\begin{itemize}
\item {} 
\sphinxAtStartPar
eqs \(<\) unknowns

\end{itemize}

\sphinxAtStartPar
Overdetermined systems:
\begin{itemize}
\item {} 
\sphinxAtStartPar
eqs \(>\) unknowns

\end{itemize}


\subsection{Overdetermined Systems}
\label{\detokenize{05.linear_algebra:overdetermined-systems}}
\sphinxAtStartPar
Consider the system \({\bf A} {\bf x} = {\bf b}\) where \({\bf A}\) is \(N \times K\) and \(K < N\)
\begin{itemize}
\item {} 
\sphinxAtStartPar
The elements of \({\bf x}\) are the unknowns

\item {} 
\sphinxAtStartPar
More equations than unknowns (\(N > K\))

\end{itemize}

\sphinxAtStartPar
May not be able to find an \({\bf x}\) that satisfies all \(N\) equations

\sphinxAtStartPar
Let’s look at this in more detail…

\sphinxAtStartPar
Fix \(N \times K\) matrix \({\bf A}\) with \(K < N\)

\sphinxAtStartPar
Let \(T \colon \mathbb{R}^K \to \mathbb{R}^N\) be defined by \(T {\bf x} = {\bf A} {\bf x}\)

\sphinxAtStartPar
We know these to be equivalent:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
there exists an \({\bf x} \in \mathbb{R}^K\) with \({\bf A} {\bf x} = {\bf b}\)

\end{enumerate}
\begin{itemize}
\item {} 
\sphinxAtStartPar
\({\bf b}\) has a preimage under \(T\)

\item {} 
\sphinxAtStartPar
\({\bf b}\) is in \(\mathrm{rng}(T)\)

\end{itemize}
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\setcounter{enumi}{8}
\item {} 
\sphinxAtStartPar
\({\bf b}\) is in \(\mathrm{span}({\bf A})\)

\end{enumerate}

\sphinxAtStartPar
We also know \(T\) \sphinxstyleemphasis{\sphinxstylestrong{cannot}} be onto (maps small to big space)

\sphinxAtStartPar
Hence \({\bf b} \in \mathrm{span}({\bf A})\) will not always hold

\sphinxAtStartPar
Given our assumption that \(K < N\), how rare is the scenario \({\bf b} \in
\mathrm{span}({\bf A})\)?

\sphinxAtStartPar
Answer: We talked about this before — it’s very rare

\sphinxAtStartPar
We know that \(\dim(\mathrm{rng}(T)) = \dim(\mathrm{span}({\bf A})) \leq K < N\)

\sphinxAtStartPar
A \(K < N\) dimensional subspace has “measure zero” in \(\mathbb{R}^N\)

\sphinxAtStartPar
So should we give up on solving \({\bf A} {\bf x} = {\bf b}\) in the
overdetermined case?

\sphinxAtStartPar
What’s typically done is we try to find a best approximation

\sphinxAtStartPar
To define ``best’’ we need a way of ranking approximations

\sphinxAtStartPar
The standard way is in terms of Euclidean norm

\sphinxAtStartPar
In particular, we search for the \({\bf x}\) that solves
\begin{equation*}
\begin{split} \min_{{\bf x} \in \mathbb{R}^K} \| {\bf A} {\bf x} - {\bf b}\|\end{split}
\end{equation*}
\sphinxAtStartPar
Details later


\subsection{Underdetermined Systems}
\label{\detokenize{05.linear_algebra:underdetermined-systems}}
\sphinxAtStartPar
Now consider \({\bf A} {\bf x} = {\bf b}\) when \({\bf A}\) is \(N \times K\) and \(K > N\)

\sphinxAtStartPar
Let \(T \colon \mathbb{R}^K \to \mathbb{R}^N\) be defined by \(T {\bf x} = {\bf A} {\bf x}\)

\sphinxAtStartPar
Now \(T\) maps from a larger to a smaller place

\sphinxAtStartPar
This tells us that \(T\) is not one\sphinxhyphen{}to\sphinxhyphen{}one

\sphinxAtStartPar
Hence solutions are not in general unique

\sphinxAtStartPar
In fact the following is true

\sphinxAtStartPar
\sphinxstylestrong{Exercise:} Show that \({\bf A} {\bf x} =
{\bf b}\) has a solution and \(K > N\), then the same equation has an infinity of solutions

\sphinxAtStartPar
Remark: Working with underdetermined systems is relatively rare in economics / elsewhere


\subsection{Transpose}
\label{\detokenize{05.linear_algebra:transpose}}
\sphinxAtStartPar
The \sphinxstyleemphasis{\sphinxstylestrong{transpose}} of \({\bf A}\) is the matrix \({\bf A}'\) defined by
\begin{equation*}
\begin{split}\mathrm{col}_n({\bf A}') = \mathrm{row}_n({\bf A})\end{split}
\end{equation*}
\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
If
\begin{equation}\label{equation:05.linear_algebra:eq:aandb}
\begin{split}
%
{\bf A} := 
\left(
\begin{array}{cc}
10 & 40 \\
20 & 50 \\
30 & 60
\end{array}
\right)
\quad \text{then} \quad
{\bf A}' = 
\left(
\begin{array}{ccc}
10 & 20 & 30 \\
40 & 50 & 60 
\end{array}
\right)
%
\end{split}
\end{equation}
\sphinxAtStartPar
If
\begin{equation*}
\begin{split}
%
{\bf B} := 
\left(
\begin{array}{ccc}
1 & 3 & 5 \\
2 & 4 & 6 \\
\end{array}
\right)
\quad \text{then} \quad
{\bf B}' := 
\left(
\begin{array}{cc}
1 & 2 \\
3 & 4 \\
5 & 6 
\end{array}
\right)
%
\end{split}
\end{equation*}\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Fact}

\sphinxAtStartPar
For conformable matrices \({\bf A}\) and \({\bf B}\), transposition satisfies
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
\(({\bf A}')' = {\bf A}\)

\item {} 
\sphinxAtStartPar
\(({\bf A} {\bf B})' = {\bf B}' {\bf A}'\)

\item {} 
\sphinxAtStartPar
\(({\bf A} + {\bf B})' = {\bf A}' + {\bf B}'\)

\item {} 
\sphinxAtStartPar
\((c {\bf A})' = c {\bf A}'\) for any constant \(c\)

\end{enumerate}

\sphinxAtStartPar
For each square matrix \({\bf A}\),
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
\(\det({\bf A}') = \det({\bf A})\)

\item {} 
\sphinxAtStartPar
If \({\bf A}\) is nonsingular then so is \({\bf A}'\), and \(({\bf A}')^{-1}= ({\bf A}^{-1})'\)

\end{enumerate}
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Definition}

\sphinxAtStartPar
A square matrix \({\bf A}\) is called \sphinxstyleemphasis{\sphinxstylestrong{symmetric}} if \({\bf A}' = {\bf A}\)
\end{sphinxadmonition}

\sphinxAtStartPar
Equivalent: \(a_{nk} = a_{kn}\) for all \(n, k\)

\begin{sphinxadmonition}{note}{Example}
\begin{equation*}
\begin{split}
%
{\bf A} 
:= 
\left(
\begin{array}{cc}
10 & 20 \\
20 & 50 
\end{array}
\right),
\qquad
{\bf B} 
:= 
\left(
\begin{array}{ccc}
1 & 2 & 3 \\
2 & 0 & 0 \\ 
3 & 0 & 2 
\end{array}
\right)
%
\end{split}
\end{equation*}\end{sphinxadmonition}

\sphinxAtStartPar
\sphinxstylestrong{Exercise:} For any matrix \({\bf A}\), show that \({\bf A}' {\bf A}\) and \({\bf A} {\bf A}'\) are always
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
well\sphinxhyphen{}defined (multiplication makes sense)

\item {} 
\sphinxAtStartPar
symmetric

\end{enumerate}

\begin{sphinxadmonition}{note}{Definition}

\sphinxAtStartPar
The \sphinxstyleemphasis{\sphinxstylestrong{trace}} of a square matrix is defined by
\begin{equation*}
\begin{split}
%
\mathrm{trace} \left(
\begin{array}{ccc}
a_{11} & \cdots & a_{1N} \\
\vdots & & \vdots \\
a_{N1} & \cdots & a_{NN} \\
\end{array}
\right)
= 
\sum_{n=1}^N a_{nn}
%
\end{split}
\end{equation*}\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Fact}

\sphinxAtStartPar
\(\mathrm{trace}({\bf A}) = \mathrm{trace}({\bf A}')\)
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Fact}

\sphinxAtStartPar
If \({\bf A}\) and \({\bf B}\) are square matrices and
\(\alpha, \beta \in \mathbb{R}\), then
\begin{equation*}
\begin{split}
%
\mathrm{trace}(\alpha {\bf A} + \beta {\bf B}) 
= \alpha \mathrm{trace}({\bf A}) + \beta \mathrm{trace}({\bf B})
%
\end{split}
\end{equation*}\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Fact}

\sphinxAtStartPar
When conformable, \(\mathrm{trace}({\bf A} {\bf B}) = \mathrm{trace}({\bf B} {\bf A})\)
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Definition}

\sphinxAtStartPar
A square matrix \({\bf A}\) is called \sphinxstyleemphasis{\sphinxstylestrong{idempotent}} if \({\bf A} {\bf A} = {\bf A}\)
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Example}
\begin{equation*}
\begin{split}
%
{\bf A} 
:= 
\left(
\begin{array}{cc}
1 & 1 \\
0 & 0 
\end{array}
\right),
\qquad
{\bf I} 
:= 
\left(
\begin{array}{ccc}
1 & 0 & 0 \\
0 & 1 & 0 \\ 
0 & 0 & 1 
\end{array}
\right)
%
\end{split}
\end{equation*}\end{sphinxadmonition}

\sphinxAtStartPar
The next result is often used in statistics / econometrics:

\begin{sphinxadmonition}{note}{Fact}

\sphinxAtStartPar
If \({\bf A}\) is idempotent, then \(\mathrm{rank}({\bf A}) = \mathrm{trace}({\bf A})\)
\end{sphinxadmonition}


\subsection{Diagonal Matrices}
\label{\detokenize{05.linear_algebra:diagonal-matrices}}
\sphinxAtStartPar
Consider a square \(N \times N\) matrix \({\bf A}\)

\begin{sphinxadmonition}{note}{Definition}

\sphinxAtStartPar
The \(N\) elements of the form \(a_{nn}\) are called the \sphinxstyleemphasis{\sphinxstylestrong{principal diagonal}}
\end{sphinxadmonition}
\begin{equation*}
\begin{split}
%
\left(
\begin{array}{cccc}
a_{11} & a_{12} & \cdots & a_{1N} \\
a_{21} & a_{22} & \cdots & a_{2N} \\
\vdots & \vdots & & \vdots \\
a_{N1} & a_{N2} & \cdots & a_{NN} \\
\end{array}
\right)
%
\end{split}
\end{equation*}
\sphinxAtStartPar
A square matrix \({\bf D}\) is called \sphinxstyleemphasis{\sphinxstylestrong{diagonal}} if all entries off the
principal diagonal are zero
\begin{equation*}
\begin{split}
%
{\bf D} = 
\left(
\begin{array}{cccc}
d_1 & 0 & \cdots & 0 \\
0 & d_2 & \cdots & 0 \\
\vdots & \vdots & & \vdots \\
0 & 0 & \cdots & d_N \\
\end{array}
\right)
%
\end{split}
\end{equation*}
\sphinxAtStartPar
Often written as
\begin{equation*}
\begin{split}
%
{\bf D} = \mathrm{diag}(d_1, \ldots, d_N) 
%
\end{split}
\end{equation*}
\sphinxAtStartPar
Incidentally, the same notation works in Python

\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{import} \PYG{n+nn}{numpy} \PYG{k}{as} \PYG{n+nn}{np}
\PYG{n}{D} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{diag}\PYG{p}{(}\PYG{p}{(}\PYG{l+m+mi}{2}\PYG{p}{,} \PYG{l+m+mi}{4}\PYG{p}{,} \PYG{l+m+mi}{6}\PYG{p}{,} \PYG{l+m+mi}{8}\PYG{p}{,} \PYG{l+m+mi}{10}\PYG{p}{)}\PYG{p}{)}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{n}{D}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
[[ 2  0  0  0  0]
 [ 0  4  0  0  0]
 [ 0  0  6  0  0]
 [ 0  0  0  8  0]
 [ 0  0  0  0 10]]
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\sphinxAtStartPar
Diagonal systems are very easy to solve

\begin{sphinxadmonition}{note}{Example}
\begin{equation*}
\begin{split}
%
\begin{pmatrix}
d_1 & 0 & 0 \\
0 & d_2 & 0 \\
0 & 0 & d_3 
\end{pmatrix}
\begin{pmatrix}
x_1 \\
x_2 \\
x_3 
\end{pmatrix}
=
\begin{pmatrix}
b_1 \\
b_2 \\
b_3 
\end{pmatrix}
%
\end{split}
\end{equation*}
\sphinxAtStartPar
is equivalent to
\begin{equation*}
\begin{split}
%
\begin{array}{c}
d_1 x_1 = b_1 \\
d_2x_2 = b_2 \\
d_3 x_3 = b_3
\end{array}
%
\end{split}
\end{equation*}\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Fact}

\sphinxAtStartPar
If \({\bf C} = \mathrm{diag}(c_1, \ldots, c_N)\) and \({\bf D} = \mathrm{diag}(d_1, \ldots,d_N)\) then
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
\({\bf C} + {\bf D} = \mathrm{diag}(c_1 + d_1, \ldots, c_N + d_N)\)

\item {} 
\sphinxAtStartPar
\({\bf C} {\bf D} = \mathrm{diag}(c_1 d_1, \ldots, c_N d_N)\)

\item {} 
\sphinxAtStartPar
\({\bf D}^k = \mathrm{diag}(d^k_1, \ldots, d^k_N)\) for any \(k \in \mathbb{N}\)

\item {} 
\sphinxAtStartPar
\(d_n \geq 0\) for all \(n\) \(\implies\) \({\bf D}^{1/2}\) exists and equals

\end{enumerate}
\begin{equation*}
\begin{split}\mathrm{diag}(\sqrt{d_1}, \ldots, \sqrt{d_N})\end{split}
\end{equation*}\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\setcounter{enumi}{4}
\item {} 
\sphinxAtStartPar
\(d_n \ne 0\) for all \(n\) \(\implies\) \({\bf D}\) is nonsingular and

\end{enumerate}
\begin{equation*}
\begin{split}{\bf D}^{-1} = \mathrm{diag}(d_1^{-1}, \ldots, d_N^{-1})\end{split}
\end{equation*}\end{sphinxadmonition}

\sphinxAtStartPar
Proofs: Check 1 and 2 directly, other parts follow

\begin{sphinxadmonition}{note}{Definition}

\sphinxAtStartPar
A square matrix is called \sphinxstyleemphasis{\sphinxstylestrong{lower triangular}} if every element strictly above the principle diagonal is zero
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Example}
\begin{equation}\label{equation:05.linear_algebra:eq:ltute}
\begin{split}
%
{\bf L} :=
\left(
\begin{array}{ccc}
1 & 0 & 0 \\
2 & 5 & 0 \\
3 & 6 & 1
\end{array}
\right)
%
\end{split}
\end{equation}\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Definition}

\sphinxAtStartPar
A square matrix is called \sphinxstyleemphasis{\sphinxstylestrong{upper triangular}} if every element
strictly below the principle diagonal is zero
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Example}
\begin{equation*}
\begin{split}
%
{\bf U} :=
\left(
\begin{array}{ccc}
1 & 2 & 3 \\
0 & 5 & 6 \\
0 & 0 & 1
\end{array}
\right)
%
\end{split}
\end{equation*}\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Definition}

\sphinxAtStartPar
A matrix is called \sphinxstyleemphasis{\sphinxstylestrong{triangular}} if either upper or lower triangular
\end{sphinxadmonition}

\sphinxAtStartPar
Associated linear equations also simple to solve

\begin{sphinxadmonition}{note}{Example}
\begin{equation*}
\begin{split}
%
\left(
\begin{array}{ccc}
4 & 0 & 0 \\
2 & 5 & 0 \\
3 & 6 & 1
\end{array}
\right)
\left(
\begin{array}{ccc}
x_1 \\
x_2 \\
x_3 
\end{array}
\right)
=
\left(
\begin{array}{c}
b_1 \\
b_2 \\
b_3 \\
\end{array}
\right)
%
\end{split}
\end{equation*}
\sphinxAtStartPar
becomes
\begin{equation*}
\begin{split}
%
\begin{array}{c}
4x_1 = b_1 \\
2x_1 + 5x_2 = b_2 \\
3x_1 + 6x_2 + x_3 = b_3
\end{array}
%
\end{split}
\end{equation*}
\sphinxAtStartPar
Top equation involves only \(x_1\), so can solve for it directly
\end{sphinxadmonition}

\sphinxAtStartPar
Plug that value into second equation, solve out for \(x_2\), etc.


\section{Eigenvalues and Eigenvectors}
\label{\detokenize{05.linear_algebra:eigenvalues-and-eigenvectors}}
\sphinxAtStartPar
Let \({\bf A}\) be \(N \times N\)

\sphinxAtStartPar
In general \({\bf A}\) maps \({\bf x}\) to some arbitrary new location \({\bf A} {\bf x}\)

\sphinxAtStartPar
But sometimes \({\bf x}\) will only be \sphinxstyleemphasis{\sphinxstylestrong{scaled}}:
\begin{equation}\label{equation:05.linear_algebra:eq:eiei}
\begin{split}
%
{\bf A} {\bf x} = \lambda {\bf x}
\quad \text{for some scalar $\lambda$}
%
\end{split}
\end{equation}
\begin{sphinxadmonition}{note}{Definition}

\sphinxAtStartPar
If \eqref{equation:05.linear_algebra:eq:eiei} holds and \({\bf x}\) is nonzero, then
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
\({\bf x}\) is called an \sphinxstyleemphasis{\sphinxstylestrong{eigenvector}} of \({\bf A}\)
and \(\lambda\) is called an \sphinxstyleemphasis{\sphinxstylestrong{eigenvalue}}

\item {} 
\sphinxAtStartPar
\(({\bf x}, \lambda)\) is called an \sphinxstyleemphasis{\sphinxstylestrong{eigenpair}}

\end{enumerate}
\end{sphinxadmonition}

\sphinxAtStartPar
Clearly \(({\bf x}, \lambda)\) is an eigenpair of \({\bf A}\) \(\implies\)
\((\alpha {\bf x}, \lambda)\) is an eigenpair of \({\bf A}\) for any nonzero \(\alpha\)

\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
Let
\begin{equation*}
\begin{split}
%
{\bf A} :=
\begin{pmatrix}
1 & -1 \\
3 & 5
\end{pmatrix}
%
\end{split}
\end{equation*}
\sphinxAtStartPar
Then
\begin{equation*}
\begin{split}
%
\lambda = 2 
\quad \text{ and } \quad
{\bf x}
=
\begin{pmatrix}
1 \\
-1
\end{pmatrix}
%
\end{split}
\end{equation*}
\sphinxAtStartPar
form an eigenpair because \({\bf x} \ne {\bf 0}\) and
\begin{equation*}
\begin{split}
%
{\bf A} {\bf x} =
\begin{pmatrix}
1 & -1 \\
3 & 5
\end{pmatrix}
\begin{pmatrix}
1 \\
-1
\end{pmatrix}
=
\begin{pmatrix}
2 \\
-2
\end{pmatrix}
= 2
\begin{pmatrix}
1 \\
-1
\end{pmatrix}
=
\lambda {\bf x} 
%
\end{split}
\end{equation*}\end{sphinxadmonition}

\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{import} \PYG{n+nn}{numpy} \PYG{k}{as} \PYG{n+nn}{np}
\PYG{n}{A} \PYG{o}{=} \PYG{p}{[}\PYG{p}{[}\PYG{l+m+mi}{1}\PYG{p}{,} \PYG{l+m+mi}{2}\PYG{p}{]}\PYG{p}{,}
     \PYG{p}{[}\PYG{l+m+mi}{2}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{]}\PYG{p}{]}
\PYG{n}{eigvals}\PYG{p}{,} \PYG{n}{eigvecs} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{linalg}\PYG{o}{.}\PYG{n}{eig}\PYG{p}{(}\PYG{n}{A}\PYG{p}{)}
\PYG{k}{for} \PYG{n}{i} \PYG{o+ow}{in} \PYG{n+nb}{range}\PYG{p}{(}\PYG{n}{eigvals}\PYG{o}{.}\PYG{n}{size}\PYG{p}{)}\PYG{p}{:}
  \PYG{n}{x} \PYG{o}{=} \PYG{n}{eigvecs}\PYG{p}{[}\PYG{p}{:}\PYG{p}{,}\PYG{n}{i}\PYG{p}{]}
  \PYG{n}{lm} \PYG{o}{=} \PYG{n}{eigvals}\PYG{p}{[}\PYG{n}{i}\PYG{p}{]}
  \PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+sa}{f}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Eigenpair }\PYG{l+s+si}{\PYGZob{}}\PYG{n}{i}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s1}{:}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+si}{\PYGZob{}}\PYG{n}{lm}\PYG{l+s+si}{:}\PYG{l+s+s1}{.5f}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s1}{ \PYGZhy{}\PYGZhy{}\PYGZgt{} }\PYG{l+s+si}{\PYGZob{}}\PYG{n}{x}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
  \PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+sa}{f}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Check Ax=lm*x: }\PYG{l+s+si}{\PYGZob{}}\PYG{n}{np}\PYG{o}{.}\PYG{n}{dot}\PYG{p}{(}\PYG{n}{A}\PYG{p}{,}\PYG{+w}{ }\PYG{n}{x}\PYG{p}{)}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s1}{ = }\PYG{l+s+si}{\PYGZob{}}\PYG{n}{lm}\PYG{+w}{ }\PYG{o}{*}\PYG{+w}{ }\PYG{n}{x}\PYG{l+s+si}{\PYGZcb{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
Eigenpair 0:
3.00000 \PYGZhy{}\PYGZhy{}\PYGZgt{} [0.70710678 0.70710678]
Check Ax=lm*x: [2.12132034 2.12132034] = [2.12132034 2.12132034]
Eigenpair 1:
\PYGZhy{}1.00000 \PYGZhy{}\PYGZhy{}\PYGZgt{} [\PYGZhy{}0.70710678  0.70710678]
Check Ax=lm*x: [ 0.70710678 \PYGZhy{}0.70710678] = [ 0.70710678 \PYGZhy{}0.70710678]
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{eigenvecs}.png}
\caption{The eigenvectors of \({\bf A}\)}\label{\detokenize{05.linear_algebra:id17}}\end{figure}

\sphinxAtStartPar
Consider the matrix
\begin{equation*}
\begin{split}
%
{\bf R} := 
\left(
\begin{array}{cc}
0 & -1 \\
1 & 0 \\
\end{array}
\right)
%
\end{split}
\end{equation*}
\sphinxAtStartPar
Induces counter\sphinxhyphen{}clockwise rotation on any point by \(90^{\circ}\)

\begin{sphinxadmonition}{hint}{Hint:}
\sphinxAtStartPar
The rows of the matrix show where the classic basis vectors are translated to.
\end{sphinxadmonition}

\sphinxAtStartPar
Hence no point \({\bf x}\) is scaled

\sphinxAtStartPar
Hence there exists \sphinxstyleemphasis{\sphinxstylestrong{no}} pair \(\lambda \in \mathbb{R}\) and \({\bf x} \ne
{\bf 0}\)
such that
\begin{equation*}
\begin{split}{\bf R} {\bf x} = \lambda {\bf x}\end{split}
\end{equation*}
\sphinxAtStartPar
In other words, no \sphinxstyleemphasis{\sphinxstylestrong{real\sphinxhyphen{}valued}} eigenpairs exist

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{rotation_1}.png}
\caption{The matrix \({\bf R}\) rotates points by \(90^{\circ}\)}\label{\detokenize{05.linear_algebra:id18}}\end{figure}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{rotation_2}.png}
\caption{The matrix \({\bf R}\) rotates points by \(90^{\circ}\)}\label{\detokenize{05.linear_algebra:id19}}\end{figure}

\sphinxAtStartPar
But \({\bf R} {\bf x} = \lambda {\bf x}\) can hold \sphinxstyleemphasis{\sphinxstylestrong{if}} we allow
complex values

\begin{sphinxadmonition}{note}{Example}
\begin{equation*}
\begin{split}
%
\left(
\begin{array}{cc}
0 & -1 \\
1 & 0 \\
\end{array}
\right)
\begin{pmatrix}
1 \\
-i
\end{pmatrix}
=
\begin{pmatrix}
i \\
1
\end{pmatrix}
=
i
\begin{pmatrix}
1 \\
-i
\end{pmatrix}
%
\end{split}
\end{equation*}\end{sphinxadmonition}

\sphinxAtStartPar
That is,
\begin{equation*}
\begin{split}
%
{\bf R} {\bf x} = \lambda {\bf x}
\quad \text{for} \quad
\lambda := i
\quad \text{and} \quad
{\bf x} := 
\begin{pmatrix}
1 \\
-i
\end{pmatrix}
%
\end{split}
\end{equation*}
\sphinxAtStartPar
Hence \(({\bf x}, \lambda)\) is an eigenpair provided we admit complex values

\begin{sphinxadmonition}{note}{Note:}
\sphinxAtStartPar
We do, since this is standard, but will not go into details in this course
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Fact}

\sphinxAtStartPar
For any square matrix \({\bf A}\)
\begin{equation*}
\begin{split}
%
\lambda \text{ is an eigenvalue of } {\bf A} \; \iff \;
\det({\bf A} - \lambda {\bf I}) = 0
%
\end{split}
\end{equation*}\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Proof}

\sphinxAtStartPar
Let \({\bf A}\) by \(N \times N\) and let \({\bf I}\) be the \(N \times N\)
identity

\sphinxAtStartPar
We have
\begin{equation*}
\begin{split}
%
\det({\bf A} - \lambda {\bf I}) = 0
\iff {\bf A} - \lambda {\bf I} \text{ is singular}
\\
\iff \exists \, {\bf x} \ne {\bf 0} \text{ such that }
({\bf A} - \lambda {\bf I}) {\bf x} = {\bf 0}
\\
\iff \exists \, {\bf x} \ne {\bf 0} \text{ such that }
{\bf A} {\bf x} = \lambda {\bf x}
\\
\iff \lambda 
\text{ is an eigenvalue of } {\bf A}
%
\end{split}
\end{equation*}\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
In the \(2 \times 2\) case,
\begin{equation*}
\begin{split}
%
{\bf A} =
\left(
\begin{array}{cc}
a & b \\
c & d \\
\end{array}
\right)
\quad \implies \quad
{\bf A} - \lambda {\bf I} =
\left(
\begin{array}{cc}
a - \lambda & b \\
c & d - \lambda 
\end{array}
\right)
%
\end{split}
\end{equation*}\begin{equation*}
\begin{split}
%
\implies
\det({\bf A} - \lambda {\bf I}) 
= (a - \lambda)(d - \lambda) - bc
\\
= \lambda^2 - (a + d) \lambda + (ad - bc)
%
\end{split}
\end{equation*}
\sphinxAtStartPar
Hence the eigenvalues of \({\bf A}\) are given by the two roots of
\begin{equation*}
\begin{split}
%
\lambda^2 - (a + d) \lambda + (ad - bc) = 0
%
\end{split}
\end{equation*}
\sphinxAtStartPar
Equivalently,
\begin{equation*}
\begin{split}
%
\lambda^2 - \mathrm{trace}({\bf A}) \lambda + \det({\bf A}) = 0
%
\end{split}
\end{equation*}\end{sphinxadmonition}




\subsection{Diagonalization}
\label{\detokenize{05.linear_algebra:diagonalization}}
\begin{sphinxadmonition}{note}{Definition}

\sphinxAtStartPar
Square matrix \({\bf A}\) is said to be \sphinxstyleemphasis{\sphinxstylestrong{similar}} to square matrix \({\bf B}\) if
\begin{equation*}
\begin{split}
%
\exists \text{ invertible matrix ${\bf P}$ such that }
{\bf A} = {\bf P} {\bf B} {\bf P}^{-1}
%
\end{split}
\end{equation*}\end{sphinxadmonition}

\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics{{diagonalize}.png}
\end{figure}

\begin{sphinxadmonition}{note}{Fact}

\sphinxAtStartPar
If \({\bf A}\) is similar to \({\bf B}\), then \({\bf A}^t\) is similar to
\({\bf B}^t\) for all \(t \in \mathbb{N}\)
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Proof}

\sphinxAtStartPar
Proof for case \(t=2\):
\begin{equation*}
\begin{split}
%
{\bf A}^2
= {\bf A} {\bf A} \\
= {\bf P} {\bf B} {\bf P}^{-1} {\bf P} {\bf B} {\bf P}^{-1} \\
= {\bf P} {\bf B} {\bf B} {\bf P}^{-1} \\
= {\bf P} {\bf B}^2 {\bf P}^{-1} 
%
\end{split}
\end{equation*}\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Definition}

\sphinxAtStartPar
If \({\bf A}\) is similar to a diagonal matrix, then \({\bf A}\) is
called \sphinxstyleemphasis{\sphinxstylestrong{diagonalizable}}
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Fact}

\sphinxAtStartPar
Let \({\bf A}\) be diagonalizable with \({\bf A} = {\bf P} {\bf D}
{\bf P}^{-1}\) and let
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
\({\bf D} = \mathrm{diag}(\lambda_1, \ldots, \lambda_N)\)

\item {} 
\sphinxAtStartPar
\({\bf p}_n := \mathrm{col}_n({\bf P})\)

\end{enumerate}

\sphinxAtStartPar
Then \(({\bf p}_n, \lambda_n)\) is an eigenpair of \({\bf A}\) for each \(n\)
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Proof}

\sphinxAtStartPar
From \({\bf A} = {\bf P} {\bf D} {\bf P}^{-1}\) we get \({\bf A} {\bf P} = {\bf P} {\bf D}\)

\sphinxAtStartPar
Equating \(n\)\sphinxhyphen{}th column on each side gives
\begin{equation*}
\begin{split}
%
{\bf A} {\bf p}_n = \lambda_n {\bf p}_n
%
\end{split}
\end{equation*}
\sphinxAtStartPar
Moreover \({\bf p}_n \ne {\bf 0}\) because \({\bf P}\) is invertible (which facts?)
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Fact}

\sphinxAtStartPar
If \(N \times N\) matrix \({\bf A}\) has \(N\) distinct eigenvalues
\(\lambda_1, \ldots, \lambda_N\), then
\({\bf A}\) is diagonalizable as \({\bf A} = {\bf P} {\bf D} {\bf P}^{-1}\) where
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
\({\bf D} = \mathrm{diag}(\lambda_1, \ldots, \lambda_N)\)

\item {} 
\sphinxAtStartPar
\(\mathrm{col}_n({\bf P})\) is an eigenvector for \(\lambda_n\)

\end{enumerate}
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
Let
\begin{equation*}
\begin{split}
%
{\bf A} :=
\begin{pmatrix}
1 & -1 \\
3 & 5
\end{pmatrix}
%
\end{split}
\end{equation*}
\sphinxAtStartPar
The eigenvalues of \({\bf A}\) are 2 and 4, while the eigenvectors are
\begin{equation*}
\begin{split}
%
{\bf p}_1 :=
\begin{pmatrix}
1 \\
-1
\end{pmatrix}
\quad \text{and} \quad
{\bf p}_2 :=
\begin{pmatrix}
1 \\
-3
\end{pmatrix}
%
\end{split}
\end{equation*}
\sphinxAtStartPar
Hence
\begin{equation*}
\begin{split}
%
{\bf A} = {\bf P} \mathrm{diag}(2, 4) {\bf P}^{-1}
%
\end{split}
\end{equation*}\end{sphinxadmonition}

\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{import} \PYG{n+nn}{numpy} \PYG{k}{as} \PYG{n+nn}{np}
\PYG{k+kn}{from} \PYG{n+nn}{numpy}\PYG{n+nn}{.}\PYG{n+nn}{linalg} \PYG{k+kn}{import} \PYG{n}{inv}
\PYG{n}{A} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{array}\PYG{p}{(}\PYG{p}{[}\PYG{p}{[}\PYG{l+m+mi}{1}\PYG{p}{,} \PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{1}\PYG{p}{]}\PYG{p}{,}
              \PYG{p}{[}\PYG{l+m+mi}{3}\PYG{p}{,} \PYG{l+m+mi}{5}\PYG{p}{]}\PYG{p}{]}\PYG{p}{)}
\PYG{n}{eigvals}\PYG{p}{,} \PYG{n}{eigvecs} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{linalg}\PYG{o}{.}\PYG{n}{eig}\PYG{p}{(}\PYG{n}{A}\PYG{p}{)}
\PYG{n}{D} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{diag}\PYG{p}{(}\PYG{n}{eigvals}\PYG{p}{)}
\PYG{n}{P} \PYG{o}{=} \PYG{n}{eigvecs}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{A =}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}\PYG{n}{A}\PYG{p}{,}\PYG{n}{sep}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{D =}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}\PYG{n}{D}\PYG{p}{,}\PYG{n}{sep}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{P =}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}\PYG{n}{P}\PYG{p}{,}\PYG{n}{sep}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{P\PYGZca{}\PYGZhy{}1 =}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}\PYG{n}{inv}\PYG{p}{(}\PYG{n}{P}\PYG{p}{)}\PYG{p}{,}\PYG{n}{sep}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{P*D*P\PYGZca{}\PYGZhy{}1 =}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}\PYG{n}{P}\PYG{n+nd}{@D}\PYG{n+nd}{@inv}\PYG{p}{(}\PYG{n}{P}\PYG{p}{)}\PYG{p}{,}\PYG{n}{sep}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
A =
[[ 1 \PYGZhy{}1]
 [ 3  5]]
D =
[[2. 0.]
 [0. 4.]]
P =
[[\PYGZhy{}0.70710678  0.31622777]
 [ 0.70710678 \PYGZhy{}0.9486833 ]]
P\PYGZca{}\PYGZhy{}1 =
[[\PYGZhy{}2.12132034 \PYGZhy{}0.70710678]
 [\PYGZhy{}1.58113883 \PYGZhy{}1.58113883]]
P*D*P\PYGZca{}\PYGZhy{}1 =
[[ 1. \PYGZhy{}1.]
 [ 3.  5.]]
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}

\subsection{The Euclidean Matrix Norm}
\label{\detokenize{05.linear_algebra:the-euclidean-matrix-norm}}
\sphinxAtStartPar
The concept of norm is very helpful for working with vectors:
provides notions of distance, similarity, convergence

\sphinxAtStartPar
How about an analogous concept for matrices?

\begin{sphinxadmonition}{note}{Definition}

\sphinxAtStartPar
Given \(N \times K\) matrix \({\bf A}\), denote
\(\| {\bf A} \|\) the \sphinxstyleemphasis{\sphinxstylestrong{matrix norm}} of \({\bf A}\).

\sphinxAtStartPar
\sphinxstyleemphasis{\sphinxstylestrong{Euclidean matrix norm}} is defined by
\begin{equation*}
\begin{split}
%
\| {\bf A} \| :=
\max \left\{ 
\frac{\| {\bf A} {\bf x} \|}{ \| {\bf x} \|} \,: \, 
{\bf x} \in \mathbb{R}^K, \; {\bf x} \ne {\bf 0}
\right\}
%
\end{split}
\end{equation*}\end{sphinxadmonition}

\sphinxAtStartPar
In the maximization we can restrict attention to \({\bf x}\) s.t. \(\| {\bf x} \| = 1\)

\sphinxAtStartPar
To see this let
\begin{equation*}
\begin{split}
%
a :=
\max_{{\bf x} \ne {\bf 0}} \frac{\| {\bf A} {\bf x} \|}{ \| {\bf x} \|} 
\qquad \text{and} \qquad
b :=
\max_{\| {\bf x} \| = 1} \frac{\| {\bf A} {\bf x} \|}{ \| {\bf x} \|} 
= \max_{\| {\bf x} \| = 1} \| {\bf A} {\bf x} \|
%
\end{split}
\end{equation*}
\sphinxAtStartPar
Evidently \(a \geq b\) because max is over a larger domain

\sphinxAtStartPar
To see the reverse let
\begin{itemize}
\item {} 
\sphinxAtStartPar
\({\bf x}_a\) be the maximizer over \({\bf x} \ne {\bf 0}\) and
let \(\alpha := 1 / \| {\bf x}_a\|\)

\item {} 
\sphinxAtStartPar
\({\bf x}_b := \alpha {\bf x}_a \)

\end{itemize}

\sphinxAtStartPar
Then
\begin{equation*}
\begin{split}
%
b 
\geq \frac{ \| {\bf A} {\bf x}_b \| }{ \| {\bf x}_b \|}
= \frac{ \| \alpha {\bf A} {\bf x}_a \| }{ \| \alpha {\bf x}_a \|}
= \frac{\alpha}{\alpha} \frac{\| {\bf A} {\bf x}_a \|}{ \| {\bf x}_a \|}
= a
%
\end{split}
\end{equation*}


\begin{sphinxadmonition}{note}{Definition}

\sphinxAtStartPar
If \(\| {\bf A} \| < 1\) then \({\bf A}\) is called \sphinxstyleemphasis{\sphinxstylestrong{contractive}} — it
shrinks the norm
\end{sphinxadmonition}

\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics{{contractive}.png}
\end{figure}

\sphinxAtStartPar
The matrix norm has similar properties to the Euclidean norm

\begin{sphinxadmonition}{note}{Fact}

\sphinxAtStartPar
For conformable matrices \({\bf A}\) and \({\bf B}\), we have
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
\(\| {\bf A} \| = {\bf 0}\) if and only if all entries of
\({\bf A}\) are zero

\item {} 
\sphinxAtStartPar
\(\| \alpha {\bf A} \| = |\alpha| \| {\bf A} \|\) for any scalar
\(\alpha\)

\item {} 
\sphinxAtStartPar
\(\| {\bf A} + {\bf B} \| \leq \| {\bf A} \| + \| {\bf B} \|\)

\item {} 
\sphinxAtStartPar
\(\| {\bf A} {\bf B} \| \leq \| {\bf A} \| \| {\bf B} \|\)

\end{enumerate}

\sphinxAtStartPar
The last inequality is called the submultiplicative property of the matrix
norm
\end{sphinxadmonition}

\sphinxAtStartPar
For square \({\bf A}\) it implies that \(\|{\bf A}^k\| \leq \|{\bf A} \|^k\) for any \(k \in \mathbb{N}\)

\begin{sphinxadmonition}{note}{Fact}

\sphinxAtStartPar
For the diagonal matrix
\begin{equation*}
\begin{split}
%
{\bf D} = 
\mathrm{diag}(d_1, \ldots, d_N) 
=
\left(
\begin{array}{cccc}
d_1 & 0 & \cdots & 0 \\
0 & d_2 & \cdots & 0 \\
\vdots & \vdots & & \vdots \\
0 & 0 & \cdots & d_N \\
\end{array}
\right)
%
\end{split}
\end{equation*}
\sphinxAtStartPar
we have
\begin{equation*}
\begin{split} 
%
\| {\bf D} \| = \max_n |d_n|
%
\end{split}
\end{equation*}\end{sphinxadmonition}

\sphinxAtStartPar
We can use matrices as elements of sequences

\sphinxAtStartPar
Let \(\{ {\bf A}_j \}\) and \({\bf A}\) be \(N \times K\) matrices
\begin{itemize}
\item {} 
\sphinxAtStartPar
If \(\| {\bf A}_j - {\bf A} \| \to 0\) then we say that \({\bf A}_j\)
\sphinxstyleemphasis{\sphinxstylestrong{converges}} to \({\bf A}\)

\item {} 
\sphinxAtStartPar
If \(\sum_{j=1}^J {\bf A}_j\) converges to some matrix
\({\bf B}_{\infty}\) as \(J \to \infty\) we write

\end{itemize}
\begin{equation*}
\begin{split}
%
\sum_{j=1}^{\infty} {\bf A}_j = {\bf B}_{\infty}
%
\end{split}
\end{equation*}
\sphinxAtStartPar
In other words,
\begin{equation*}
\begin{split}
%
{\bf B}_{\infty} = \sum_{j=1}^{\infty} {\bf A}_j 
\quad \iff \quad
\lim_{J \to \infty}
\;
\left\| \sum_{j=1}^J {\bf A}_j - {\bf B}_{\infty} \right\|
\to 0
%
\end{split}
\end{equation*}

\subsection{Neumann Series {[}optional{]}}
\label{\detokenize{05.linear_algebra:neumann-series-optional}}
\sphinxAtStartPar
Consider the difference equation \({\bf x}_{t+1} = {\bf A} {\bf x}_t + {\bf b}\), where
\begin{itemize}
\item {} 
\sphinxAtStartPar
\({\bf x}_t \in \mathbb{R}^N\) represents the values of some variables at time \(t\)

\item {} 
\sphinxAtStartPar
\({\bf A}\) and \({\bf b}\) form the parameters in the law of motion for \({\bf x}_t\)

\end{itemize}

\sphinxAtStartPar
Question of interest: is there an \({\bf x}\) such that
\begin{equation*}
\begin{split}
%
{\bf x}_t = {\bf x} \; \implies \; {\bf x}_{t+1} = {\bf x}
%
\end{split}
\end{equation*}
\sphinxAtStartPar
In other words, we seek an \({\bf x} \in \mathbb{R}^N\) that solves the system of equations
\begin{equation*}
\begin{split}
%
{\bf x} = {\bf A} {\bf x} + {\bf b}, 
\quad \text{where} \quad {\bf A} \text{ is } N \times N
\text{ and } {\bf b} \text{ is } N \times 1
%
\end{split}
\end{equation*}
\sphinxAtStartPar
We can get some insight from the scalar case \(x_{t+1} = a x_t + b\)

\sphinxAtStartPar
If \(|a| < 1\), then this equation has the solution
\begin{equation*}
\begin{split}
%
\bar x 
= \frac{b}{1-a} 
= b \sum_{k=0}^{\infty} a^k 
%
\end{split}
\end{equation*}
\sphinxAtStartPar
Does an analogous result hold in the vector case \({\bf x} = {\bf A} {\bf x} + {\bf b}\)?

\sphinxAtStartPar
Yes, if we replace condition \(|a| < 1\) with \(\| {\bf A} \| < 1\)

\sphinxAtStartPar
Let \({\bf b}\) be any vector in \(\mathbb{R}^N\) and \({\bf A}\) be an \(N \times N\) matrix

\sphinxAtStartPar
The next result is called the \sphinxstyleemphasis{\sphinxstylestrong{Neumann series lemma}}

\begin{sphinxadmonition}{note}{Fact}

\sphinxAtStartPar
If \(\| {\bf A}^k \| < 1\) for some \(k \in \mathbb{N}\), then \({\bf I} - {\bf A}\) is invertible and
\begin{equation*}
\begin{split}
%
({\bf I} - {\bf A})^{-1} = \sum_{j=0}^{\infty} {\bf A}^j
%
\end{split}
\end{equation*}
\sphinxAtStartPar
In this case \({\bf x} = {\bf A} {\bf x} + {\bf b}\) has the unique solution
\begin{equation*}
\begin{split}
%
\bar {\bf x} = \sum_{j=0}^{\infty} {\bf A}^j {\bf b} 
%
\end{split}
\end{equation*}\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Proof}

\sphinxAtStartPar
Sketch of proof that \(({\bf I} - {\bf A})^{-1} = \sum_{j=0}^{\infty} {\bf A}^j\)
for case \(\|{\bf A} \| < 1\)

\sphinxAtStartPar
We have \(({\bf I} - {\bf A}) \sum_{j=0}^{\infty} {\bf A}^j =
{\bf I} \) because
\begin{equation*}
\begin{split}
%
\left\|
({\bf I} - {\bf A}) \sum_{j=0}^{\infty} {\bf A}^j - {\bf I}
\right\|
=
\left\|
({\bf I} - {\bf A}) \lim_{J \to \infty}\sum_{j=0}^J {\bf A}^j - {\bf I}
\right\|
\\
=
\lim_{J \to \infty}
\left\|
({\bf I} - {\bf A}) \sum_{j=0}^J {\bf A}^j - {\bf I}
\right\|
\\
=
\lim_{J \to \infty}
\left\|
{\bf A}^J 
\right\|
\\
\leq
\lim_{J \to \infty}
\left\| {\bf A} \right\|^J = 0
%
\end{split}
\end{equation*}\end{sphinxadmonition}

\sphinxAtStartPar
How to test the hypotheses of the Neumann series lemma?

\begin{sphinxadmonition}{note}{Definition}

\sphinxAtStartPar
The \sphinxstyleemphasis{\sphinxstylestrong{spectral radius}} of square matrix \({\bf A}\) is
\begin{equation*}
\begin{split}
%
\rho({\bf A}) := \max \{ |\lambda| \colon \lambda \text{ is an eigenvalue of \} {\bf A}}
%
\end{split}
\end{equation*}\end{sphinxadmonition}

\sphinxAtStartPar
Here \(|\lambda|\) is the \sphinxstyleemphasis{\sphinxstylestrong{modulus}} of the possibly complex number \(\lambda\).
That is, if \(\lambda = a + ib\), then \(|\lambda| = \sqrt{a^2 + b^2}\).




\section{Quadratic Forms}
\label{\detokenize{05.linear_algebra:quadratic-forms}}
\sphinxAtStartPar
Up till now we have studied linear functions extensively

\sphinxAtStartPar
Next level of complexity is quadratic maps

\begin{sphinxadmonition}{note}{Definition}

\sphinxAtStartPar
Let \({\bf A}\) be \(N \times N\) and symmetric, and let \({\bf x}\) be \(N \times 1\)

\sphinxAtStartPar
The \sphinxstyleemphasis{\sphinxstylestrong{quadratic function}} on \(\mathbb{R}^N\) associated with \({\bf A}\) is the map
\begin{equation*}
\begin{split}
%
Q \colon \mathbb{R}^N \to \mathbb{R}, \qquad
Q({\bf x}) := {\bf x}' {\bf A} {\bf x} = \sum_{j=1}^N \sum_{i=1}^N a_{ij} x_i x_j
%
\end{split}
\end{equation*}\end{sphinxadmonition}

\sphinxAtStartPar
The properties of \(Q\) depend on \({\bf A}\)

\sphinxAtStartPar
An \(N \times N\) symmetric matrix \({\bf A}\) is called
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
\sphinxstyleemphasis{\sphinxstylestrong{nonnegative definite}} if \({\bf x}' {\bf A} {\bf x} \geq 0\)
for all \({\bf x} \in \mathbb{R}^N\)

\end{enumerate}
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleemphasis{\sphinxstylestrong{positive definite}} if \({\bf x}' {\bf A} {\bf x} > 0\) for all \({\bf x}
\in \mathbb{R}^N\) with \({\bf x} \ne {\bf 0}\)

\item {} 
\sphinxAtStartPar
\sphinxstyleemphasis{\sphinxstylestrong{nonpositive definite}} if \({\bf x}' {\bf A} {\bf x} \leq 0\)
for all \({\bf x} \in \mathbb{R}^N\)

\item {} 
\sphinxAtStartPar
\sphinxstyleemphasis{\sphinxstylestrong{negative definite}} if \({\bf x}' {\bf A} {\bf x} < 0\) for all \({\bf x}
\in \mathbb{R}^N\) with \({\bf x} \ne {\bf 0}\)

\end{itemize}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{qform_pd}.png}
\caption{A positive definite case: \(Q({\bf x}) = {\bf x}' {\bf I} {\bf x}\)}\label{\detokenize{05.linear_algebra:f-qform-pd}}\end{figure}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{qform_nd}.png}
\caption{A negative definite case: \(Q({\bf x}) =
{\bf x}'(-{\bf I}){\bf x}\)}\label{\detokenize{05.linear_algebra:f-qform-nd}}\end{figure}

\sphinxAtStartPar
Note that some matrices have none of these properties
\begin{itemize}
\item {} 
\sphinxAtStartPar
\({\bf x}' {\bf A} {\bf x} < 0\) for some \({\bf x}\)

\item {} 
\sphinxAtStartPar
\({\bf x}' {\bf A} {\bf x} > 0\) for other \({\bf x}\)

\end{itemize}

\sphinxAtStartPar
In this case \({\bf A}\) is called \sphinxstyleemphasis{\sphinxstylestrong{indefinite}}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{qform_indef}.png}
\caption{Indefinite quadratic function \(Q({\bf x}) = x_1^2/2 +
8 x_1 x_2 + x_2^2/2\)}\label{\detokenize{05.linear_algebra:f-qform-indef}}\end{figure}

\begin{sphinxadmonition}{note}{Fact}

\sphinxAtStartPar
A symmetric matrix \({\bf A}\) is
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
positive definite \(\iff\) all eigenvalues are strictly positive

\end{enumerate}
\begin{itemize}
\item {} 
\sphinxAtStartPar
negative definite \(\iff\) all eigenvalues are strictly negative

\item {} 
\sphinxAtStartPar
nonpositive definite \(\iff\) all eigenvalues are nonpositive

\end{itemize}
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\setcounter{enumi}{8}
\item {} 
\sphinxAtStartPar
nonnegative definite \(\iff\) all eigenvalues are nonnegative

\end{enumerate}
\end{sphinxadmonition}

\sphinxAtStartPar
It follows that
\begin{itemize}
\item {} 
\sphinxAtStartPar
\({\bf A}\) is positive definite \(\implies\) \(\det({\bf A}) > 0\)

\end{itemize}

\sphinxAtStartPar
In particular, \({\bf A}\) is nonsingular


\section{Extra study material}
\label{\detokenize{05.linear_algebra:extra-study-material}}\label{\detokenize{05.linear_algebra:id1}}
\sphinxAtStartPar
Watch \sphinxhref{https://youtu.be/fNk\_zzaMoSs?si=X6EK-AqVhQOBplZj}{excellent video series on linear algebra} by Grant Sanderson (3blue1brown) — best visualisations for strong intuition

\sphinxstepscope


\chapter{Fundamentals of optimization}
\label{\detokenize{06.optimization_fundamentals:fundamentals-of-optimization}}\label{\detokenize{06.optimization_fundamentals::doc}}
\sphinxAtStartPar
\sphinxstylestrong{ECON2125/6012 Lecture 6}
Fedor Iskhakov


\section{Announcements \& Reminders}
\label{\detokenize{06.optimization_fundamentals:announcements-reminders}}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleemphasis{Test 1} results and discussion

\item {} 
\sphinxAtStartPar
\sphinxstyleemphasis{Test 2} due date \sphinxstylestrong{extended to Sept 6th (23:59)}

\end{itemize}


\section{Plan for this lecture}
\label{\detokenize{06.optimization_fundamentals:plan-for-this-lecture}}\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
Open and closed sets (review)

\item {} 
\sphinxAtStartPar
Continuity of functions

\item {} 
\sphinxAtStartPar
Suprema and infima

\item {} 
\sphinxAtStartPar
Existence of optima

\item {} 
\sphinxAtStartPar
Uniqueness of optima

\end{enumerate}

\sphinxAtStartPar
\sphinxstylestrong{Supplementary reading:}
\begin{itemize}
\item {} 
\sphinxAtStartPar
Simon \& Blume:

\item {} 
\sphinxAtStartPar
Sundaram:

\end{itemize}


\section{Sequences and limits in \protect\(\mathbb{R}^K\protect\)}
\label{\detokenize{06.optimization_fundamentals:sequences-and-limits-in-mathbb-r-k}}
\begin{sphinxadmonition}{note}{Definition: sequence}

\sphinxAtStartPar
A \sphinxstyleemphasis{\sphinxstylestrong{sequence}} \(\{{\bf x}_n\}\) in \(\mathbb{R}^K\) is a function from \(\mathbb{N}\) to \(\mathbb{R}^K\)
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Definition: Euclidean norm}

\sphinxAtStartPar
The (Euclidean) \sphinxstyleemphasis{\sphinxstylestrong{norm}} of \({\bf x} \in \mathbb{R}^N\) is defined as
\begin{equation*}
\begin{split}
%
\| {\bf x} \| 
:= \sqrt{{\bf x}' {\bf x} } 
= \left( \sum_{n=1}^N x_n^2 \right)^{1/2}
%
\end{split}
\end{equation*}\end{sphinxadmonition}

\sphinxAtStartPar
Interpretation:
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(\| {\bf x} \|\) represents the \sphinxstyleemphasis{length} of \({\bf x}\)

\item {} 
\sphinxAtStartPar
\(\| {\bf x} - {\bf y} \|\) represents distance between \({\bf x}\) and \({\bf y}\)

\end{itemize}

\sphinxAtStartPar
When \(K=1\), the norm \(\| \cdot \|\) reduces to \(|\cdot|\)

\begin{sphinxadmonition}{note}{Definition}

\sphinxAtStartPar
A set \(A \subset \mathbb{R}^K\) called \sphinxstyleemphasis{\sphinxstylestrong{bounded}} if
\begin{equation*}
\begin{split}
%
\exists \, M \in \mathbb{R} 
\; \mathrm{such\;that} \;
\|{\bf x}\| \leq M, \quad \forall \; {\bf x} \in A
%
\end{split}
\end{equation*}\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Definition}

\sphinxAtStartPar
For \(\epsilon > 0\), the \(\epsilon\)\sphinxhyphen{}ball \(B_{\epsilon}({\bf a})\) around
\({\bf a} \in \mathbb{R}^K\) is all \({\bf x} \in \mathbb{R}^K\) such that \(\|{\bf a} - {\bf x}\|
< \epsilon\)
\end{sphinxadmonition}

\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics[scale=0.5]{{eps_ball2D}.png}
\end{figure}

\begin{sphinxadmonition}{note}{Fact}

\sphinxAtStartPar
If \({\bf x}\) is in every \(\epsilon\)\sphinxhyphen{}ball around \({\bf a}\) then
\({\bf x}={\bf a}\)
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Fact}

\sphinxAtStartPar
If \({\bf a} \ne {\bf b}\), then \(\exists \, \epsilon > 0\) such that
\(B_\epsilon({\bf a}) \cap B_\epsilon({\bf b}) = \emptyset\)
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Definition}

\sphinxAtStartPar
Sequence \(\{{\bf x}_n\}\) is said to \sphinxstyleemphasis{\sphinxstylestrong{converge}} to \({\bf a} \in \mathbb{R}^K\) if
\begin{equation*}
\begin{split}
%
\forall \epsilon > 0, 
\;
\exists \, N \in \mathbb{N}
\; 
\text{ such that } n \geq N \implies {\bf x}_n \in B_{\epsilon}({\bf a})
%
\end{split}
\end{equation*}\end{sphinxadmonition}

\sphinxAtStartPar
We say: “\(\{{\bf x}_n\}\) is eventually in any \(\epsilon\)\sphinxhyphen{}neighborhood of \({\bf a}\)”

\sphinxAtStartPar
In this case \({\bf a}\) is called the \sphinxstyleemphasis{\sphinxstylestrong{limit}} of the sequence, and we write
\begin{equation*}
\begin{split} 
%
{\bf x}_n \to {\bf a} \; \text{ as } \; n \to \infty
\quad \text{or} \quad
\lim_{n \to \infty} {\bf x}_n = {\bf a}
%
\end{split}
\end{equation*}
\begin{sphinxadmonition}{note}{Definition}

\sphinxAtStartPar
We call \(\{ {\bf x}_n \}\) \sphinxstyleemphasis{\sphinxstylestrong{convergent}} if it converges to some limit in \(\mathbb{R}^K\)
\end{sphinxadmonition}

\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics[scale=0.8]{{convergence}.png}
\end{figure}

\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics[scale=0.8]{{convergence2}.png}
\end{figure}

\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics[scale=0.8]{{convergence3}.png}
\end{figure}

\begin{sphinxadmonition}{note}{Fact}

\sphinxAtStartPar
A sequence \(\{{\bf x}_n\}\) in \(\mathbb{R}^K\) converges to \({\bf a} \in \mathbb{R}^K\)
if and only if each component sequence converges in \(\mathbb{R}\)

\sphinxAtStartPar
That is,
\begin{equation*}
\begin{split}
%
\begin{pmatrix}
x^1_n \\
\vdots \\
x^K_n 
\end{pmatrix}
\to
\begin{pmatrix}
a^1 \\
\vdots \\
a^K 
\end{pmatrix}
\quad \text{in } \mathbb{R}^K
\quad \iff \quad
\begin{array}{cc}
x^1_n \to a^1 & \quad \text{in } \mathbb{R} \\
\vdots & \\
x^K_n \to a^K & \quad \text{in } \mathbb{R} 
\end{array}
%
\end{split}
\end{equation*}\begin{equation*}
\begin{split}
% {\bf x}_n \to {\bf a} \; \text{ in } \mathbb{R}^K
% \quad \iff\quad 
% {\bf e}_k' {\bf x}_n \to {\bf e}_k' {\bf a} \text{ in $\mathbb{R}$ for all } k
%
\end{split}
\end{equation*}\end{sphinxadmonition}

\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics{{norm_and_pointwise}.png}
\end{figure}


\section{Open and Closed Sets}
\label{\detokenize{06.optimization_fundamentals:open-and-closed-sets}}
\sphinxAtStartPar
Let \(G \subset \mathbb{R}^K\)

\begin{sphinxadmonition}{note}{Definition}

\sphinxAtStartPar
We call \({\bf x} \in G\) \sphinxstyleemphasis{\sphinxstylestrong{interior}} to \(G\) if
\(\exists \; \epsilon > 0\) with \(B_\epsilon({\bf x}) \subset G\)
\end{sphinxadmonition}

\sphinxAtStartPar
Loosely speaking, interior means “not on the boundary”

\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics[scale=0.5]{{interior}.png}
\end{figure}

\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
If \(G = (a, b)\) for some \(a < b\), then any \(x \in (a, b)\) is interior
\end{sphinxadmonition}

\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics{{x_interior}.png}
\end{figure}

\begin{sphinxadmonition}{note}{Proof}

\sphinxAtStartPar
Fix any \(a < b\) and any \(x \in (a, b)\)

\sphinxAtStartPar
Let \(\epsilon := \min\{x - a, b - x\}\)

\sphinxAtStartPar
If \(y \in B_\epsilon(x)\) then \(y < b\) because
\begin{equation*}
\begin{split}
%
y 
= y + x - x
\leq |y - x| + x
< \epsilon + x 
\leq b - x + x = b
%
\end{split}
\end{equation*}\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
If \(G = [-1, 1]\), then \(1\) is not interior
\end{sphinxadmonition}

\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics{{not_interior}.png}
\end{figure}

\sphinxAtStartPar
Intuitively, any \(\epsilon\)\sphinxhyphen{}ball centered on \(1\) will contain points \(> 1\)

\sphinxAtStartPar
More formally, pick any \(\epsilon > 0\) and consider \(B_\epsilon(1)\)

\sphinxAtStartPar
There exists a \(y \in B_\epsilon(1)\) such that \(y \notin [-1, 1]\)

\sphinxAtStartPar
For example, consider the point \(y := 1 + \epsilon/2\)

\sphinxAtStartPar
\sphinxstylestrong{Exercise:} Check this point: lies in \(B_\epsilon(1)\) but not in \([-1, 1]\)

\begin{sphinxadmonition}{note}{Definition}

\sphinxAtStartPar
A set \(G\subset \mathbb{R}^K\) is called \sphinxstyleemphasis{\sphinxstylestrong{open}} if all of its points are interior
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
Open sets:
\begin{itemize}
\item {} 
\sphinxAtStartPar
any “open” interval \((a,b) \subset \mathbb{R}\), since we showed all points are interior

\item {} 
\sphinxAtStartPar
any “open” ball \(B_\epsilon({\bf a}) = {\bf x} \in
\mathbb{R}^K : \|{\bf x} - {\bf a} \| < \epsilon\)

\item {} 
\sphinxAtStartPar
\(\mathbb{R}^K\) itself

\end{itemize}
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
Sets that are not open
\begin{itemize}
\item {} 
\sphinxAtStartPar
\((a,b]\) because \(b\) is not interior

\item {} 
\sphinxAtStartPar
\([a,b)\) because \(a\) is not interior

\end{itemize}
\end{sphinxadmonition}


\subsection{Closed Sets}
\label{\detokenize{06.optimization_fundamentals:closed-sets}}
\begin{sphinxadmonition}{note}{Definition}

\sphinxAtStartPar
A set \(F \subset \mathbb{R}^K\) is called \sphinxstyleemphasis{\sphinxstylestrong{closed}} if every convergent sequence in \(F\) converges to a point in \(F\)
\end{sphinxadmonition}

\sphinxAtStartPar
Rephrased: If \(\{{\bf x}_n\} \subset F\) and \({\bf x}_n \to {\bf x}\) for some
\({\bf x} \in \mathbb{R}^K\), then \({\bf x} \in F\)

\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
All of \(\mathbb{R}^K\) is closed because every sequence converging to a point in \(\mathbb{R}^K\) converges to a point in \(\mathbb{R}^K\)… right?
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
If \((-1, 1) \subset \mathbb{R}\) is \{\textbackslash{}bf not\} closed
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Proof}

\sphinxAtStartPar
True because
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
\(x_n := 1-1/n\) is a sequence in \((-1, 1)\) converging to \(1\),

\item {} 
\sphinxAtStartPar
and yet \(1 \notin (-1, 1)\)

\end{enumerate}
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
If \(F = [a, b] \subset \mathbb{R}\) then \(F\) is closed in \(\mathbb{R}\)
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Proof}

\sphinxAtStartPar
Take any sequence \(\{x_n\}\) such that
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(x_n \in F\) for all \(n\)

\item {} 
\sphinxAtStartPar
\(x_n \to x\) for some \(x \in \mathbb{R}\)

\end{itemize}

\sphinxAtStartPar
We claim that \(x \in F\)

\sphinxAtStartPar
Recall that (weak) inequalities are preserved under limits:
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(x_n \leq b\) for all \(n\) and \(x_n \to x\), so \(x \leq b\)

\item {} 
\sphinxAtStartPar
\(x_n \geq a\) for all \(n\) and \(x_n \to x\), so \(x \geq a\)

\end{itemize}

\sphinxAtStartPar
therefore \(x \in [a, b] =: F\)
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
Any “hyperplane” of the form
\begin{equation*}
\begin{split}
%
H = \{ {\bf x} \in \mathbb{R}^K : {\bf x}' {\bf a} = c \}
%
\end{split}
\end{equation*}
\sphinxAtStartPar
is closed
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Proof}

\sphinxAtStartPar
Fix \({\bf a} \in \mathbb{R}^K\) and \(c \in \mathbb{R}\) and let \(H\) be as above

\sphinxAtStartPar
Let \(\{{\bf x}_n\} \subset H\) with \({\bf x}_n \to {\bf x} \in \mathbb{R}^K\)

\sphinxAtStartPar
We claim that \({\bf x} \in H\)

\sphinxAtStartPar
Since \({\bf x}_n \in H\) and \({\bf x}_n \to {\bf x}\) we have
\begin{equation*}
\begin{split}
%
{\bf x}_n ' {\bf a} \to {\bf x}' {\bf a} \text{ in } \mathbb{R}
\quad \text{and} \quad
{\bf x}_n' {\bf a} = c \text{ for all } n
%
\end{split}
\end{equation*}\begin{equation*}
\begin{split}
%
\text{therefore } 
{\bf x}' {\bf a} = \lim_{n} {\bf x}_n' {\bf a} 
= \lim_n c
= c
%
\end{split}
\end{equation*}\begin{equation*}
\begin{split}
%
\text{therefore } 
{\bf x} \in H
%
\end{split}
\end{equation*}\end{sphinxadmonition}


\subsection{Properties of Open and Closed Sets}
\label{\detokenize{06.optimization_fundamentals:properties-of-open-and-closed-sets}}
\begin{sphinxadmonition}{note}{Fact}

\sphinxAtStartPar
\(G \subset \mathbb{R}^K\) is open \(\iff \; G^c\) is closed
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Proof}

\sphinxAtStartPar
\(\implies\)

\sphinxAtStartPar
First prove necessity

\sphinxAtStartPar
Pick any \(G\) and let \(F := G^c\)

\sphinxAtStartPar
Suppose to the contrary that \(G\) is open but \(F\) is not closed, so

\sphinxAtStartPar
\(\exists\) a sequence \(\{{\bf x}_n\} \subset F\) with limit \({\bf x} \notin F\)

\sphinxAtStartPar
Then \({\bf x} \in G\), and since \(G\) open, \(\exists \, \epsilon > 0\) such
that \(B_\epsilon({\bf x}) \subset G\)

\sphinxAtStartPar
Since \({\bf x}_n \to {\bf x}\) we can choose an \(N \in \mathbb{N}\) with \({\bf x}_N \in
B_\epsilon({\bf x})\)

\sphinxAtStartPar
This contradicts \({\bf x}_n \in F\) for all \(n\)

\sphinxAtStartPar
\(\Longleftarrow\)

\sphinxAtStartPar
Next prove sufficiency

\sphinxAtStartPar
Pick any closed \(F\) and let \(G := F^c\), need to prove that \(G\) is open

\sphinxAtStartPar
Suppose to the contrary that \(G\) is not open

\sphinxAtStartPar
Then exists some non\sphinxhyphen{}interior \({\bf x} \in G\), that is no \(\epsilon\)\sphinxhyphen{}ball around \(x\) lies entirely in \(G\)

\sphinxAtStartPar
Then it is possible to find a sequence \(\{{\bf x}_n\}\) which converges to \(x \in G\), but every element of which lies in the \(B_{1/n}({\bf x}) \cap F\)

\sphinxAtStartPar
This contradicts the fact that \(F\) is closed
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
Any singleton \(\{ {\bf x} \} \subset \mathbb{R}^K\) is closed
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Proof}

\sphinxAtStartPar
Let’s prove this by showing that \(\{{\bf x}\}^c\) is open

\sphinxAtStartPar
Pick any \({\bf y} \in \{{\bf x}\}^c\)

\sphinxAtStartPar
We claim that \({\bf y}\) is interior to \(\{{\bf x}\}^c\)

\sphinxAtStartPar
Since \({\bf y} \in \{{\bf x}\}^c\) it must be that \({\bf y} \ne {\bf x}\)

\sphinxAtStartPar
Therefore, exists \(\epsilon > 0\) such that \(B_\epsilon({\bf y}) \cap B_\epsilon({\bf x}) = \emptyset\)

\sphinxAtStartPar
In particular, \({\bf x} \notin B_\epsilon({\bf y})\), and hence \(B_\epsilon({\bf y}) \subset \{{\bf x}\}^c\)

\sphinxAtStartPar
Therefore \({\bf y}\) is interior as claimed

\sphinxAtStartPar
Since \({\bf y}\) was arbitrary it follows that \(\{{\bf x}\}^c\) is open and \(\{{\bf x}\}\) is closed
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Fact}
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
Any \sphinxstyleemphasis{union} of open sets is open

\item {} 
\sphinxAtStartPar
Any \sphinxstyleemphasis{intersection} of closed sets is closed

\end{enumerate}
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Proof}

\sphinxAtStartPar
\sphinxstyleemphasis{Proof of first fact:}

\sphinxAtStartPar
Let \(G := \cup_{\lambda \in \Lambda} G_\lambda\), where each \(G_\lambda\) is
open

\sphinxAtStartPar
We claim that any given \({\bf x} \in G\) is interior to \(G\)

\sphinxAtStartPar
Pick any \({\bf x} \in G\)

\sphinxAtStartPar
By definition, \({\bf x} \in G_\lambda\) for some \(\lambda\)

\sphinxAtStartPar
Since \(G_\lambda\) is open, \(\exists \, \epsilon > 0\) such that \(B_\epsilon({\bf x})
\subset G_\lambda\)

\sphinxAtStartPar
But \(G_\lambda \subset G\), so \(B_\epsilon({\bf x}) \subset G\) also holds

\sphinxAtStartPar
In other words, \({\bf x}\) is interior to \(G\)
\end{sphinxadmonition}

\sphinxAtStartPar
But be careful:
\begin{itemize}
\item {} 
\sphinxAtStartPar
An \sphinxstylestrong{infinite} intersection of open sets is not necessarily open

\item {} 
\sphinxAtStartPar
An \sphinxstylestrong{infinite} union of closed sets is not necessarily closed

\end{itemize}

\sphinxAtStartPar
For example, if \(G_n := (-1/n, 1/n)\), then \(\cap_{n \in \mathbb{N}} G_n = \{0\} \)

\sphinxAtStartPar
To see this, suppose that \(x \in \cap_n G_n\)

\sphinxAtStartPar
Then
\begin{equation*}
\begin{split}
%
-1/n < x < 1/n, \quad \forall n \in \mathbb{N}
%
\end{split}
\end{equation*}
\sphinxAtStartPar
Therefore \(x = 0\), and hence \(x \in \{0\}\)

\sphinxAtStartPar
On the other hand, if \(x \in \{0\}\) then \(x \in \cap_n G_n\)

\begin{sphinxadmonition}{note}{Fact}

\sphinxAtStartPar
If \(A\) is closed and bounded then every sequence in
\(A\) has a subsequence which converges to a point of \(A\)
\end{sphinxadmonition}

\sphinxAtStartPar
Take any sequence \(\{{\bf x}_n\}\) contained in \(A\)

\sphinxAtStartPar
Since \(A\) is bounded, \(\{{\bf x}_n\}\) is bounded

\sphinxAtStartPar
Therefore it has a convergent subsequence

\sphinxAtStartPar
Since the subsequence is also contained in \(A\),
and \(A\) is closed, the limit must lie in \(A\).

\begin{sphinxadmonition}{note}{Definition}

\sphinxAtStartPar
Bounded and closed sets are called \sphinxstylestrong{compact sets} or \sphinxstylestrong{compacts}
\end{sphinxadmonition}


\section{Continuity}
\label{\detokenize{06.optimization_fundamentals:continuity}}
\sphinxAtStartPar
One of the most fundamental properties of functions

\sphinxAtStartPar
Related to existence of
\begin{itemize}
\item {} 
\sphinxAtStartPar
optima

\item {} 
\sphinxAtStartPar
roots

\item {} 
\sphinxAtStartPar
fixed points

\item {} 
\sphinxAtStartPar
etc

\end{itemize}

\sphinxAtStartPar
as well as a variety of other useful concepts


\subsection{Reminder on functions >>}
\label{\detokenize{06.optimization_fundamentals:reminder-on-functions}}
\begin{sphinxadmonition}{note}{Definition}

\sphinxAtStartPar
A \sphinxstyleemphasis{\sphinxstylestrong{function}} \(f \colon A \rightarrow B\) from set \(A\) to set \(B\) is a rule that
associates to \sphinxstyleemphasis{each} element of \(A\) a \sphinxstyleemphasis{uniquely determined} element of \(B\)
\end{sphinxadmonition}

\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics{{function}.png}
\end{figure}

\sphinxAtStartPar
\(A\) is called the \sphinxstyleemphasis{\sphinxstylestrong{domain}} of \(f\) and \(B\) is called the \sphinxstyleemphasis{\sphinxstylestrong{codomain}}

\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics[scale=0.5]{{allfunctions}.png}
\end{figure}

\sphinxAtStartPar
Lower panel: functions have to map \sphinxstyleemphasis{all} elements in domain to a \sphinxstyleemphasis{uniquely determined} element in codomain.

\begin{sphinxadmonition}{note}{Definition}

\sphinxAtStartPar
The smallest possible codomain is called the \sphinxstyleemphasis{\sphinxstylestrong{range}} of \(f \colon A \to B\):
\end{sphinxadmonition}
\begin{equation*}
\begin{split}
%
\mathrm{rng}(f) := \{ b \in B : f(a) = b \text{ for some } a \in A \} 
%
\end{split}
\end{equation*}
\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics[scale=0.5]{{range}.png}
\end{figure}

\begin{sphinxadmonition}{note}{Definition}

\sphinxAtStartPar
A function \(f \colon A \to B\) is called \sphinxstyleemphasis{\sphinxstylestrong{onto}} (or surjection) if every element of \(B\)
is the image under \(f\) of at least one point in \(A\).

\sphinxAtStartPar
A function \(f \colon A \to B\) is called \sphinxstyleemphasis{\sphinxstylestrong{one\sphinxhyphen{}to\sphinxhyphen{}one}} (or injection) if distinct
elements of \(A\) are always mapped into distinct elements of \(B\).

\sphinxAtStartPar
A function that is both one\sphinxhyphen{}to\sphinxhyphen{}one (injection) and onto (surjection) is called a \sphinxstyleemphasis{\sphinxstylestrong{bijection}} or \sphinxstyleemphasis{\sphinxstylestrong{one\sphinxhyphen{}to\sphinxhyphen{}one correspondence}}
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Fact}

\sphinxAtStartPar
If \(f \colon A \to B\) is one\sphinxhyphen{}to\sphinxhyphen{}one, then \(f \colon A \to \mathrm{rng}(f)\) is a bijection
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Fact}

\sphinxAtStartPar
If \(f \colon A \to B\) a bijection, then there exists a unique
function \(\phi \colon B \to A\) such that
\begin{equation*}
\begin{split}
%
\phi(f(a)) = a, \quad \forall \; a \in A
%
\end{split}
\end{equation*}
\sphinxAtStartPar
That function \(\phi\) is called the \sphinxstyleemphasis{\sphinxstylestrong{inverse}} of \(f\) and written \(f^{-1}\)
\end{sphinxadmonition}

\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics{{bijec}.png}
\end{figure}


\subsection{Bounded functions}
\label{\detokenize{06.optimization_fundamentals:bounded-functions}}
\begin{sphinxadmonition}{note}{Definition}

\sphinxAtStartPar
A function \(F\) is called \sphinxstyleemphasis{\sphinxstylestrong{bounded}} if its range is a bounded set.
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Fact}

\sphinxAtStartPar
If \(F\) and \(G\) are bounded, then so are \(F+G\), \(F \cdot G\) and \(\alpha F\) for any finite \(\alpha\)
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Proof}

\sphinxAtStartPar
Proof for the case \(F + G\):

\sphinxAtStartPar
Let \(F\) and \(G\) be bounded functions

\sphinxAtStartPar
\(\exists\) \(M_F\) and \(M_G\) s.t.
\(\| F({\bf x}) \| \leq M_F\) and \(\| G({\bf x}) \| \leq M_G\)
for all \({\bf x}\)

\sphinxAtStartPar
Fix any \({\bf x}\) and let \(M := M_F + M_G\)

\sphinxAtStartPar
Applying the triangle inequality gives
\begin{equation*}
\begin{split}
%
\| (F + G)({\bf x}) \|
:= \| F({\bf x}) + G({\bf x}) \|
\leq \| F({\bf x}) \| + \| G({\bf x}) \| 
\leq M
%
\end{split}
\end{equation*}
\sphinxAtStartPar
Since \({\bf x}\) was arbitrary this bound holds for all \({\bf x}\)
\end{sphinxadmonition}


\subsection{Continuous functions}
\label{\detokenize{06.optimization_fundamentals:continuous-functions}}
\begin{sphinxadmonition}{note}{Definition}

\sphinxAtStartPar
Let \(F \colon A \to \mathbb{R}^J\) where \(A\) is a subset of \(\mathbb{R}^K\).
\(F\) is called \sphinxstyleemphasis{\sphinxstylestrong{continuous at}} \({\bf x} \in A\) if as \(n \to \infty\)
\begin{equation*}
\begin{split}
%
{\bf x}_n \to {\bf x}
\quad \implies \quad
F({\bf x}_n) \to F({\bf x}) 
%
\end{split}
\end{equation*}\end{sphinxadmonition}

\sphinxAtStartPar
Requires that
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(F({\bf x}_n)\) converges for each choice of \({\bf x}_n \to {\bf x}\),

\item {} 
\sphinxAtStartPar
The limit is always the same, and that limit is \(F({\bf x})\)

\end{itemize}

\begin{sphinxadmonition}{note}{Definition}

\sphinxAtStartPar
\(F\) is called \sphinxstyleemphasis{\sphinxstylestrong{continuous}} if it is continuous at every \({\bf x} \in
A\)
\end{sphinxadmonition}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{cont_func}.png}
\caption{Continuity}\label{\detokenize{06.optimization_fundamentals:cont-func2}}\end{figure}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{discont_func}.png}
\caption{Discontinuity at \(x\)}\label{\detokenize{06.optimization_fundamentals:discont-func2}}\end{figure}

\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
Let \({\bf A}\) be an \(J \times K\) matrix and let \(F({\bf x}) = {\bf A}
{\bf x}\)

\sphinxAtStartPar
The function \(F\) is continuous at every \({\bf x} \in \mathbb{R}^K\)
\end{sphinxadmonition}

\sphinxAtStartPar
To see this take
\begin{itemize}
\item {} 
\sphinxAtStartPar
any \({\bf x} \in \mathbb{R}^K\)

\item {} 
\sphinxAtStartPar
any \({\bf x}_n \to {\bf x}\)

\end{itemize}

\sphinxAtStartPar
By the definition of the matrix norm \(\| {\bf A} \|\), we have
\begin{equation*}
\begin{split}
%
\| {\bf A} {\bf x}_n - {\bf A} {\bf x} \|
= \| {\bf A} ({\bf x}_n - {\bf x}) \|
\leq \| {\bf A} \| \| {\bf x}_n - {\bf x} \|
%
\end{split}
\end{equation*}\begin{equation*}
\begin{split}
%
\text{therefore }
{\bf x}_n \to {\bf x} \implies
{\bf A} {\bf x}_n \to {\bf A} {\bf x} 
%
\end{split}
\end{equation*}
\sphinxAtStartPar
\sphinxstyleemphasis{\sphinxstylestrong{Exercise:}} Exactly what rules are we using here?

\begin{sphinxadmonition}{note}{Fact}

\sphinxAtStartPar
If \(f \colon \mathbb{R} \to \mathbb{R}\) is differentiable at \(x\), then \(f\) is continuous at \(x\)
\end{sphinxadmonition}
\begin{equation*}
\begin{split}
%\frac{f(x + h_n) - f(x)}{h_n} 
%= 
%\frac{f(x_n) - f(x)}{x_n - x} 
%%
\end{split}
\end{equation*}
\begin{sphinxadmonition}{note}{Fact}

\sphinxAtStartPar
Some functions known to be continuous on their domains:
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(x \mapsto x^\alpha\)

\item {} 
\sphinxAtStartPar
\(x \mapsto |x|\)

\item {} 
\sphinxAtStartPar
\(x \mapsto \log(x)\)

\item {} 
\sphinxAtStartPar
\(x \mapsto \exp(x)\)

\item {} 
\sphinxAtStartPar
\(x \mapsto \sin(x)\)

\item {} 
\sphinxAtStartPar
\(x \mapsto \cos(x)\)

\end{itemize}
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
Discontinuous at zero: \(x \mapsto \mathbb{1}\{x > 0\}\).
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Fact}

\sphinxAtStartPar
Let \(F\) and \(G\) be functions and let \(\alpha \in \mathbb{R}\)
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
If \(F\) and \(G\) are continuous at \({\bf x}\) then so is \(F + G\),
where

\end{enumerate}
\begin{equation*}
\begin{split}
%
(F + G)({\bf x}) := F({\bf x}) + G({\bf x})
%
\end{split}
\end{equation*}\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\setcounter{enumi}{1}
\item {} 
\sphinxAtStartPar
If \(F\) is continuous at \({\bf x}\) then so is \(\alpha F\), where

\end{enumerate}
\begin{equation*}
\begin{split}
%
(\alpha F)({\bf x}) := \alpha F({\bf x})
%
\end{split}
\end{equation*}\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\setcounter{enumi}{2}
\item {} 
\sphinxAtStartPar
If \(F\) and \(G\) are continuous at \({\bf x}\) and real valued then so is
\(FG\), where

\end{enumerate}
\begin{equation*}
\begin{split}
%
(FG)({\bf x}) := F({\bf x}) \cdot G({\bf x})
%
\end{split}
\end{equation*}
\sphinxAtStartPar
In the latter case, if in addition \(G({\bf x}) \ne 0\), then \(F/G\) is also continuous.
\end{sphinxadmonition}

\sphinxAtStartPar
As a result, set of continuous functions is “closed” under elementary
arithmetic operations

\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
The function \(F \colon \mathbb{R} \to \mathbb{R}\) defined by
\begin{equation*}
\begin{split}
%
F(x) = \frac{\exp(x) + \sin(x)}{2 + \cos(x)} + \frac{x^4}{2}
- \frac{\cos^3(x)}{8!}
%
\end{split}
\end{equation*}
\sphinxAtStartPar
is continuous
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Proof}

\sphinxAtStartPar
Just repeatedly apply the rules on the previous slide

\sphinxAtStartPar
Let’s just check that
\begin{equation*}
\begin{split}
%
\text{$F$ and $G$ continuous at ${\bf x}$}
\implies 
\text{$F + G$ continuous at ${\bf x}$}
%
\end{split}
\end{equation*}
\sphinxAtStartPar
Let \(F\) and \(G\) be continuous at \({\bf x}\)

\sphinxAtStartPar
Pick any \({\bf x}_n \to {\bf x}\)

\sphinxAtStartPar
We claim that
\(F({\bf x}_n) + G({\bf x}_n) \to F({\bf x}) + G({\bf x})\)

\sphinxAtStartPar
By assumption, \(F({\bf x}_n) \to F({\bf x})\) and \(G({\bf x}_n) \to G({\bf x})\)

\sphinxAtStartPar
From this and the triangle inequality we get
\begin{equation*}
\begin{split}
%
\| F({\bf x}_n) + G({\bf x}_n) - (F({\bf x}) + G({\bf x})) \|
\leq 
%
\end{split}
\end{equation*}\begin{equation*}
\begin{split}
%
\leq 
\| F({\bf x}_n) - F({\bf x}) \|
+
\| G({\bf x}_n) - G({\bf x}) \|
\to 0
%
\end{split}
\end{equation*}\end{sphinxadmonition}

\sphinxAtStartPar
End of review, \sphinxstylestrong{new topic} next >>>


\section{Suprema and Infima (\protect\(\mathrm{sup}\protect\) + \protect\(\mathrm{inf}\protect\))}
\label{\detokenize{06.optimization_fundamentals:suprema-and-infima-mathrm-sup-mathrm-inf}}
\sphinxAtStartPar
In the introductory lecture we have seen a few simple examples of optimization problems. Like in many introductory econ/finance cources
we get well behaved, prepackaged problems.

\sphinxAtStartPar
Usually they
\begin{itemize}
\item {} 
\sphinxAtStartPar
have a solution

\item {} 
\sphinxAtStartPar
the solution is unique and not hard to find

\end{itemize}

\sphinxAtStartPar
However, for the \sphinxstyleemphasis{majority} of problems such properties aren’t guaranteed

\sphinxAtStartPar
We need some idea of how to check these things

\sphinxAtStartPar
Consider the problem of finding the “maximum” or “minimum” of a function

\sphinxAtStartPar
A first issue is that such values might not be well defined

\sphinxAtStartPar
Recall that the set of maximizers/minimizers can be
\begin{itemize}
\item {} 
\sphinxAtStartPar
empty

\item {} 
\sphinxAtStartPar
a singleton (contains one element)

\item {} 
\sphinxAtStartPar
infinite (contains infinitely many elements)

\end{itemize}

\begin{sphinxadmonition}{note}{Example: no maximizers}

\sphinxAtStartPar
The following function has no maximizers on \([0, 2]\)
\begin{equation*}
\begin{split}
f(x) = 
\begin{cases}
x^2 &  \text{ if } x < 1
\\
1/2 &  \text{ otherwise}
\end{cases}
\end{split}
\end{equation*}
\begin{figure}[H]
\centering
\capstart

\noindent\sphinxincludegraphics[width=0.800\linewidth]{{dc6ae1475886bdbf3870fb56da4b850ca80141076ee12d4c620b333af6eb564d}.png}
\caption{No maximizer on \([0, 2]\)}\label{\detokenize{06.optimization_fundamentals:id1}}\end{figure}
\end{sphinxadmonition}

\sphinxAtStartPar
This leads us to start with “suprema” and “infima”
\begin{itemize}
\item {} 
\sphinxAtStartPar
Always well defined

\item {} 
\sphinxAtStartPar
Agree with max and min when the latter exist

\end{itemize}

\begin{sphinxadmonition}{note}{Definition}

\sphinxAtStartPar
Let \(A \subset \mathbb{R}\).
A number \(u \in \mathbb{R}\) is called an \sphinxstyleemphasis{\sphinxstylestrong{upper bound}} of \(A\) if
\begin{equation*}
\begin{split}
%
a \leq u \quad \text{for all} \quad a \in A
%
\end{split}
\end{equation*}\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
If \(A = (0, 1)\) then 10 is an upper bound of \(A\)

\sphinxAtStartPar
\(\because \quad\) Every element of \((0, 1)\) is \(\leq 10\)
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
If \(A = (0, 1)\) then 1 is an upper bound of \(A\)

\sphinxAtStartPar
\(\because \quad\) Every element of \((0, 1)\) is \(\leq 1\)
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
If \(A = (0, 1)\) then \(0.5\) is \sphinxstyleemphasis{\sphinxstylestrong{not}} an upper bound of \(A\)

\sphinxAtStartPar
\(\because \quad\) \(\exists\, a = 0.6 \in (0, 1) = A\) and \(0.5 < 0.6\)
\end{sphinxadmonition}

\sphinxAtStartPar
Let \(U(A) :=\) set of all upper bounds of \(A\)

\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics{{upper_bounds}.png}
\end{figure}

\begin{sphinxadmonition}{note}{Examples}
\begin{itemize}
\item {} 
\sphinxAtStartPar
If \(A = [0, 1]\), then \(U(A) = [1, \infty)\)

\item {} 
\sphinxAtStartPar
If \(A = (0, 1)\), then \(U(A) = [1, \infty)\)

\item {} 
\sphinxAtStartPar
If \(A = (0, 1) \cup (2, 3)\), then \(U(A) = [3, \infty)\)

\item {} 
\sphinxAtStartPar
If \(A = \mathbb{N}\), then \(U(A) = \emptyset\)

\end{itemize}
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Definition}

\sphinxAtStartPar
The \sphinxstyleemphasis{least upper bound} of \(A\) is called \sphinxstyleemphasis{\sphinxstylestrong{supremum}} of \(A\).
\end{sphinxadmonition}

\sphinxAtStartPar
In other words, if \(s\) is a number satisfying
\begin{equation*}
\begin{split}
%
s \in U(A)
\qquad \text{and} \qquad
s \leq u, \; \forall \, u \in U(A)
%
\end{split}
\end{equation*}
\sphinxAtStartPar
then \(s\) is the \sphinxstyleemphasis{\sphinxstylestrong{supremum}} of \(A\) and we write \(s = \sup A\)

\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics{{sup}.png}
\end{figure}

\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
If \(A = (0, 1]\), then \(U(A) = [1, \infty)\), so \(\sup A = 1\)
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
If \(A = (0, 1)\), then \(U(A) = [1, \infty)\), so \(\sup A = 1\)
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Definition}

\sphinxAtStartPar
A set \(A \subset \mathbb{R}\) is called \sphinxstyleemphasis{\sphinxstylestrong{bounded above}} if \(U(A)\) is not empty
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Fact}

\sphinxAtStartPar
If \(A\) is nonempty and bounded above then \(A\) has a supremum in \(\mathbb{R}\)
\end{sphinxadmonition}
\begin{itemize}
\item {} 
\sphinxAtStartPar
Equivalent to the fact that all Cauchy sequences converge

\item {} 
\sphinxAtStartPar
Same principle: \(\mathbb{R}\) has no “gaps” or “holes”

\end{itemize}

\sphinxAtStartPar
What if \(A\) is not bounded above, so that \(U(A) = \emptyset\)?

\sphinxAtStartPar
We follow the convention that \(\sup A := \infty\) in this case

\sphinxAtStartPar
Now the supremum of a nonempty subset of \(\mathbb{R}\) \sphinxstylestrong{always} exists

\begin{sphinxadmonition}{note}{Note:}
\sphinxAtStartPar
Aside: Conventions for dealing with symbols “\(\infty\)’’ and ``\(-\infty\)”

\sphinxAtStartPar
If \(a \in \mathbb{R}\), then
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(a + \infty = \infty\)

\item {} 
\sphinxAtStartPar
\(a - \infty = -\infty\)

\item {} 
\sphinxAtStartPar
\(a \times \infty = \infty\) if \(a \ne 0\), \(0 \times \infty = 0\)

\item {} 
\sphinxAtStartPar
\(-\infty < a < \infty\)

\item {} 
\sphinxAtStartPar
\(\infty + \infty = \infty\)

\item {} 
\sphinxAtStartPar
\(-\infty - \infty = -\infty\)

\end{itemize}

\sphinxAtStartPar
But \(\infty - \infty\) is not defined
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Fact}

\sphinxAtStartPar
If \(A \subset B\), then \(\sup A \leq \sup B\)
\end{sphinxadmonition}

\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics{{sup_ab}.png}
\end{figure}

\begin{sphinxadmonition}{note}{Proof}

\sphinxAtStartPar
Let \(A \subset B\)

\sphinxAtStartPar
If \(\sup B = \infty\) then the claim is trivial so suppose \(\bar b = \sup B < \infty\)

\sphinxAtStartPar
By definition, \(\bar b \in U(B)\), so \(b \leq \bar b\) for all \(b \in B\)

\sphinxAtStartPar
Since each \(a \in A\) is also in \(B\), we then have \(a \leq \bar b\) for all \(a \in A \)

\sphinxAtStartPar
It follows that \(\bar b \in U(A)\)

\sphinxAtStartPar
Hence \(\sup A \leq \bar b\)
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Fact}

\sphinxAtStartPar
Let \(A\) be any set bounded from above and let \(s := \sup A\).
There exists a sequence \(\{x_n\}\) in \(A\) with \(x_n \to s\).
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Proof}

\sphinxAtStartPar
Note that
\begin{equation*}
\begin{split}
%
\forall \, n \in \mathbb{N}, \;\; \exists \, x_n \in A \; \text{ such that } \; x_n > s - \frac{1}{n}
%
\end{split}
\end{equation*}
\begin{figure}[H]
\centering

\noindent\sphinxincludegraphics{{sup_seq}.png}
\end{figure}

\sphinxAtStartPar
(Otherwise \(s\) is not a sup, because \(s-\frac{1}{n}\) is a smaller upper bound)

\sphinxAtStartPar
The sequence \(\{x_n\}\) lies in \(A\) and converges to \(s\)
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Definition}

\sphinxAtStartPar
A \sphinxstyleemphasis{\sphinxstylestrong{lower bound}} of \(A \subset \mathbb{R}\) is any \(\ell \in \mathbb{R}\) with \(\ell \leq a\) for all \(a \in A\)
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Definition}

\sphinxAtStartPar
If \(i \in \mathbb{R}\) is an lower bound for \(A\) with \(i \geq \ell\) for every
lower bound \(\ell\) of \(A\), then \(i\) is called the
\sphinxstyleemphasis{\sphinxstylestrong{infimum}} of \(A\)
\end{sphinxadmonition}

\sphinxAtStartPar
Infimum is written as \(i = \inf A\)

\begin{sphinxadmonition}{note}{Example}
\begin{itemize}
\item {} 
\sphinxAtStartPar
If \(A = [0, 1]\), then \(\inf A = 0\)

\item {} 
\sphinxAtStartPar
If \(A = (0, 1)\), then \(\inf A = 0\)

\end{itemize}
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Fact}

\sphinxAtStartPar
Every nonempty subset of \(\mathbb{R}\) bounded from below has an infimum
\end{sphinxadmonition}

\sphinxAtStartPar
If \(A\) is unbounded below then we set \(\inf A = -\infty\)


\subsection{Maxima and Minima of Sets}
\label{\detokenize{06.optimization_fundamentals:maxima-and-minima-of-sets}}
\sphinxAtStartPar
In optimization we’re mainly interested in maximizing and minimizing functions
\begin{equation*}
\begin{split}
%
\max_{{\bf x} \in A} f({\bf x})
%
\end{split}
\end{equation*}
\sphinxAtStartPar
As we’ll see, the problem is the same as finding the largest number in the \sphinxstylestrong{range of} \(f\)

\sphinxAtStartPar
That is, the largest number \sphinxstylestrong{in the set}
\begin{equation*}
\begin{split}
f(A) := \{ f({\bf x}) \colon {\bf x } \in A\}
\end{split}
\end{equation*}
\begin{sphinxadmonition}{note}{Definition}

\sphinxAtStartPar
We call \(a^*\) the \sphinxstyleemphasis{\sphinxstylestrong{maximum}} of \(A \subset \mathbb{R}\) and write \(a^* = \max A\) if
\begin{equation*}
\begin{split}
%
a^* \in A 
\qquad \text{and} \qquad
a \leq a^*
\text{ for all } 
a \in A 
%
\end{split}
\end{equation*}\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
If \(A = [0, 1]\) then \(\max A = 1\)
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Definition}

\sphinxAtStartPar
We call \(a^*\) the \sphinxstyleemphasis{\sphinxstylestrong{minimum}} of \(A \subset \mathbb{R}\) and write \(a^* = \min A\) if
\begin{equation*}
\begin{split}
%
a^* \in A 
\qquad \text{and} \qquad
a^* \leq a
\text{ for all } 
a \in A 
%
\end{split}
\end{equation*}\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
If \(A = [0, 1]\) then \(\min A = 0\)
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Fact}

\sphinxAtStartPar
If \(A \subset \mathbb{R}\) is finite then \(\max A\) and \(\min A\) always exist
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Example}
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(\max\{2, 4, 6, 8\} = 8\)

\item {} 
\sphinxAtStartPar
\(\min\{2, 4, 6, 8\} = 2\)

\end{itemize}
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Fact}

\sphinxAtStartPar
For infinite subsets of \(\mathbb{R}\), max and min may not exist!
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
\(\max \mathbb{N}\) does not exist
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Proof}

\sphinxAtStartPar
Suppose to the contrary that \(n^* = \max \mathbb{N}\)

\sphinxAtStartPar
By the definition of the maximum, \(n^* \in \mathbb{N}\)

\sphinxAtStartPar
Now consider
\begin{equation*}
\begin{split}
%
n^{**} := n^* + 1
%
\end{split}
\end{equation*}
\sphinxAtStartPar
Clearly
\begin{equation*}
\begin{split}
%
n^{**} \in \mathbb{N}
\quad \text{and} \quad 
n^{**} > n^*
%
\end{split}
\end{equation*}
\sphinxAtStartPar
This contradicts the definition of \(n^*\)
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
\(\max (0, 1)\) does not exist
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Proof}

\sphinxAtStartPar
Suppose to the contrary that \(a^* = \max (0, 1)\)

\sphinxAtStartPar
By the definition of the maximum, \(a^* \in (0, 1)\)

\sphinxAtStartPar
Hence \(a^* < 1\)

\sphinxAtStartPar
Now consider
\begin{equation*}
\begin{split}
%
a^{**} := (1 + a^*)/2
%
\end{split}
\end{equation*}
\sphinxAtStartPar
Clearly
\begin{equation*}
\begin{split}
%
a^{**} \in (0, 1) \text{ and } a^{**} > a^*
%
\end{split}
\end{equation*}
\sphinxAtStartPar
Contradicts hypothesis that \(a^*\) is the maximum
\end{sphinxadmonition}


\subsection{Relationship between max/min and sup/inf}
\label{\detokenize{06.optimization_fundamentals:relationship-between-max-min-and-sup-inf}}
\sphinxAtStartPar
When max and min exist they agree with sup and inf

\begin{sphinxadmonition}{note}{Fact}

\sphinxAtStartPar
Let \(A\) be any subset of \(\mathbb{R}\)
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
If \(\sup A \in A\), then \(\max A\) exists and \(\max A = \sup A\)

\item {} 
\sphinxAtStartPar
If \(\inf A \in A\), then \(\min A\) exists and \(\min A = \inf A\)

\end{enumerate}
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Proof}

\sphinxAtStartPar
Proof of case 1: Let \(a^* := \sup A\) and suppose \(a^* \in A\)

\sphinxAtStartPar
We want to show that \(\max A = a^*\)

\sphinxAtStartPar
Since \(a^* \in A\), we need only show that \(a \leq a^*\) for all \(a \in A\)

\sphinxAtStartPar
This follows from \(a^* = \sup A\), which implies \(a^* \in U(A)\)
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Fact}

\sphinxAtStartPar
If \(F \subset \mathbb{R}\) is a closed and bounded, then
\(\max F\) and \(\min F\) both exist
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Proof}

\sphinxAtStartPar
Proof for the max case:

\sphinxAtStartPar
Since \(F\) is bounded,
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(\sup F\) exists

\item {} 
\sphinxAtStartPar
\(\exists\) a sequence \(\{x_n\} \subset F\) with \(x_n \to \sup F\)

\end{itemize}

\sphinxAtStartPar
Since \(F\) is closed, this implies that \(\sup F \in F\)

\sphinxAtStartPar
Hence \(\max F\) exists and \(\max F = \sup F\)
\end{sphinxadmonition}


\section{Existence of optima for functions}
\label{\detokenize{06.optimization_fundamentals:existence-of-optima-for-functions}}
\sphinxAtStartPar
Now we turn to suprema and infima, maxima and minima (extrema) for functions

\sphinxAtStartPar
This is not a new concept — it’s just about extrema of sets — but the sets are the \sphinxstylestrong{range} of functions

\sphinxAtStartPar
In particular
\begin{itemize}
\item {} 
\sphinxAtStartPar
The sup of a function \(f\) is just the sup of its range

\item {} 
\sphinxAtStartPar
The max of a function \(f\) is just the max of its range

\end{itemize}

\sphinxAtStartPar
Througout we use the notation
\begin{equation*}
\begin{split}
f(A) := \{ f({\bf x}) \colon {\bf x } \in A\}
\end{split}
\end{equation*}
\begin{sphinxadmonition}{note}{Definition}

\sphinxAtStartPar
Let \(f \colon A \to \mathbb{R}\), where \(A\) is any set

\sphinxAtStartPar
The \sphinxstyleemphasis{\sphinxstylestrong{supremum of \(f\) on \(A\)}} is defined as
\begin{equation*}
\begin{split}
%
\sup_{{\bf x} \in A} f({\bf x}) 
:= \sup f(A)
%
\end{split}
\end{equation*}
\sphinxAtStartPar
The \sphinxstyleemphasis{\sphinxstylestrong{infimum of \(f\) on \(A\)}} is defined as
\begin{equation*}
\begin{split}
%
\inf_{{\bf x} \in A} f({\bf x}) 
:= \inf f(A)
%
\end{split}
\end{equation*}\end{sphinxadmonition}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{func_sup}.png}
\caption{The supremum of \(f\) on \(A\)}\label{\detokenize{06.optimization_fundamentals:id2}}\end{figure}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{func_inf}.png}
\caption{The infimum of \(f\) on \(A\)}\label{\detokenize{06.optimization_fundamentals:id3}}\end{figure}

\begin{sphinxadmonition}{note}{Definition}

\sphinxAtStartPar
Let \(f \colon A \to \mathbb{R}\) where \(A\) is any set

\sphinxAtStartPar
The \sphinxstyleemphasis{\sphinxstylestrong{maximum}} of \(f\) on \(A\) is defined as
\begin{equation*}
\begin{split}
%
\max_{{\bf x} \in A} f({\bf x}) 
:= \max f(A)
%
\end{split}
\end{equation*}
\sphinxAtStartPar
The \sphinxstyleemphasis{\sphinxstylestrong{minimum}} of \(f\) on \(A\) is defined as
\begin{equation*}
\begin{split}
%
\min_{{\bf x} \in A} f({\bf x}) 
:= \min f(A)
%
\end{split}
\end{equation*}\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Definition}

\sphinxAtStartPar
A \sphinxstyleemphasis{\sphinxstylestrong{maximizer}} of \(f\) on \(A\) is a point \({\bf a}^* \in A\) such that
\begin{equation*}
\begin{split}
%
f({\bf a}^*) = \max_{{\bf x} \in A} f({\bf x}),
%
\end{split}
\end{equation*}
\sphinxAtStartPar
or equivalently
\begin{equation*}
\begin{split}
{\bf a}^* \in A \text{ and } f({\bf a}^*) \geq f({\bf x}) \text{ for all
} {\bf x} \in A
\end{split}
\end{equation*}\end{sphinxadmonition}

\sphinxAtStartPar
The set of all maximizers is typically denoted by
\begin{equation*}
\begin{split}\mathrm{argmax}_{{\bf x} \in A}f({\bf x})\end{split}
\end{equation*}
\begin{sphinxadmonition}{note}{Definition}

\sphinxAtStartPar
A \sphinxstyleemphasis{\sphinxstylestrong{minimizer}} of \(f\) on \(A\) is a point \({\bf a}^* \in A\) such that
\begin{equation*}
\begin{split}
%
f({\bf a}^*) = \min_{{\bf x} \in A} f({\bf x}),
%
\end{split}
\end{equation*}
\sphinxAtStartPar
or equivalently
\begin{equation*}
\begin{split}
%
{\bf a}^* \in A \text{ and } f({\bf a}^*) \leq f({\bf x}) \text{ for all
} {\bf x} \in A
%
\end{split}
\end{equation*}\end{sphinxadmonition}

\sphinxAtStartPar
The set of all minimizers denoted by
\begin{equation*}
\begin{split}\mathrm{argmin}_{{\bf x} \in A}f({\bf x})\end{split}
\end{equation*}

\subsection{Weierstrass extreme value theorem}
\label{\detokenize{06.optimization_fundamentals:weierstrass-extreme-value-theorem}}
\begin{sphinxadmonition}{note}{Fact (Weierstrass extreme value theorem)}

\sphinxAtStartPar
If \(f\) is continuous and \(A\) is closed and bounded, then \(f\) has both a maximizer and a minimizer in \(A\).
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Proof}

\sphinxAtStartPar
Sketch:
\begin{itemize}
\item {} 
\sphinxAtStartPar
can show under the assumptions that \(f(A)\) is closed and bounded

\item {} 
\sphinxAtStartPar
proof uses Bolzano–Weierstrass theorem, details omitted

\end{itemize}
\end{sphinxadmonition}

\sphinxAtStartPar
Hence the max of \(f(A)\) exists, and we can write
\begin{equation*}
\begin{split}
%
M^* := \max f(A) := \max \{ f({\bf x}) \colon {\bf x } \in A\}
%
\end{split}
\end{equation*}
\sphinxAtStartPar
The point \({\bf x}^* \in A\) such that \(f({\bf x}^*) = M^*\) is a maximizer

\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
Consider the problem
\begin{equation*}
\begin{split} 
%
\max_{c_1, c_2} \; U(c_1, c_2) := \sqrt{c_1} + \beta \sqrt{c_2} 
%
\end{split}
\end{equation*}\begin{equation*}
\begin{split}
%
\text{ such that } \; c_2 \leq (1 + r)(w - c_1), 
\quad c_i \geq 0 \text{ for } i = 1,2
%
\end{split}
\end{equation*}
\sphinxAtStartPar
where
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(r=\) interest rate, \(w=\) wealth, \(\beta=\) discount factor

\item {} 
\sphinxAtStartPar
all parameters \(> 0\)

\end{itemize}
\end{sphinxadmonition}

\sphinxAtStartPar
Let \(B\) be all \((c_1, c_2)\) satisfying the constraint

\sphinxAtStartPar
\sphinxstylestrong{Exercise:} Show that the budget set \(B\) is a closed, bounded subset of \(\mathbb{R}^2\)

\sphinxAtStartPar
\sphinxstylestrong{Exercise:} Show that \(U\) is continuous on \(B\)

\sphinxAtStartPar
We conclude that a maximizer exists


\subsection{Properties of Optima}
\label{\detokenize{06.optimization_fundamentals:properties-of-optima}}
\sphinxAtStartPar
We now state some useful facts regarding optima

\sphinxAtStartPar
Sometimes we state properties about sups and infs rather than max and min — this is so we don’t have to keep saying “if it exsits”

\sphinxAtStartPar
But remember that if it does exist then the same properties apply: if a max exists, then it’s a sup, etc.

\begin{sphinxadmonition}{note}{Fact}

\sphinxAtStartPar
If \(A \subset B\) and \(f \colon B \to \mathbb{R}\), then
\begin{equation*}
\begin{split}
%
\sup_{{\bf x} \in A} f({\bf x}) \leq \sup_{{\bf x} \in B} f({\bf x})
\qquad \text{and} \qquad
\inf_{{\bf x} \in A} f({\bf x}) \geq \inf_{{\bf x} \in B} f({\bf x})
%
\end{split}
\end{equation*}\end{sphinxadmonition}

\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics{{sup_ab_func}.png}
\end{figure}

\begin{sphinxadmonition}{note}{Proof}

\sphinxAtStartPar
Proof, for the sup case:

\sphinxAtStartPar
Let \(A\), \(B\) and \(f\) be as in the statement of the fact

\sphinxAtStartPar
We already know that \(C \subset D \implies \sup C \leq \sup D\)

\sphinxAtStartPar
Hence it suffices to show that \(f(A) \subset f(B)\), because then
\begin{equation*}
\begin{split}
%
\sup_{{\bf x} \in A} f({\bf x}) 
:= \sup f(A)
\leq \sup f(B) 
=: \sup_{{\bf x} \in B} f({\bf x})
%
\end{split}
\end{equation*}
\sphinxAtStartPar
To see that \(f(A) \subset f(B)\), take any \(y \in f(A)\)

\sphinxAtStartPar
By definition, \(\exists \, {\bf x} \in A\) such that \(f({\bf x}) = y\)

\sphinxAtStartPar
Since \(A \subset B\) we must have \({\bf x} \in B\)

\sphinxAtStartPar
So \(f({\bf x}) = y\) for some \({\bf x} \in B\), and hence \(y \in f(B)\)

\sphinxAtStartPar
Thus \(f(A) \subset f(B)\) as was to be shown
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
“If you have more choice then you’re better off”
\end{sphinxadmonition}

\sphinxAtStartPar
Consider the problem of maximizing utility
\begin{equation*}
\begin{split}
%
U(x_1, x_2) = \alpha \log(x_1) + \beta \log(x_2)
%
\end{split}
\end{equation*}
\sphinxAtStartPar
over all \((x_1, x_2)\) in the budget set
\begin{equation*}
\begin{split}
%
B(m) 
:= \left\{ 
(x_1, x_2) \in \mathbb{R}^2
\;:\;
x_i > 0 \text{ and } p_1 x_1 + p_2 x_2 \leq m
\right\}
%
\end{split}
\end{equation*}
\sphinxAtStartPar
Thus, we solve
\begin{equation*}
\begin{split}
%
\max_{{\bf x} \in B(m)} U({\bf x})
%
\end{split}
\end{equation*}
\sphinxAtStartPar
Clearly \(m \leq m' \implies B(m) \subset B(m')\)

\sphinxAtStartPar
Hence the maximal value goes up as \(m\) increases

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{bset1}.png}
\caption{Budget set \(B(m)\)}\label{\detokenize{06.optimization_fundamentals:id4}}\end{figure}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{bset2}.png}
\caption{Budget set \(B(m')\)}\label{\detokenize{06.optimization_fundamentals:id5}}\end{figure}

\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
Let \(y_n\) be income and \(x_n\) be years education
\end{sphinxadmonition}

\sphinxAtStartPar
Consider regressing income on education:
\begin{equation*}
\begin{split}
%
y_n = \alpha + \beta x_n + \epsilon_n 
%
\end{split}
\end{equation*}
\sphinxAtStartPar
We have data for \(n = 1, \ldots, N\) individuals

\sphinxAtStartPar
Successful regression is often associated with large \(R^2\)
\begin{itemize}
\item {} 
\sphinxAtStartPar
A measure of “goodness of fit”

\end{itemize}

\sphinxAtStartPar
Large \(R^2\) occurs when we have a small sum of squared residuals
\begin{equation*}
\begin{split}
%
{\rm ssr}_a := 
\min_{\alpha, \beta} 
\; \sum_{n=1}^N \, (y_n - \alpha - \beta x_n)^2
%
\end{split}
\end{equation*}
\sphinxAtStartPar
However, we can always reduce the ssr by including irrelevant variables
\begin{itemize}
\item {} 
\sphinxAtStartPar
e.g., \(z_n = \) consumption of apples in kgs per annum

\end{itemize}
\begin{equation*}
\begin{split}
%
{\rm ssr}_b := 
\min_{\alpha, \beta, \gamma} 
\; \sum_{n=1}^N \, (y_n - \alpha - \beta x_n - \gamma z_n)^2
\, \leq {\rm ssr}_a
%
\end{split}
\end{equation*}
\sphinxAtStartPar
Indeed, let
\begin{equation*}
\begin{split}
%
{\boldsymbol \theta} 
:= (\alpha, \beta, \gamma),
\qquad
f({\boldsymbol \theta}) 
:= 
\sum_{n=1}^N \, (y_n - \alpha - \beta x_n - \gamma z_n)^2
%
\end{split}
\end{equation*}
\sphinxAtStartPar
Then
\begin{equation*}
\begin{split}
%
{\rm ssr}_b 
= \min_{{\boldsymbol \theta} \in \mathbb{R}^3} f({\boldsymbol \theta})
\leq 
\min_{\substack{{\boldsymbol \theta} \in \mathbb{R}^3 \\ \gamma = 0}} f({\boldsymbol \theta})
= {\rm ssr}_a
%
\end{split}
\end{equation*}
\begin{sphinxadmonition}{note}{Fact}

\sphinxAtStartPar
If \(f \colon A \to \mathbb{R}\), then
\begin{equation*}
\begin{split}
%
{\bf a}^* \in \mathrm{argmax}_{{\bf x} \in A}f({\bf x})
\; \iff \;
{\bf a}^* \in \mathrm{argmin}_{{\bf x} \in A} -f({\bf x})
%
\end{split}
\end{equation*}\end{sphinxadmonition}

\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics{{max_min}.png}
\end{figure}

\begin{sphinxadmonition}{note}{Proof}

\sphinxAtStartPar
Let’s prove that, when \(g = -f\),
\begin{equation*}
\begin{split}
%
{\bf a}^* \in \mathrm{argmax}_{{\bf x} \in A}f({\bf x})
\; \implies \;
{\bf a}^* \in \mathrm{argmin}_{{\bf x} \in A}g({\bf x})
%
\end{split}
\end{equation*}
\sphinxAtStartPar
To begin, let \({\bf a}^*\) be a maximizer of \(f\) on \(A\)

\sphinxAtStartPar
Then, for any given \({\bf x} \in A\) we have \(f({\bf a}^*) \geq f({\bf x})\)
\begin{equation*}
\begin{split}
%
\implies
-f({\bf a}^*) \leq -f({\bf x})
%
\end{split}
\end{equation*}\begin{equation*}
\begin{split}
%
\implies
g({\bf a}^*) \leq g({\bf x})
%
\end{split}
\end{equation*}
\sphinxAtStartPar
Hence \({\bf a}^*\) is a minimizer of \(g\) on \(A\)
\begin{itemize}
\item {} 
\sphinxAtStartPar
because the last inequality was shown for any \({\bf x} \in A\)

\end{itemize}
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
Most numerical routines provide minimization only

\sphinxAtStartPar
Suppose we want to maximize \(f(x) = 3 \ln x - x\) on \((0, \infty)\)

\sphinxAtStartPar
We can do this by finding the minimizer of \(-f\)
\end{sphinxadmonition}

\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{from} \PYG{n+nn}{scipy}\PYG{n+nn}{.}\PYG{n+nn}{optimize} \PYG{k+kn}{import} \PYG{n}{fminbound}
\PYG{k+kn}{import} \PYG{n+nn}{numpy} \PYG{k}{as} \PYG{n+nn}{np}

\PYG{n}{f} \PYG{o}{=} \PYG{k}{lambda} \PYG{n}{x}\PYG{p}{:} \PYG{l+m+mi}{3} \PYG{o}{*} \PYG{n}{np}\PYG{o}{.}\PYG{n}{log}\PYG{p}{(}\PYG{n}{x}\PYG{p}{)} \PYG{o}{\PYGZhy{}} \PYG{n}{x}
\PYG{n}{g} \PYG{o}{=} \PYG{k}{lambda} \PYG{n}{x}\PYG{p}{:} \PYG{o}{\PYGZhy{}}\PYG{n}{f}\PYG{p}{(}\PYG{n}{x}\PYG{p}{)} \PYG{c+c1}{\PYGZsh{} Find min of \PYGZhy{}f}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Maximizer of f(x) on [1,100] is x=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{fminbound}\PYG{p}{(}\PYG{n}{g}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{,} \PYG{l+m+mi}{100}\PYG{p}{)}\PYG{p}{)}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
Maximizer of f(x) on [1,100] is x= 3.0000015012062393
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\begin{sphinxadmonition}{note}{Fact}

\sphinxAtStartPar
Given \(A \subset \mathbb{R}^K\), let
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(f \colon A \to B \subset \mathbb{R}\)

\item {} 
\sphinxAtStartPar
\(h \colon B \to \mathbb{R}\) and \(g := h \circ f\)

\end{itemize}

\sphinxAtStartPar
If \(h\) is strictly increasing, then
\begin{equation*}
\begin{split}\mathrm{argmax}_{{\bf x} \in A}f({\bf x}) =\mathrm{argmax}_{{\bf x} \in A}g({\bf x})\end{split}
\end{equation*}\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Proof}

\sphinxAtStartPar
Let \({\bf a}^* \in \mathrm{argmax}_{{\bf x} \in A}f({\bf x})\)

\sphinxAtStartPar
If \({\bf x} \in A\), then \(f({\bf x}) \leq f({\bf a}^*)\), and hence \(h(f({\bf x})) \leq h(f({\bf a}^*)) \quad\)

\sphinxAtStartPar
In other words, \(g({\bf x}) \leq g({\bf a}^*)\) for any \({\bf x} \in A\)

\sphinxAtStartPar
Hence \({\bf a}^* \in \mathrm{argmax}_{{\bf x} \in A} g({\bf x})\) as claimed
\end{sphinxadmonition}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{max_preserved}.png}
\caption{Increasing transform \(h(x) = \exp(x/2)\) preserves the maximizer}\label{\detokenize{06.optimization_fundamentals:id6}}\end{figure}

\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
A well known statistical problem is to maximize the likelihood of exponential distribution:
\begin{equation*}
\begin{split}
%
\max_{\lambda > 0} L(\lambda)
\quad \text{where} \quad
L(\lambda) 
:= \lambda^N \exp \left(-\lambda \sum_{n=1}^N x_n \right)
%
\end{split}
\end{equation*}
\sphinxAtStartPar
It’s easier to maximize the log\sphinxhyphen{}likelihood function
\begin{equation*}
\begin{split}
%
\ell(\lambda) 
:= \log(L(\lambda))
= N \log(\lambda) - \lambda \sum_{n=1}^N x_n 
%
\end{split}
\end{equation*}
\sphinxAtStartPar
The unique solution
\begin{equation*}
\begin{split}
%
\hat \lambda := \frac{N}{\sum_{n=1}^N x_n}
%
\end{split}
\end{equation*}
\sphinxAtStartPar
is also the unique maximiser of \(L(\lambda)\)
\end{sphinxadmonition}

\sphinxAtStartPar
In the next several propositions
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(A\) is any set

\item {} 
\sphinxAtStartPar
\(f\) is some function from \(A\) to \(\mathbb{R}\)

\item {} 
\sphinxAtStartPar
\(g\) is some function from \(A\) to \(\mathbb{R}\)

\end{itemize}

\sphinxAtStartPar
To simplify notation, we define
\begin{equation*}
\begin{split}
%
\inf f 
:= \inf_{{\bf x} \in A} f({\bf x}) 
%
\end{split}
\end{equation*}
\sphinxAtStartPar
and
\begin{equation*}
\begin{split}
%
\sup f 
:= \sup_{{\bf x} \in A} f({\bf x}) 
%
\end{split}
\end{equation*}
\begin{sphinxadmonition}{note}{Fact}
\begin{equation*}
\begin{split}
%
f({\bf x}) \leq g({\bf x}) \text{ for all } {\bf x} \in A
\implies
\sup f \leq \sup g
%
\end{split}
\end{equation*}\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Proof}

\sphinxAtStartPar
Fix any such functions \(f\) and \(g\) and any \({\bf x} \in A\)

\sphinxAtStartPar
We have
\begin{equation*}
\begin{split}
%
f({\bf x}) \leq g({\bf x}) \leq \sup g
%
\end{split}
\end{equation*}
\sphinxAtStartPar
Hence \(\sup g\) is an upper bound for \(\{ f({\bf x}) \colon {\bf x } \in A\}\)

\sphinxAtStartPar
Since the supremum is the least upper bound, this gives
\begin{equation*}
\begin{split}
%
\sup f \leq \sup g
%
\end{split}
\end{equation*}\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Fact}
\begin{equation*}
\begin{split}
%
\sup_{{\bf x} \in A} (f({\bf x}) + g({\bf x})) 
\leq \sup_{{\bf x} \in A} f({\bf x}) + \sup_{{\bf x} \in A} g({\bf x})
%
\end{split}
\end{equation*}\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Proof}

\sphinxAtStartPar
Fix any such functions \(f\) and \(g\) and any \({\bf x} \in A\)

\sphinxAtStartPar
We have
\begin{equation*}
\begin{split}
%
f({\bf x}) \leq \sup f
\quad \text{and} \quad 
g({\bf x}) \leq \sup g
%
\end{split}
\end{equation*}\begin{equation*}
\begin{split}
%
\implies
f({\bf x}) + g({\bf x}) \leq \sup f + \sup g
%
\end{split}
\end{equation*}\begin{equation*}
\begin{split}
%
\implies
\sup (f + g) \leq \sup f + \sup g
%
\end{split}
\end{equation*}\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Fact}
\begin{equation*}
\begin{split}
%
| \sup_{{\bf x} \in A} f({\bf x}) - \sup_{{\bf x} \in A} g({\bf x}) | \leq
\sup_{{\bf x} \in A} |f({\bf x}) - g({\bf x})|
%
\end{split}
\end{equation*}\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Proof}

\sphinxAtStartPar
Picking any such \(f, g\), we have
\begin{equation*}
\begin{split}
%
\sup f = \sup (f - g + g) 
& \leq \sup (f - g) + \sup g
\\
& \leq \sup | f - g | + \sup g
%
\end{split}
\end{equation*}\begin{equation*}
\begin{split}
%
\text{therefore } \; \sup f - \sup g \leq \sup | f - g |
%
\end{split}
\end{equation*}
\sphinxAtStartPar
Same argument reversing roles of \(f\) and \(g\) finishes the proof
\end{sphinxadmonition}


\section{Concavity and uniqueness of optima}
\label{\detokenize{06.optimization_fundamentals:concavity-and-uniqueness-of-optima}}
\sphinxAtStartPar
Uniqueness of optima is directly connected to convexity / concavity
\begin{itemize}
\item {} 
\sphinxAtStartPar
Convexity is a shape property for sets

\item {} 
\sphinxAtStartPar
Convexity and concavity are shape properties for functions

\end{itemize}

\sphinxAtStartPar
However, only one fundamental concept: convex sets


\subsection{Convex Sets}
\label{\detokenize{06.optimization_fundamentals:convex-sets}}
\begin{sphinxadmonition}{note}{Definition}

\sphinxAtStartPar
A set \(C \subset \mathbb{R}^K\) is called \sphinxstyleemphasis{\sphinxstylestrong{convex}} if
\begin{equation*}
\begin{split}
%
{\bf x}, {\bf y} \text{ in } C \text{ and } 0 \leq \lambda \leq 1
\; \implies \;
\lambda {\bf x} + (1 - \lambda) {\bf y} \in C
%
\end{split}
\end{equation*}\end{sphinxadmonition}

\sphinxAtStartPar
Remark: This is vector addition and scalar multiplication

\sphinxAtStartPar
Convexity \(\iff\) line between any two points in \(C\) lies in \(C\)

\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics[scale=0.5]{{convex}.png}
\end{figure}

\sphinxAtStartPar
A non\sphinxhyphen{}convex set

\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics[scale=0.5]{{non_convex}.png}
\end{figure}

\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
The “positive cone” \(P := \{ {\bf x} \in \mathbb{R}^K \colon {\bf x } \geq {\bf 0} \}\) is convex
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Proof}

\sphinxAtStartPar
To see this, pick any \({\bf x}\), \({\bf y}\) in \(P\) and any \(\lambda \in [0, 1]\)

\sphinxAtStartPar
Let \({\bf z} := \lambda {\bf x} + (1 - \lambda) {\bf y}\) and let \(z_k :=
{\bf e}_k' {\bf z}\)

\sphinxAtStartPar
Since
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(z_k = \lambda x_k + (1 - \lambda) y_k\)

\item {} 
\sphinxAtStartPar
\(x_k \geq 0\) and \(y_k \geq 0\)

\end{itemize}

\sphinxAtStartPar
It is clear that \(z_k \geq 0\) for all \(k\)

\sphinxAtStartPar
Hence \({\bf z} \in P\) as claimed
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
Every \(\epsilon\)\sphinxhyphen{}ball in \(\mathbb{R}^K\) is convex.
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Proof}

\sphinxAtStartPar
Fix \({\bf a} \in \mathbb{R}^K\), \(\epsilon > 0\) and let
\(B_\epsilon({\bf a})\) be the \(\epsilon\)\sphinxhyphen{}ball

\sphinxAtStartPar
Pick any \({\bf x}\), \({\bf y}\) in \(B_\epsilon({\bf a})\) and any \(\lambda \in [0, 1]\)

\sphinxAtStartPar
The point \(\lambda {\bf x} + (1 - \lambda) {\bf y}\) lies in
\(B_\epsilon({\bf a})\) because
\begin{equation*}
\begin{split}
%
& \| \lambda {\bf x} + (1 - \lambda) {\bf y} - {\bf a} \|
= \| \lambda {\bf x} - \lambda {\bf a} 
+ (1 - \lambda) {\bf y} - (1 - \lambda) {\bf a} \| \leq
\\ &
\leq \| \lambda {\bf x} - \lambda {\bf a} \|
+ \| (1 - \lambda) {\bf y} - (1 - \lambda) {\bf a} \| =
\\ &
= \lambda \| {\bf x} - {\bf a} \|
+ (1 - \lambda) \| {\bf y} - {\bf a} \| <>
\\ &
< \lambda \epsilon + (1 - \lambda) \epsilon =
\\ &
= \epsilon
%
\end{split}
\end{equation*}\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
Let \({\bf p} \in \mathbb{R}^K\) and let \(M\) be the “half\sphinxhyphen{}space”
\begin{equation*}
\begin{split}
%
M := \{ {\bf x} \in \mathbb{R}^K \colon {\bf p }' {\bf x} \leq m\}
%
\end{split}
\end{equation*}
\sphinxAtStartPar
The set \(M\) is convex
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Proof}

\sphinxAtStartPar
Let \({\bf p}\), \(m\) and \(M\) be as described

\sphinxAtStartPar
Fix \({\bf x}\), \({\bf y}\) in \(M\) and \(\lambda \in [0, 1]\)

\sphinxAtStartPar
Then \(\lambda {\bf x} + (1 - \lambda) {\bf y} \in M\) because
\begin{equation*}
\begin{split}
%
{\bf p}'[\lambda {\bf x} + (1 - \lambda) {\bf y} ] =
\lambda {\bf p}'{\bf x} + (1 - \lambda) {\bf p}'{\bf y} 
\leq \lambda m + (1 - \lambda) m
= m
%
\end{split}
\end{equation*}
\sphinxAtStartPar
Hence \(M\) is convex
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Fact}

\sphinxAtStartPar
If \(A\) and \(B\) are convex, then so is \(A \cap B\)
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Proof}

\sphinxAtStartPar
Let \(A\) and \(B\) be convex and let \(C := A \cap B\)

\sphinxAtStartPar
Pick any \({\bf x}\), \({\bf y}\) in \(C\) and any \(\lambda \in [0, 1]\)

\sphinxAtStartPar
Set
\begin{equation*}
\begin{split}{\bf z} := \lambda {\bf x} + (1 - \lambda) {\bf y}\end{split}
\end{equation*}
\sphinxAtStartPar
Since \({\bf x}\) and \({\bf y}\) lie in \(A\) and \(A\) is convex we have \({\bf z}
\in A\)

\sphinxAtStartPar
Since \({\bf x}\) and \({\bf y}\) lie in \(B\) and \(B\) is convex we have \({\bf z}
\in B\)

\sphinxAtStartPar
Hence \({\bf z} \in A \cap B\)
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
Let \({\bf p} \in \mathbb{R}^K\) be a vector of prices and consider the budget set
\begin{equation*}
\begin{split}
%
B(m) := \{ {\bf x} \in \mathbb{R}^K \colon {\bf x } \geq {\bf 0} \text{ and }
{\bf p}' {\bf x} \leq m\}
%
\end{split}
\end{equation*}
\sphinxAtStartPar
The budget set \(B(m)\) is convex
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Proof}

\sphinxAtStartPar
To see this, note that \(B(m) = P \cap M\) where
\begin{equation*}
\begin{split}
%
P := \{ {\bf x} \in \mathbb{R}^K \colon {\bf x } \geq {\bf 0} \}
\qquad
M := \{ {\bf x} \in \mathbb{R}^K \colon {\bf p }' {\bf x} \leq m\}
%
\end{split}
\end{equation*}
\sphinxAtStartPar
We already know that
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(P\) and \(M\) are convex, intersections of convex sets are convex

\end{itemize}

\sphinxAtStartPar
Hence \(B(m)\) is convex
\end{sphinxadmonition}


\subsection{Convex Functions}
\label{\detokenize{06.optimization_fundamentals:convex-functions}}
\sphinxAtStartPar
Let \(A \subset \mathbb{R}^K\) be a convex set and let \(f\) be a function from \(A\) to \(\mathbb{R}\)

\begin{sphinxadmonition}{note}{Definition}

\sphinxAtStartPar
\(f\) is called \sphinxstyleemphasis{\sphinxstylestrong{convex}} if
\begin{equation*}
\begin{split}
%
f(\lambda {\bf x} + (1 - \lambda) {\bf y})
\leq \lambda f({\bf x}) + (1 - \lambda) f({\bf y})
%
\end{split}
\end{equation*}
\sphinxAtStartPar
for all \({\bf x}, {\bf y} \in A\) and all \(\lambda \in [0, 1]\)
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Definition}

\sphinxAtStartPar
\(f\) is called \sphinxstyleemphasis{\sphinxstylestrong{strictly convex}} if
\begin{equation*}
\begin{split}
%
f(\lambda {\bf x} + (1 - \lambda) {\bf y})
< \lambda f({\bf x}) + (1 - \lambda) f({\bf y})
%
\end{split}
\end{equation*}
\sphinxAtStartPar
for all \({\bf x}, {\bf y} \in A\) with \({\bf x} \ne {\bf y}\) and all \(\lambda \in (0, 1)\)
\end{sphinxadmonition}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{convex_function}.png}
\caption{A strictly convex function on a subset of \(\mathbb{R}\)}\label{\detokenize{06.optimization_fundamentals:id7}}\end{figure}

\begin{sphinxadmonition}{note}{Fact}

\sphinxAtStartPar
\(f \colon A \to \mathbb{R}\) is convex if and only if its \sphinxstyleemphasis{\sphinxstylestrong{epigraph}} (aka supergraph)
\begin{equation*}
\begin{split}
%
E_f := \{ ({\bf x}, y) \in A \times \mathbb{R} \colon f({\bf x \}) \leq y}
%
\end{split}
\end{equation*}
\sphinxAtStartPar
is a convex subset of \(\mathbb{R}^K \times \mathbb{R}\)
\end{sphinxadmonition}

\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics{{epigraph}.png}
\end{figure}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{qform_pd}.png}
\caption{A strictly convex function on a subset of \(\mathbb{R}^2\)}\label{\detokenize{06.optimization_fundamentals:id8}}\end{figure}

\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
\(f({\bf x}) = \|{\bf x}\|\) is convex on \(\mathbb{R}^K\)
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Proof}

\sphinxAtStartPar
To see this recall that, by the properties of norms,
\begin{equation*}
\begin{split}
%
\|\lambda {\bf x} + (1 - \lambda) {\bf y}\|
& \leq \|\lambda {\bf x}\| + \|(1 - \lambda) {\bf y}\|
\\
= \lambda \|{\bf x}\| + (1 - \lambda) \|{\bf y}\|
%
\end{split}
\end{equation*}
\sphinxAtStartPar
That is,
\begin{equation*}
\begin{split}
%
f(\lambda {\bf x} + (1 - \lambda) {\bf y})
\leq 
\lambda f({\bf x}) + (1 - \lambda) f({\bf y})
%
\end{split}
\end{equation*}\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
\(f(x) = \cos(x)\) is \sphinxstyleemphasis{\sphinxstylestrong{not}} convex on \(\mathbb{R}\) because
\begin{equation*}
\begin{split}
%
1 = f(2\pi) = f(\pi/2 + 3\pi/2) > f(\pi)/2 + f(3\pi)/2 = -1
%
\end{split}
\end{equation*}\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Fact}

\sphinxAtStartPar
If \({\bf A}\) is \(K \times K\) and positive definite, then
\begin{equation*}
\begin{split}
%
Q({\bf x}) = {\bf x}' {\bf A} {\bf x}
\qquad ({\bf x} \in \mathbb{R}^K)
%
\end{split}
\end{equation*}
\sphinxAtStartPar
is strictly convex on \(\mathbb{R}^K\)
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Proof}

\sphinxAtStartPar
Proof: Fix \({\bf x}, {\bf y} \in \mathbb{R}^K\) with \({\bf x} \ne {\bf y}\) and \(\lambda \in (0, 1)\)

\sphinxAtStartPar
\sphinxstylestrong{Exercise:} Show that
\begin{equation*}
\begin{split}
%
\lambda Q({\bf x}) + (1 - \lambda) Q({\bf y})
& - Q(\lambda {\bf x} + (1 - \lambda) {\bf y})
\\
= \lambda (1 - \lambda) ({\bf x} - {\bf y})' {\bf A} ({\bf x} - {\bf y})
%
\end{split}
\end{equation*}
\sphinxAtStartPar
Since \({\bf x} - {\bf y} \ne {\bf 0}\) and \(0 < \lambda < 1\), the right
hand side is \(> 0\)

\sphinxAtStartPar
Hence
\begin{equation*}
\begin{split}
%
\lambda Q({\bf x}) + (1 - \lambda) Q({\bf y})
> Q(\lambda {\bf x} + (1 - \lambda) {\bf y})
%
\end{split}
\end{equation*}\end{sphinxadmonition}


\subsection{Concave Functions}
\label{\detokenize{06.optimization_fundamentals:concave-functions}}
\sphinxAtStartPar
Let \(A \subset \mathbb{R}^K\) be a convex and let \(f\) be a function from \(A\) to \(\mathbb{R}\)

\begin{sphinxadmonition}{note}{Definition}

\sphinxAtStartPar
\(f\) is called \sphinxstyleemphasis{\sphinxstylestrong{concave}} if
\begin{equation*}
\begin{split}
%
f(\lambda {\bf x} + (1 - \lambda) {\bf y})
\geq \lambda f({\bf x}) + (1 - \lambda) f({\bf y})
%
\end{split}
\end{equation*}
\sphinxAtStartPar
for all \({\bf x}, {\bf y} \in A\) and all \(\lambda \in [0, 1]\)
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Definition}

\sphinxAtStartPar
\(f\) is called \sphinxstyleemphasis{\sphinxstylestrong{strictly concave}} if
\begin{equation*}
\begin{split}
%
f(\lambda {\bf x} + (1 - \lambda) {\bf y})
> \lambda f({\bf x}) + (1 - \lambda) f({\bf y})
%
\end{split}
\end{equation*}
\sphinxAtStartPar
for all \({\bf x}, {\bf y} \in A\) with \({\bf x} \ne {\bf y}\) and all \(\lambda \in (0, 1)\)
\end{sphinxadmonition}

\sphinxAtStartPar
\sphinxstylestrong{Exercise:} Show that
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
\(f\) is concave if and only if \(-f\) is convex

\item {} 
\sphinxAtStartPar
\(f\) is strictly concave if and only if \(-f\) is strictly convex

\end{enumerate}

\begin{sphinxadmonition}{note}{Fact}

\sphinxAtStartPar
\(f \colon A \to \mathbb{R}\) is concave if and only if its \sphinxstyleemphasis{\sphinxstylestrong{hypograph}} (aka subgraph)
\begin{equation*}
\begin{split}
%
H_f := \{ ({\bf x}, y) \in A \times \mathbb{R} \colon f({\bf x \}) \geq y}
%
\end{split}
\end{equation*}
\sphinxAtStartPar
is a convex subset of \(\mathbb{R}^K \times \mathbb{R}\)
\end{sphinxadmonition}

\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics{{hypograph}.png}
\end{figure}


\subsection{Preservation of Shape}
\label{\detokenize{06.optimization_fundamentals:preservation-of-shape}}
\sphinxAtStartPar
Let \(A \subset \mathbb{R}^K\) be convex and let \(f\) and \(g\) be functions from \(A\)
to \(\mathbb{R}\)

\begin{sphinxadmonition}{note}{Fact}

\sphinxAtStartPar
If \(f\) and \(g\) are convex (resp., concave) and \(\alpha \geq 0\), then
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(\alpha f\) is convex (resp., concave)

\item {} 
\sphinxAtStartPar
\(f + g\) is convex (resp., concave)

\end{itemize}
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Fact}

\sphinxAtStartPar
If \(f\) and \(g\) are strictly convex (resp., strictly concave) and \(\alpha > 0\), then
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(\alpha f\) is strictly convex (resp., strictly concave)

\item {} 
\sphinxAtStartPar
\(f + g\) is strictly convex (resp., strictly concave)

\end{itemize}
\end{sphinxadmonition}

\sphinxAtStartPar
Let’s prove that \(f\) and \(g\) convex \(\implies h := f + g\) convex

\sphinxAtStartPar
Pick any \({\bf x}, {\bf y} \in A\) and \(\lambda \in [0, 1]\)

\sphinxAtStartPar
We have
\begin{equation*}
\begin{split}
%
& 
h(\lambda {\bf x} + (1 - \lambda) {\bf y})
= f(\lambda {\bf x} + (1 - \lambda) {\bf y})
+ g(\lambda {\bf x} + (1 - \lambda) {\bf y})
\\ &
\leq 
\lambda f({\bf x}) + (1 - \lambda) f({\bf y})
+
\lambda g({\bf x}) + (1 - \lambda) g({\bf y})
\\ &
=
\lambda [f({\bf x}) + g({\bf x})]
+ (1 - \lambda) [f({\bf y}) + g({\bf y})]
\\ &
=
\lambda h({\bf x}) + (1 - \lambda) h({\bf y})
%
\end{split}
\end{equation*}
\sphinxAtStartPar
Hence \(h\) is convex


\section{Uniqueness of Optimizers}
\label{\detokenize{06.optimization_fundamentals:uniqueness-of-optimizers}}
\begin{sphinxadmonition}{note}{Fact}

\sphinxAtStartPar
Let \(A \subset \mathbb{R}^K\) be convex and let \(f \colon A \to \mathbb{R}\)
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
If \(f\) is strictly convex, then \(f\) has at most one minimizer on \(A\)

\item {} 
\sphinxAtStartPar
If \(f\) is strictly concave, then \(f\) has at most one maximizer on \(A\)

\end{enumerate}
\end{sphinxadmonition}

\sphinxAtStartPar
Interpretation, strictly concave case:
\begin{itemize}
\item {} 
\sphinxAtStartPar
we don’t know in general if \(f\) has a maximizer

\item {} 
\sphinxAtStartPar
but if it does, then it has exactly one

\item {} 
\sphinxAtStartPar
in other words, we have uniqueness

\end{itemize}

\begin{sphinxadmonition}{note}{Proof}

\sphinxAtStartPar
Proof for the case where \(f\) is strictly concave:

\sphinxAtStartPar
Suppose to the contrary that
\begin{itemize}
\item {} 
\sphinxAtStartPar
\({\bf a}\) and \({\bf b}\) are distinct points in \(A\)

\item {} 
\sphinxAtStartPar
both are maximizers of \(f\) on \(A\)

\end{itemize}

\sphinxAtStartPar
By the def of maximizers, \(f({\bf a}) \geq f({\bf b})\) and \(f({\bf b}) \geq f({\bf a})\)

\sphinxAtStartPar
Hence we have \(f({\bf a}) = f({\bf b})\)

\sphinxAtStartPar
By strict concavity, then
\begin{equation*}
\begin{split}
%
f\left( \frac{1}{2} {\bf a} + \frac{1}{2} {\bf b} \right)
> \frac{1}{2} f( {\bf a}) + \frac{1}{2} f( {\bf b})
= \frac{1}{2} f( {\bf a}) + \frac{1}{2} f( {\bf a})
= f({\bf a})
%
\end{split}
\end{equation*}
\sphinxAtStartPar
This contradicts the assumption that \({\bf a}\) is a maximizer
\end{sphinxadmonition}


\subsection{A Sufficient Condition}
\label{\detokenize{06.optimization_fundamentals:a-sufficient-condition}}
\sphinxAtStartPar
We can now restate more precisely optimization results stated in the
introductory lectures

\sphinxAtStartPar
Let \(f \colon A \to \mathbb{R}\) be a \(C^2\) function where \(A \subset \mathbb{R}^K\)
is open, convex

\sphinxAtStartPar
Recall that \({\bf x}^* \in A\) is a stationary point of \(f\) if
\begin{equation*}
\begin{split}
%
\frac{\partial}{\partial x_i} 
f({\bf x}^*)
= 0
\quad \text{for all $i$ in } 1, \ldots, K
%
\end{split}
\end{equation*}
\begin{sphinxadmonition}{note}{Fact}

\sphinxAtStartPar
If \(f\) and \(A\) are as above and \({\bf x}^* \in A\) is stationary, then
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
\(f\) strictly concave \(\implies\) \({\bf x}^*\) is the unique maximizer of \(f\) on \(A\)

\item {} 
\sphinxAtStartPar
\(f\) strictly convex \(\implies\) \({\bf x}^*\) is the unique
minimizer of \(f\) on \(A\)

\end{enumerate}
\end{sphinxadmonition}

\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics{{concave_max}.png}
\end{figure}

\sphinxstepscope


\chapter{Unconstrained optimization}
\label{\detokenize{07.unconstrained:unconstrained-optimization}}\label{\detokenize{07.unconstrained::doc}}
\noindent{\hspace*{\fill}\sphinxincludegraphics[scale=1.0]{{coming_soon}.png}\hspace*{\fill}}



\sphinxstepscope


\chapter{Constrained optimization}
\label{\detokenize{08.constrained:constrained-optimization}}\label{\detokenize{08.constrained::doc}}
\noindent{\hspace*{\fill}\sphinxincludegraphics[scale=1.0]{{coming_soon}.png}\hspace*{\fill}}

\sphinxstepscope


\chapter{Practical session}
\label{\detokenize{09.practical_session:practical-session}}\label{\detokenize{09.practical_session::doc}}
\noindent{\hspace*{\fill}\sphinxincludegraphics[scale=1.0]{{coming_soon}.png}\hspace*{\fill}}

\sphinxstepscope


\chapter{Envelope and maximum theorems}
\label{\detokenize{10.envelope_maximum:envelope-and-maximum-theorems}}\label{\detokenize{10.envelope_maximum::doc}}
\noindent{\hspace*{\fill}\sphinxincludegraphics[scale=1.0]{{coming_soon}.png}\hspace*{\fill}}

\sphinxstepscope


\chapter{Dynamic optimization}
\label{\detokenize{11.dynamic:dynamic-optimization}}\label{\detokenize{11.dynamic::doc}}
\noindent{\hspace*{\fill}\sphinxincludegraphics[scale=1.0]{{coming_soon}.png}\hspace*{\fill}}

\sphinxstepscope


\chapter{Revision}
\label{\detokenize{12.revision:revision}}\label{\detokenize{12.revision::doc}}
\noindent{\hspace*{\fill}\sphinxincludegraphics[scale=1.0]{{coming_soon}.png}\hspace*{\fill}}

\sphinxstepscope


\chapter{Exercise set A}
\label{\detokenize{02.exercises.A:exercise-set-a}}\label{\detokenize{02.exercises.A::doc}}
\sphinxAtStartPar
\sphinxstylestrong{General comment on the tutorial exercises}
\begin{itemize}
\item {} 
\sphinxAtStartPar
these questions are not directly assessable and solutions are provided in a separate document

\item {} 
\sphinxAtStartPar
the aim is to help you better understand the material we have covered so far and start to prepare for actual assessments

\item {} 
\sphinxAtStartPar
if you are having no particular problems with this course then
please carry on to the questions below; if, on the other hand, you are having difﬁculty with the material, then please read on

\item {} 
\sphinxAtStartPar
this is an upper level course on mathematics for economists that pushes you beyond the boundaries of the kind of things we do in high school or ﬁrst year university

\item {} 
\sphinxAtStartPar
many people ﬁnd this material hard at ﬁrst, however, the experience is that anyone who works diligently and consistently can and will do well

\end{itemize}

\sphinxAtStartPar
Here are few tips on getting through and doing well:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
It’s hard to “wing” this course, even if you did well at maths in high school. It’s also very hard to follow everything just from the lectures.
It takes practice to do well, just like playing guitar or learning a language. The ﬁrst resource is the lecture slides, and the more often you read them the more the deﬁnitions will stick and the material will gel in your head.

\item {} 
\sphinxAtStartPar
Each time you are having difficulty with a new concept try googling it. Have a look at Wikipedia, find a video on YouTube, or some of the other online resources. They might phrase or explain the concept in a way that ﬁts better with your brain.

\item {} 
\sphinxAtStartPar
Work consistently throughout the semester. Concepts become clearer and more familiar the more times that you go over them—with at least one sleep in between to allow your brain to organize neurons and synapses to store and categorize this new information.

\item {} 
\sphinxAtStartPar
Make use of your tutors. They are very knowledgable and are willing to put in time to help anyone who is genuinely trying (although much less inclined to help those who aren’t).

\item {} 
\sphinxAtStartPar
Send me feedback if you think it’s something I can help with (e.g., more practice questions on a certain topic) or drop in during my ofﬁce hours to discuss.

\item {} 
\sphinxAtStartPar
Above all, remember that the course material is nontrivial for a reason. Doing straightforward calculations applying well known rules or memorizing “cookbooks” of facts are not particularly useful, mainly because computers are far, far better than humans at these kinds of activities. What is still very useful—probably more than ever—is understanding concepts and how they relate to each other, and building up your ability to digest technical material and think in a logical way.
If you complete this course successfully you will have signiﬁcantly upgraded your mathematical skills.

\end{enumerate}

\sphinxAtStartPar
Finally, here are some tips on doing proofs:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
In many instances there will be an easy way to do things, if you can spot it. A question that seems to require a long calculation will likely have an easy answer if you know the relevant fact.

\item {} 
\sphinxAtStartPar
If you feel stuck, remember that the hardest step is getting started, and for proofs the best place to start is always the relevant deﬁnitions. If you are asked to show that the range of a given function is a linear subspace, start by writing down those two deﬁnitions. They will tell you more speciﬁcally what you need to show. If you’re still stuck, review any facts from the lecture slides related to those deﬁnitions. Is there a different way to describe the range of this function? Is there some fact related to linear subspaces that might be helpful?

\item {} 
\sphinxAtStartPar
If you’re still stuck, try ﬂipping the problem around. In the previous example, suppose that the range of the function is not a linear subspace. What would that imply? Can you show that such an outcome is impossible?

\item {} 
\sphinxAtStartPar
Be patient and don’t rush. You’ll get quicker naturally, with practice.

\end{enumerate}

\sphinxAtStartPar
\sphinxstyleemphasis{\sphinxstylestrong{Question A.1}}

\sphinxAtStartPar
Let \(f \colon [-1, 1] \to \mathbb{R}\) be defined by \(f(x) = 1 - |x|\), where \(|x|\) is the absolute value of \(x\).
\begin{itemize}
\item {} 
\sphinxAtStartPar
Is the point \(x = 0\) a maximizer of \(f\) on \([-1, 1]\)?

\item {} 
\sphinxAtStartPar
Is it a unique maximizer?

\item {} 
\sphinxAtStartPar
Is it an interior maximizer?

\item {} 
\sphinxAtStartPar
Is it stationary?

\end{itemize}

\sphinxAtStartPar
\sphinxstyleemphasis{\sphinxstylestrong{Question A.2}}

\sphinxAtStartPar
Let \(f \colon \mathbb{R} \to \mathbb{R}\) be defined by \(f(x) = \sin(x)\).
\begin{itemize}
\item {} 
\sphinxAtStartPar
Write down the set of stationary points of this function.

\item {} 
\sphinxAtStartPar
Which of these, if any, are maximizers, and which are minimizers?

\end{itemize}

\begin{sphinxadmonition}{tip}{Tip:}
\sphinxAtStartPar
When we discussed these kinds of problems it was for functions of the form \(f \colon [a, b] \to \mathbb{R}\).  Now the domain is all of \(\mathbb{R}\).
However you can apply the same definitions and use similar reasoning.  Also, feel free to look up and use any helpful facts on trigonometric functions.
\end{sphinxadmonition}


\section{Question A.3: Profit maximization with Cobb\sphinxhyphen{}Douglas production and linear costs}
\label{\detokenize{02.exercises.A:question-a-3-profit-maximization-with-cobb-douglas-production-and-linear-costs}}
\sphinxAtStartPar
A firm uses capital and labor to produce output.
When it employs \(k\) units of capital and \(\ell\) units of labor, its output is \(A k^{\alpha} \ell^{\beta}\) units, where \(A\) is a positive number, and \(\alpha + \beta < 1\).

\sphinxAtStartPar
The unit price of capital is \(r\), and the unit price of labor is \(w\); both are non\sphinxhyphen{}negative.
The firm would like to maximize the profits taking the price \(p\) of the output as given.

\sphinxAtStartPar
The firm’s chief economist \sphinxstyleemphasis{Bob} presented the following formulation of the firm’s optimization problem to the CEO \sphinxstyleemphasis{Alice}:
\begin{equation*}
\begin{split}
\text{Choose } k, \ell, w \text{ and } r \text{ to maximize } 
p k^{\alpha} \ell^{\beta} - w \ell - r k 
\quad \mathrm{s.t.} \quad
\alpha + \beta < 1
\end{split}
\end{equation*}
\sphinxAtStartPar
Questions:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
Is this formulation of the firm’s optimization problem correct?

\end{enumerate}
\begin{itemize}
\item {} 
\sphinxAtStartPar
What part reflects the revenue?

\item {} 
\sphinxAtStartPar
What part reflects the costs?

\item {} 
\sphinxAtStartPar
What are the choice variables?

\item {} 
\sphinxAtStartPar
Are there any constraints to be taken into account?

\end{itemize}
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\setcounter{enumi}{1}
\item {} 
\sphinxAtStartPar
Right down the problem after \sphinxstyleemphasis{Alice} have updated the formulation.

\item {} 
\sphinxAtStartPar
Approach the problem as unconstrained maximization, and follow the steps in the lecture to find find all stationary points (solve the FOCs).

\item {} 
\sphinxAtStartPar
Write down second order partial derivatives and verify the shape conditions for the profit function.

\item {} 
\sphinxAtStartPar
What is the optimal strategy for the firm? Is the maximizer unique? Why?

\end{enumerate}


\section{Question A.4*}
\label{\detokenize{02.exercises.A:question-a-4}}
\begin{sphinxadmonition}{note}{Note:}
\sphinxAtStartPar
Exercises marked with an asterisk \sphinxstylestrong{(*)} are optional and more difficult.
\end{sphinxadmonition}
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
Find all stationary points of the function
\(f(x, y) = \frac{\cos(x^2 + y^2)}{1 + x^2 + y^2}\).

\item {} 
\sphinxAtStartPar
Find all maximizers and minimizers of this function on \(\mathbb{R}^2\).

\end{enumerate}

\begin{sphinxadmonition}{hint}{Hint:}
\sphinxAtStartPar
Is there a convenient change of variable to convert the problem to a univariate one.
\end{sphinxadmonition}
\subsubsection*{Solutions}

\sphinxAtStartPar
\sphinxstyleemphasis{\sphinxstylestrong{Question A.1}}

\sphinxAtStartPar
The point \(x=0\) is indeed a maximizer, since \(f(x) = 1 -|x| \leq 1 = f(0)\) for any \(x \in [-1, 1]\) (\(|x|=0\) if and only if \(x=0\)).
It is also a unique maximizer, since no other point is a maximizer (because \(1 -|x| < 1\) for any other \(x\)).
It is an interior maximizer since \(0\) is not an end point of \([-1, 1]\).
It is not stationary because \(f\) is not differentiable at this point (sketch the graph if you like) and hence cannot satisfy \(f'(x)=0\).

\sphinxAtStartPar
\sphinxstyleemphasis{\sphinxstylestrong{Question A.2}}

\sphinxAtStartPar
The set \(S\) of stationary points of \(f\) are the points \(x \in \mathbb{R}\) such
that \(f'(x) = \cos(x) = 0\). By the definition of the cosine function this
is the set
\begin{equation*}
\begin{split}
S := \{ x \in \mathbb{R} : x = \pi/2 + k \pi \text{ for } k \in \mathbb{Z} \}
\end{split}
\end{equation*}
\sphinxAtStartPar
Every point in the domain \(\mathbb{R}\) is interior (i.e, not an end point) and
the function \(f\) is differentiable, so the set of maximizers will be
contained in the set of stationary points. The same is true of the set of
minimizers. From the definition of the sine function, we have
\begin{equation*}
\begin{split}
f(\pi/2 + k \pi) =
\begin{cases}
    1 & \text{ if $k$ is even} \\
    -1 & \text{ if $k$ is odd} \\
\end{cases}
\end{split}
\end{equation*}
\sphinxAtStartPar
Hence the set of maximizers is
\begin{equation*}
\begin{split}
M^* := \{ x \in \mathbb{R} : x = \pi/2 + k \pi \text{ for  } k \text{ an
even integer}\}
\end{split}
\end{equation*}
\sphinxAtStartPar
The set of minimizers is
\begin{equation*}
\begin{split}
M_* := \{ x \in \mathbb{R} : x = \pi/2 + k \pi \text{ for  } k \text{ an
odd integer}\}
\end{split}
\end{equation*}
\sphinxAtStartPar
\sphinxstyleemphasis{\sphinxstylestrong{Question A.3}}
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
The formulation is not correct. The revenue (after reincerting constant \(A\)) is \(p A k^{\alpha} \ell^{\beta}\), the costs are \(w \ell + r k\), and the choice variables are \(k\) and \(\ell\) (\(w\) and \(r\) are not chosen by the firm).\\
The constraint \(\alpha + \beta < 1\) is irrelevant for the optimization problem, instead it is a constraint on the parameters for the problem to be well posed.
Relevant constraints on the optimization problem are \(k>0\) and \(\ell>0\), they can be first ignored and checked after we solve the unconstrained version of the problem.

\item {} 
\sphinxAtStartPar
The correct formulation is (\(A, p, \alpha, \beta, w, r\) are parameters and should be fixed/found out before the firm solves the optimization problem)

\end{enumerate}
\begin{equation*}
\begin{split}
p A k^{\alpha} \ell^{\beta} - w \ell - r k
\rightarrow \max_{k, \ell}\\
\quad \mathrm{s.t.} \quad
k \ge 0, \ell \ge 0
\end{split}
\end{equation*}\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\setcounter{enumi}{2}
\item {} 
\sphinxAtStartPar
See lecture notes

\item {} 
\sphinxAtStartPar
See lecture notes

\item {} 
\sphinxAtStartPar
Optimal strategy \(k^*, \ell^*\) are given in the lecture notes. The maximizer is unique because the objective function is strictly concave when \(\alpha+\beta < 1\).

\end{enumerate}

\sphinxAtStartPar
\sphinxstyleemphasis{\sphinxstylestrong{Proof:}}

\sphinxAtStartPar
We check second order conditions for strict concavity.

\sphinxAtStartPar
What we need: for any \(k, \ell > 0\)
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
\(\pi_{11}(k, \ell) < 0\)

\item {} 
\sphinxAtStartPar
\(\pi_{11}(k, \ell) \, \pi_{22}(k, \ell) >  \pi_{12}(k, \ell)^2\)

\end{enumerate}

\sphinxAtStartPar
The second order derivatives are
\begin{equation*}
\begin{split}
\pi_{11}(k,\ell) = (\alpha-1)\alpha pA k^{\alpha-2} \ell^\beta \\
\pi_{22}(k,\ell) = (\beta-1)\beta pA k^{\alpha} \ell^{\beta-2}\\
\pi_{12}(k, \ell) = \alpha \beta pA k^{\alpha-1} \ell^{\beta-1}.
\end{split}
\end{equation*}
\sphinxAtStartPar
Since \(\alpha+\beta<1\) and \(\alpha, \beta \geq 0\), we have \(\alpha-1<0\), which implies \(\pi_{11}(k,\ell)<0\) for all \(k, \ell >0\).\\
Moreover, the second order differentials imply
\begin{equation*}
\begin{split}
\pi_{11}(k, \ell) \, \pi_{22}(k, \ell) = (\alpha-1)(\beta-1)\alpha \beta p^2 A^2 k^{2\alpha-2} \ell^{2\beta-2}\\
(\pi_{22}(k, \ell))^2 = \alpha^2 \beta^2 p^2 A^2 k^{2\alpha-2} \ell^{2\beta-2}.
\end{split}
\end{equation*}
\sphinxAtStartPar
Assuming that all parameters and variables are positive.
Then, we obtain \(\pi_{11}(k, \ell) \, \pi_{22}(k, \ell) >  \pi_{12}(k, \ell)^2\) if and only if \((\alpha-1)(\beta-1) > \alpha \beta\) if and only if \(1 > \alpha + \beta\).

\sphinxAtStartPar
\sphinxstyleemphasis{\sphinxstylestrong{Question A.4}}

\sphinxAtStartPar
The graph of \(f(x,y)\) is

\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics[width=0.800\linewidth]{{9f17d8225a84f50e4af3428865a35a303a960a7dfc688ae24291d0485ed2538d}.png}
\end{figure}

\sphinxAtStartPar
Let \(t = x^2+y^2 \geq 0\).
The function becomes
\begin{equation*}
\begin{split}
f(x,y) = \frac{\cos(x^2+y^2)}{1 + x^2+y^2} = \frac{\cos(t)}{1 + t} =: g(t)  \quad (t \geq 0).
\end{split}
\end{equation*}
\sphinxAtStartPar
First note that since \(t \geq 0\) and \(\cos(t) \leq 1\), we have \(g(t)\leq 1\) and \(g(0)=1\).
Hence, \(t=0\) is a maximizer for \(g\), or \((x,y)=(0,0)\) is the maximizer for \(f\).
It is a unique maximizer, since if \(g(t) < 1\) for \(t >0\).

\sphinxAtStartPar
Next, we find the stationary points of \(f\) by finding the stationary points of \(g\).
The FOC is
\begin{equation*}
\begin{split}
g'(t) = \frac{-\sin(t)(1+t) - \cos(t)}{(1+t)^2} = 0.
\end{split}
\end{equation*}
\sphinxAtStartPar
Since \((1+t)^2>0\), it must be
\begin{equation*}
\begin{split}
-\sin(t)(1+t) - \cos(t) = 0 ⇔ t\sin(t) + \sin(t) + \cos(t)=0.
\end{split}
\end{equation*}
\sphinxAtStartPar
The numerical solutions for the smallest stationary point \(t_m\) such that \(\cos(t_m)<0\) are

\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics[width=0.800\linewidth]{{b8f4ba23545cba1a4ae33535ce31abda505ac10be9092284e5b78c1b9df38010}.png}
\end{figure}

\sphinxAtStartPar
\DUrole{output,text_plain}{‘The smallest stationary point is tm=2.889969697678371’}

\sphinxAtStartPar
\DUrole{output,text_plain}{‘The minimum is \sphinxhyphen{}0.24897613487740497’}

\sphinxAtStartPar
The minimizers are \(\{(x,y)\in\mathbb{R}: x^2+y^2 = t_m\}\).
To verify that \(t_m\) is the unique minimizer for \(g\), since \(\cos^2(t) + \sin^2(t)=1\), we rewrite FOC to get
\begin{equation*}
\begin{split}
t\sin(t) + \sin(t) = \pm \sqrt{1-\sin^2(t)} \\
⇔ \sin^2(t) = \frac{1}{2 + 2t + t^2} \\
⇔ \cos^2(t) = 1 - \frac{1}{2+2t + t^2}=\frac{(1+t)^2}{2+2t + t^2}\\
⇒ g(t) = \frac{\cos(t)}{1+t} = \pm \frac{1}{\sqrt{2+2t +t^2}}  \qquad (\text{$t$ is stationary point}).
\end{split}
\end{equation*}
\sphinxAtStartPar
Therefore, the smallest stationary point such that \(\cos(t) < 0\) will be the unique minimizer for \(g\).

\sphinxstepscope


\chapter{Exercise set B}
\label{\detokenize{03.exercises.B:exercise-set-b}}\label{\detokenize{03.exercises.B::doc}}
\sphinxAtStartPar
Please, see the
{\hyperref[\detokenize{02.exercises.A::doc}]{\sphinxcrossref{\DUrole{doc,std,std-doc}{\sphinxstylestrong{general comment on the tutorial exercises}}}}}


\section{Question B.1}
\label{\detokenize{03.exercises.B:question-b-1}}
\sphinxAtStartPar
Each of the definitions below is an attempt to define a set. Determine whether a set is indeed defined in each case, and if not explain why.
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
\(\{1,e,-2,-\pi\}\)

\item {} 
\sphinxAtStartPar
\(\{15,\{1,2,3\},\text{ANU},\text{Europe},\text{USA}\}\)

\item {} 
\sphinxAtStartPar
\(\{1,2,\dots,99 \}\)

\item {} 
\sphinxAtStartPar
\(\{1,4,7,91, \dots \}\)

\item {} 
\sphinxAtStartPar
\(\{x \in \mathbb{R} \colon x^2 \le 5\}\)

\item {} 
\sphinxAtStartPar
\(\{(x,y) \in \mathbb{R}^2 \colon 5x^2 + y^2 \le 10\}\)

\item {} 
\sphinxAtStartPar
\(\{f \colon [0,1] \rightarrow \mathbb{R} \colon f \text{ is one-to-one} \}\)

\item {} 
\sphinxAtStartPar
\(\{ f_n(x) \colon [0,1] \rightarrow \mathbb{R} \colon f_n(x) = x^n \}\)

\item {} 
\sphinxAtStartPar
\(\{A \subset S : x_0 \in A \}\) for given \(S\) and \(x_0 \in S\)

\end{enumerate}


\section{Question B.2}
\label{\detokenize{03.exercises.B:question-b-2}}
\sphinxAtStartPar
Let \(A\),\(B\) and \(C\) be any three sets.
Show that \(A \cap (B \cup C) = (A\cap B) \cup (A \cap C)\).

\begin{sphinxadmonition}{hint}{Hint:}
\sphinxAtStartPar
Hint, if you need it: One way to show that \(E=F\) is show that a arbitrary element of \(E\) must also be in \(F\) and vice versa.
\end{sphinxadmonition}


\section{Question B.3}
\label{\detokenize{03.exercises.B:question-b-3}}
\sphinxAtStartPar
Let \(A\), \(B\), \(C\) and \(D\) be some set such that \(A \subset C\) and \(B \subset C\).
Let \(f\colon D \rightarrow C\) be a function.

\sphinxAtStartPar
Show that \(f^{-1}(A \setminus B) = f^{-1}(A) \setminus f^{-1}(B)\).


\section{Question B.4}
\label{\detokenize{03.exercises.B:question-b-4}}
\sphinxAtStartPar
Find the composition \(g \circ f\) of two functions \(f\) and \(g\), if it exists:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
\(f \colon \mathbb{R} \rightarrow \mathbb{R}\) defined by \(f(x)=\sin(x)\) and \(g \colon \mathbb{R} \rightarrow \mathbb{R}\) defined by \(g(x)= \frac{x}{1+x^2}\)

\item {} 
\sphinxAtStartPar
\(f \colon \mathbb{R} \rightarrow \mathbb{R}\) defined by \(f(x)= 1-x^4\) and \(g \colon (1,\infty) \rightarrow \mathbb{R}\) defined by \(g(x)= \log(x-1)\)

\item {} 
\sphinxAtStartPar
\(f \colon \mathbb{R} \rightarrow \mathbb{R}\) defined by \(f(x)=\cos(x)\) and \(g \colon \mathbb{R}\setminus\{1\} \rightarrow \mathbb{R}\) defined by \(g(x)= \frac{x}{1-x}\)

\end{enumerate}

\begin{sphinxadmonition}{hint}{Hint:}
\sphinxAtStartPar
Is there a composition in each case?
\end{sphinxadmonition}


\section{Question B.5}
\label{\detokenize{03.exercises.B:question-b-5}}
\sphinxAtStartPar
Let \(f\) and \(g\) be any two functions from \(\mathbb{R}\) to \(\mathbb{R}\).  Is it true that
\(g \circ f = f \circ g\) always holds?

\begin{sphinxadmonition}{hint}{Hint:}
\sphinxAtStartPar
There are two
things implicit in this question.  First, there is an implicit final
sentence here, which is: If yes, prove it.  If no, give a
counterexample.  Second, an equality sign between two functions means
that they are the same function.  Hence to show equality you need to
show that they agree everywhere on the domain.  To show inequality,
you need to give just one point in the domain where the function
values differ.
\end{sphinxadmonition}


\section{Question B.6}
\label{\detokenize{03.exercises.B:question-b-6}}
\begin{sphinxadmonition}{note}{Fact: the sufficient conditions for concavity/convexity in 2D}

\sphinxAtStartPar
Let \(z = f(x,y)\) be a twice continuously differentiable function defined for all
\((x, y) \in R^2\).

\sphinxAtStartPar
Then it holds:
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(f \text{ is convex } \iff f''_{1,1} \ge 0, \; f''_{2,2} \ge 0 , \text{ and } f''_{1,1} f''_{2,2} − (f''_{1,2})^2 \ge 0\)

\item {} 
\sphinxAtStartPar
\(f \text{ is concave } \iff f''_{1,1} \le 0, \; f''_{2,2} \le 0 , \text{ and } f''_{1,1} f''_{2,2} − (f''_{1,2})^2 \ge 0\)

\item {} 
\sphinxAtStartPar
\(f''_{1,1} > 0 \text{ and } f''_{1,1} f''_{2,2} \implies f \text{ is strictly convex}\)

\item {} 
\sphinxAtStartPar
\(f''_{1,1} < 0 \text{ and } f''_{1,1} f''_{2,2} \implies f \text{ is strictly concave}\)

\end{itemize}
\end{sphinxadmonition}
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
Find the largest domain \(S\) on which
\(f(x, y) = x^2 − y^2 − xy − x^3\) is concave.

\item {} 
\sphinxAtStartPar
How about strictly concave?

\end{enumerate}
\subsubsection*{Solutions}

\sphinxAtStartPar
\sphinxstyleemphasis{\sphinxstylestrong{Question B.1}}

\sphinxAtStartPar
A set is \sphinxstyleemphasis{a collection of objects viewed as a whole}, see a precise {\hyperref[\detokenize{03.set_theory:ref-set-defition}]{\sphinxcrossref{\DUrole{std,std-ref}{definition}}}}.

\sphinxAtStartPar
Therefore:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
Yes

\item {} 
\sphinxAtStartPar
Yes

\item {} 
\sphinxAtStartPar
Yes

\item {} 
\sphinxAtStartPar
No, no apparent pattern for a definition

\item {} 
\sphinxAtStartPar
Yes

\item {} 
\sphinxAtStartPar
Yes

\item {} 
\sphinxAtStartPar
Yes, all functions from \([0,1]\) to \(\mathbb{R}\) form a set

\item {} 
\sphinxAtStartPar
No, as the set of \(n\) is not specified

\item {} 
\sphinxAtStartPar
Yes

\end{enumerate}

\sphinxAtStartPar
\sphinxstyleemphasis{\sphinxstylestrong{Question B.2}}

\sphinxAtStartPar
Let \(A, B\) and \(C\) be any three sets, as in the question.
Let
\begin{equation*}
\begin{split}
E := A \cap (B \cup C)
\quad \text{and} \quad
F := (A \cap B) \cup (A \cap C)
\end{split}
\end{equation*}
\sphinxAtStartPar
We need to show that \(E = F\), or, equivalently, that \(E \subset F\) and \(F
\subset E\).

\sphinxAtStartPar
To see that \(E \subset F\), pick any \(x \in E\). We claim that \(x \in F\) also
holds. To see this, observe that since \(x \in E\), it must be true that \(x\) is
in \(A\) as well as being in at least one of \(B\) and \(C\). In the first case \(x\)
is in both \(A\) and \(B\). In the second case \(x\) is in both \(A\) and \(C\). In
either case we have \(x \in F\) by the definition of \(F\).

\sphinxAtStartPar
To see that \(F \subset E\), pick any \(x \in F\). We claim that \(x
\in E\) also holds. Indeed, since \(x \in F\) we know that either \(x\) is in both
\(A\) and \(B\) or \(x\) is in both \(A\) and \(C\). In other words, \(x\) is in \(A\) and
also at least one of \(B\) and \(C\). Hence \(x \in E\).

\sphinxAtStartPar
\sphinxstyleemphasis{\sphinxstylestrong{Question B.3}}

\sphinxAtStartPar
Note the definitions that \(f^{-1}(A) := \{x\in D\colon f(x) \in A \}\) and \((f^{-1}(B))^c = \{x\in D\colon f(x) ∉  B\}\).

\sphinxAtStartPar
To show the equality we can prove the the left hand side (LHS) implies the right hand side (RHS), i.e. LHS \(\Rightarrow\) RHS, and then show that RHS \(\Rightarrow\) LHS. These two steps are usually referred to as
\sphinxstyleemphasis{necessity} and \sphinxstyleemphasis{sufficiency} (of the RHS for LHS).

\sphinxAtStartPar
\sphinxstylestrong{Necessity}: assume \(x \in f^{-1}(A \setminus B)\), then \(f(x) \in A\) and \(f(x) \notin B\), and so \(x \in f^{-1}(A)\) and \(x \notin f^{-1}(B)\).

\sphinxAtStartPar
\sphinxstylestrong{Sufficiency}: if \(x \in f^{-1}(A) \setminus f^{-1}(B)\), then \(f(x) \in A\) and \(f(x) \notin B\), and so \(x \in f^{-1}(A \setminus B)\).

\sphinxAtStartPar
\sphinxstyleemphasis{\sphinxstylestrong{Question B.4}}

\sphinxAtStartPar
The issue we have to deal with is the compatibility of the domains and ranges of the functions.
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
All good
\begin{equation*}
\begin{split}
   g \circ f \colon \mathbb{R} \rightarrow \mathbb{R}, \;\; (g \circ f)(x) = \frac{\sin(x)}{1+\sin^2(x)}
   \end{split}
\end{equation*}
\item {} 
\sphinxAtStartPar
The range of \(f(x)\) and the domain of \(g(x)\) are disjoint, so the composition is not defined.

\item {} 
\sphinxAtStartPar
The points where \(f(x)=1\) have to be excluded in the composition
\begin{equation*}
\begin{split}
   g \circ f \colon \mathbb{R}\setminus\{x: \cos(x)=1\} \rightarrow \mathbb{R}, \;\; (g \circ f)(x) = \frac{\cos(x)}{1-\cos(x)}
   \end{split}
\end{equation*}
\end{enumerate}

\sphinxAtStartPar
\sphinxstyleemphasis{\sphinxstylestrong{Question B.5}}

\sphinxAtStartPar
This is not always true. For example, if \(f(x) = x^2\) and
\(g(x) = 4x\), then \(g \circ f\) and \(f \circ g\) differ. Indeed, if we set
\(x=1\), then
\begin{equation*}
\begin{split}
(g \circ f)(1) = g(f(1)) = 4(1^2) = 4,
\end{split}
\end{equation*}
\sphinxAtStartPar
while
\begin{equation*}
\begin{split}
(f \circ g)(1) = f(g(1)) = (4 \times 1)^2 = 16.
\end{split}
\end{equation*}
\sphinxAtStartPar
Hence \(g \circ f \not= f \circ g\) as claimed.

\begin{sphinxadmonition}{note}{Note:}
\sphinxAtStartPar
Can you think of restrictions on \(f\) and \(g\) that would make the claim true?
\end{sphinxadmonition}

\sphinxAtStartPar
\sphinxstyleemphasis{\sphinxstylestrong{Question B.6}}
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
\(f^{\prime}_{1}(x, y) = 2x - y -3x^2\)

\sphinxAtStartPar
\(f^{\prime}_{2}(x, y) = -2y - x\)

\sphinxAtStartPar
\(f^{\prime\prime}_{1, 1}(x, y) = 2 - 6x\)

\sphinxAtStartPar
\(f^{\prime\prime}_{2, 2}(x, y) = -2\)

\sphinxAtStartPar
\(f^{\prime\prime}_{1, 2}(x, y) = -1\)
\begin{equation*}
\begin{split}
   f(x, y) \text{ is concave } \iff
   \begin{cases}
    f^{\prime\prime}_{1, 1}(x, y) = 2 - 6x \leq 0 \\
    f^{\prime\prime}_{2, 2}(x, y) = -2 \leq 0 \\
    f^{\prime\prime}_{1, 1}(x, y) f^{\prime\prime}_{2, 2}(x, y) - f^{\prime\prime}_{1, 2}(x, y)^2 = (2 - 6x)(-2) - (-1)^2 = 12x - 5 \geq 0 \\
   \end{cases} \\
   \iff x \geq \frac{5}{12}\\
   \end{split}
\end{equation*}
\sphinxAtStartPar
Thus, \(S = \{(x, y) \in \mathbb{R^2}: x \geq \frac{5}{12}\}= [\frac{5}{12}, +\infty) \times \mathbb{R}\).

\item {} 
\sphinxAtStartPar
We just replace all the inequality in question 1 to strict inequality, and we get \(S = \{(x, y) \in \mathbb{R^2}: x > \frac{5}{12}\}= (\frac{5}{12}, +\infty) \times \mathbb{R}\).

\end{enumerate}

\sphinxstepscope


\chapter{Exercise set C}
\label{\detokenize{04.exercises.C:exercise-set-c}}\label{\detokenize{04.exercises.C::doc}}
\sphinxAtStartPar
Please, see the
{\hyperref[\detokenize{02.exercises.A::doc}]{\sphinxcrossref{\DUrole{doc,std,std-doc}{\sphinxstylestrong{general comment on the tutorial exercises}}}}}


\section{Question C.1}
\label{\detokenize{04.exercises.C:question-c-1}}
\sphinxAtStartPar
Consider two convergent sequences in \(\mathbb{R}^n\), \(\{{\bf x}_i\}_{i=1}^\infty\) and
\(\{{\bf y}_i\}_{i=1}^\infty\) such that
\begin{equation*}
\begin{split}
\lim_{i \to \infty} {\bf x}_i = {\bf x} \in \mathbb{R}^n, \quad
\lim_{i \to \infty} {\bf y}_i = {\bf y} \in \mathbb{R}^n
\end{split}
\end{equation*}
\sphinxAtStartPar
Prove the following properties of the limits:
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(\lim_{i \to \infty} ({\bf x}_i+{\bf y}_i) = {\bf x} + {\bf y}\)

\item {} 
\sphinxAtStartPar
\(\lim_{i \to \infty} ({\bf x}_i'{\bf y}_i) = {\bf x}'{\bf y}\)

\item {} 
\sphinxAtStartPar
\({\bf x}_i \le {\bf y}_i\) for \(\forall i\) component\sphinxhyphen{}wise \(\implies {\bf x} \le {\bf y}\)

\end{itemize}

\begin{sphinxadmonition}{note}{Definition}

\sphinxAtStartPar
The scalar product \({\bf x}'{\bf y}\) of two vector is \(\mathbb{R}\) is defined by \({\bf x}'{\bf y} = \sum_{j=1}^n x_j y_j\)

\sphinxAtStartPar
Component\sphinxhyphen{}wise comparison of the vectors is defined as \({\bf x} \le {\bf y} \iff x_j \le y_j\) for all \(j\in\{1,\dots,N\}\)
\end{sphinxadmonition}

\begin{sphinxadmonition}{tip}{Tip:}
\sphinxAtStartPar
Definition of the limit in \(\mathbb{R}^n\) is essentially unchanged from the definition of the limit in \(\mathbb{R}\)
\end{sphinxadmonition}


\section{Question C.2}
\label{\detokenize{04.exercises.C:question-c-2}}
\sphinxAtStartPar
Show that the Cobb\sphinxhyphen{}Douglas production function
\(f(k,l) = k^\alpha l^\beta\) from \([0,\infty) \times [0,\infty)\) to \(\mathbb{R}\) is continuous everywhere in its domain.

\begin{sphinxadmonition}{tip}{Tip:}
\sphinxAtStartPar
You can use the fact that, for any \(a \in \mathbb{R}\) the function \(g(x) = x^a\) is continuous at any \(x \in [0,\infty)\). This was mentioned towards the end of lecture 4.
Also, remember that norm convergence implies element by element convergence.
\end{sphinxadmonition}


\section{Question C.3}
\label{\detokenize{04.exercises.C:question-c-3}}
\sphinxAtStartPar
Let \(\beta \in (0,1)\). Show that the utility function \(u(c_1,c_2) = \sqrt{c_1} + \beta \sqrt{c_2}\) from \([0,\infty) \times [0,\infty)\) to \(\mathbb{R}\) to \(\mathbb{R}\) is continuous everywhere in its domain.


\section{Question C.4}
\label{\detokenize{04.exercises.C:question-c-4}}
\sphinxAtStartPar
Let \(A\) be the set of all consumption pairs \((c_1,c_2)\) such that \(c_1 \ge 0\), \(c_2 \ge 0\) and \(p_1 c_1 + p_2 c_2 \le M\) Here \(p_1\), \(p_2\) and \(M\) are positive constants. Show that \(A\) is a closed subset of \(\mathbb{R}^2\).

\begin{sphinxadmonition}{tip}{Tip:}
\sphinxAtStartPar
Weak inequalities are preserved under limits
\end{sphinxadmonition}


\section{Question C.5}
\label{\detokenize{04.exercises.C:question-c-5}}
\sphinxAtStartPar
Let \({\bf x}, {\bf y} \in \mathbb{R}^N\) and \(\| {\bf x} \| \) denote the Euclidean norm.  Verify the \sphinxstyleemphasis{\sphinxstylestrong{Parallelogram Equality}} given by
\begin{equation*}
\begin{split}
\| {\bf x} + {\bf y} \|^2 + \| {\bf x} - {\bf y} \|^2 = 2 \big( \| {\bf x} \|^2 + \| {\bf y} \|^2 \big)
\end{split}
\end{equation*}\subsubsection*{Solutions}

\sphinxAtStartPar
\sphinxstyleemphasis{\sphinxstylestrong{Question C.1}}

\sphinxAtStartPar
Let \(\{\mathbf{x}_i\}_{i=1}^\infty\) and \(\{\mathbf{y}_i\}_{i=1}^\infty\) be two converget sequences in \(\mathbb{R}^n\) such that \(\mathbf{x}_i \to \mathbf{x} \in \mathbb{R}^n\) and \(\mathbf{y}_i \to y \in \mathbb{R}^n\) as \(i \to \infty\).
Recall that \(\mathbf{x}_i \to \mathbf{x}\) if and only if \(\|\mathbf{x}_i - \mathbf{x}\| \to 0\).

\sphinxAtStartPar
\sphinxstylestrong{Proof} of \(\lim_{i \to \infty} (\mathbf{x}_i + \mathbf{y}_i) = \mathbf{x} + \mathbf{y}\)

\sphinxAtStartPar
Fix \(\varepsilon > 0\).
Since \(\mathbf{x}_i \to \mathbf{x}\) and \(\mathbf{y}_i \to \mathbf{y}\), there exists an \(N \in \mathbb{N}\) such that
\begin{equation*}
\begin{split}
\|\mathbf{x}_i - \mathbf{x}\| < \frac{\varepsilon}{2} \qquad \text{and} \qquad  \|\mathbf{y}_i - \mathbf{y}\| < \frac{\varepsilon}{2}
\end{split}
\end{equation*}
\sphinxAtStartPar
for all \(i \geq N\).
Hence, the triangle inequality yields
\begin{equation*}
\begin{split}
\|(\mathbf{x}_i + \mathbf{y}_i) - (\mathbf{x} + \mathbf{y})\| = \|\mathbf{x}_i - \mathbf{x} + \mathbf{y}_i - \mathbf{y}\| \leq \|\mathbf{x}_i - \mathbf{x}\| + \|\mathbf{y}_i - \mathbf{y}\|< \varepsilon
\end{split}
\end{equation*}
\sphinxAtStartPar
for all \(i \geq N\). Therefore, since \(\varepsilon\) is arbitrary, we have \(\mathbf{x}_i + \mathbf{y}_i \to \mathbf{x} + \mathbf{y}\) as \(i \to \infty\).

\sphinxAtStartPar
\sphinxstylestrong{Proof} of \(\lim_{i \to \infty} (\mathbf{x}_i' \mathbf{y}_i) = \mathbf{x}' \mathbf{y}\)

\sphinxAtStartPar
Since \(\{\mathbf{x}_i\}_{i=1}^\infty\) and \(\{\mathbf{y}_i\}_{i=1}^\infty\) are convergent sequences, they are bounded (why?) by constants \(M_x > 0\) and \(M_y >0\), respectively.
That is, we have \(\|\mathbf{x}_i\|\leq M_x\) and \(\|\mathbf{y}_i\|\leq M_y\) for all \(i\in\mathbb{N}\).

\sphinxAtStartPar
Let \(M:= \max\{M_x, M_y, \|\mathbf{x}\|, \|\mathbf{y}\|\}\).
Fix \(\varepsilon > 0\).
Again, since these sequences are convergent, there is an \(N \in \mathbb{N}\) such that
\begin{equation*}
\begin{split}
\|\mathbf{x}_i - \mathbf{x}\| < \frac{\varepsilon}{2M}, \qquad \text{and} \qquad \|\mathbf{y}_i - \mathbf{y}\| < \frac{\varepsilon}{2M}
\end{split}
\end{equation*}
\sphinxAtStartPar
for all \(i \geq N\).
The tirangle inequality and Cauchy\sphinxhyphen{}Schwarz inequality imply
\begin{equation*}
\begin{split}
|\mathbf{x}_i' \mathbf{y}_i - \mathbf{x}'\mathbf{y}| 
= |\mathbf{x}_i' \mathbf{y}_i - \mathbf{x}' \mathbf{y}_i + \mathbf{x}' \mathbf{y}_i - \mathbf{x}'\mathbf{y}| \\
\leq |\mathbf{x}_i' \mathbf{y}_i - \mathbf{x}' \mathbf{y}_i| + |\mathbf{x}' \mathbf{y}_i - \mathbf{x}'\mathbf{y}| \\
= |(\mathbf{x}_i - \mathbf{x})' \mathbf{y}_i| + |\mathbf{x}'(\mathbf{y}_i-\mathbf{y})| \\
\leq \|\mathbf{y}_i\| \|\mathbf{x}_i-\mathbf{x}\| + \|\mathbf{x}\|\|\mathbf{y}_i - \mathbf{y}\| \\
\leq M \|\mathbf{x}_i - \mathbf{x}\| + M \|\mathbf{y}_i - \mathbf{y}\| \\
< M \frac{\varepsilon}{2M}+ M \frac{\varepsilon}{2M}< \varepsilon
\end{split}
\end{equation*}
\sphinxAtStartPar
for all \(i \geq N\).
Therefore, since \(\varepsilon\) is arbitrary, we have \(\mathbf{x}_i'\mathbf{y}_i \to \mathbf{x}'\mathbf{y}\) as \(i \to \infty\).

\sphinxAtStartPar
\sphinxstylestrong{Proof} of “\(\mathbf{x}_i \leq \mathbf{y}_i\) for all \(i\) component\sphinxhyphen{}wise \(\Longrightarrow \mathbf{x} \leq \mathbf{y}\)”

\sphinxAtStartPar
Assume that \(\mathbf{x}_i \leq \mathbf{y}_i\) for all \(i\).
Toward contradiction, suppose that \(\mathbf{x} \nleq \mathbf{y}\).
Then, there is \(k\in\{1, 2, \dots, n\}\) such that \(\mathbf{x}(k) > \mathbf{y}(k)\), where \(\mathbf{x}(k)\) denotes the \(k\)\sphinxhyphen{}th component of \(\mathbf{x} \in \mathbb{R}^n\).
Let \(\varepsilon = \mathbf{x}(k) - \mathbf{y}(k) > 0\).
Since the convergences of \(\{\mathbf{x}_i\}_{i=1}^\infty\) and \(\{\mathbf{y}_i\}_{i=1}^\infty\) imply the convergences of \(\{\mathbf{x}_i(k)\}_{i=1}^\infty\) and \(\{\mathbf{y}_i(k)\}_{i=1}^\infty\) (why?),
there is an \(N\in\mathbb{N}\) such that
\begin{equation*}
\begin{split}
|\mathbf{x}_i(k) - \mathbf{x}(k)| < \frac{\varepsilon}{4} \qquad \text{and} \qquad |\mathbf{y}_i(k) - \mathbf{y}(k)| < \frac{\varepsilon}{4} \\
\Rightarrow \mathbf{x}_i(k) > \mathbf{x}(k) - \frac{\varepsilon}{4}  \qquad \text{and} \qquad \mathbf{y}_i(k) < \mathbf{y}(k) + \frac{\varepsilon}{4}
\end{split}
\end{equation*}
\sphinxAtStartPar
for all \(i \geq N\).
This implies that \(\mathbf{x}_i(k) > \mathbf{y}_i(k)\) for all \(i \geq N\).
To see this, observe that
\begin{equation*}
\begin{split}
\mathbf{x}_i(k) - \mathbf{y}_i(k) > \mathbf{x}(k) - \frac{\varepsilon}{4} -  \Big(\mathbf{y}(k) +\frac{\varepsilon}{4}\Big)> \mathbf{x}(k) - \mathbf{y}(k) -\frac{\varepsilon}{2} = \varepsilon - \frac{\varepsilon}{2} = \frac{\varepsilon}{2}> 0
\end{split}
\end{equation*}
\sphinxAtStartPar
for all \(i \geq N\).
Since \(\mathbf{x}_i(k)\leq \mathbf{y}_i(k)\) for all \(i\) by assumption, we obtain a contraction, which implies that it must be \(\mathbf{x} \leq \mathbf{y}\).

\sphinxAtStartPar
\sphinxstyleemphasis{\sphinxstylestrong{Question C.2}}

\sphinxAtStartPar
Let \((k, \ell)\) be any point in \(A\), and let \(\{(k_n, \ell_n)\}\) be any
sequence converging to \((k, \ell)\) in the sense of convergence in \(\mathbb{R}^2\). We wish to show that
\begin{equation*}
\begin{split}
f(k_n, \ell_n) \to f(k, \ell)
\end{split}
\end{equation*}
\sphinxAtStartPar
Since \((k_n, \ell_n) \to (k, \ell)\) in \(\mathbb{R}^2\), we know from the facts on
convergence in norm that the individual components converge in \(\mathbb{R}\).
That is,
\begin{equation*}
\begin{split}
k_n \to k
\quad \text{and} \quad
\ell_n \to \ell
\end{split}
\end{equation*}
\sphinxAtStartPar
We also know from the facts that, for any \(a\), the function \(g(x) = x^a\)
is continuous at \(x\). It follows from the definition of continuity and
the convergence in \(\mathbb{R}\) above that \(k_n^\alpha \to k^{\alpha}\) and \(\ell^{\beta}_n \to
\ell^\beta\).

\sphinxAtStartPar
Moreover, we know that, for any sequences \(\{y_n\}\) and
\(\{z_n\}\), if \(y_n \to y\) and \(z_n \to z\), then \(y_n z_n \to yz\). Hence
\begin{equation*}
\begin{split}
    k_n^\alpha \ell^{\beta}_n \to k^{\alpha}\ell^\beta
\end{split}
\end{equation*}
\sphinxAtStartPar
That is, \(f(k_n, \ell_n) \to f(k, \ell)\). Hence \(f\) satisfies the
definition of continity.

\sphinxAtStartPar
\sphinxstyleemphasis{\sphinxstylestrong{Question C.3}}

\sphinxAtStartPar
The proof is analogous to the proof of continuity of the Cobb\sphinxhyphen{}Douglas
production function given above.

\sphinxAtStartPar
\sphinxstyleemphasis{\sphinxstylestrong{Question C.4}}

\sphinxAtStartPar
To show that \(A\) is closed, we need to show that the limit of any sequence
contained in \(A\) is also in \(A\). To this end,
let \(\{{\bf x}_n\}\) be an arbitrary sequence in \(A\) coverging to a point
\({\bf x} \in \mathbb{R}^2\).
Since \({\bf x}_n \in A\) for all \(n\) we have
\({\bf x}_n \geq {\bf 0}\) in the sense of the component\sphinxhyphen{}vise vector inequality
and \({\bf x}_n' {\bf p} \leq m\), where \({\bf p} = (p_1, p_2)\).
We need to show that the same is true for \({\bf x}\).

\sphinxAtStartPar
Since \({\bf x}_n \to {\bf x}\), we have
\({\bf x}_n' {\bf p} \to {\bf x}' {\bf p}\). Since limits preserve weak
inequalities and \({\bf x}_n' {\bf p} \leq m\) for all \(n\), we have
\({\bf x}' {\bf p} \leq m\). Hence it remains only to show that \({\bf x} \geq
0\). Again using the fact that weak inequalities are preserved under
limits, combined with \({\bf x}_n \geq {\bf 0}\) for all \(n\), gives
\({\bf x} \geq {\bf 0}\) as required.

\sphinxAtStartPar
\sphinxstyleemphasis{\sphinxstylestrong{Question C.5}}

\sphinxAtStartPar
From the definition of Euclidean norm, we have \(\|{\bf x}\|^2 = \sum_{i=1}^{N}x_i^2\) where \(x_i\) are components of \({\bf x}\). Therefore:
\begin{equation*}
\begin{split}
\| {\bf x} + {\bf y} \|^2 + \| {\bf x} - {\bf y} \|^2 = \sum_{i=1}^{N}(x_i+y_i)^2 + \sum_{i=1}^{N}(x_i-y_i)^2 = \\
= \sum_{i=1}^{N} \Big( 2 x_i^2 + 2 x_i y_i - 2 x_i y_i + 2 y_i^2 \Big) = 2 \sum_{i=1}^{N}x_i^2 + 2 \sum_{i=1}^{N}y_i^2 = 2 \big( \| {\bf x} \|^2 + \| {\bf y} \|^2 \big)
\end{split}
\end{equation*}
\sphinxstepscope


\chapter{Exercise set D}
\label{\detokenize{05.exercises.D:exercise-set-d}}\label{\detokenize{05.exercises.D::doc}}
\sphinxAtStartPar
Please, see the
{\hyperref[\detokenize{02.exercises.A::doc}]{\sphinxcrossref{\DUrole{doc,std,std-doc}{\sphinxstylestrong{general comment on the tutorial exercises}}}}}


\section{Question D.1}
\label{\detokenize{05.exercises.D:question-d-1}}
\sphinxAtStartPar
Consider the matrix \({\bf A}\) defined by
\begin{equation*}
\begin{split}
%
{\bf A} = 
\begin{pmatrix}
1 & 0 \\
0.5 & -12 \\
-2 & 7 
\end{pmatrix}
%
\end{split}
\end{equation*}
\sphinxAtStartPar
Do the columns of this matrix form a basis of \(\mathbb{R}^3\)? Why or why not?


\section{Question D.2}
\label{\detokenize{05.exercises.D:question-d-2}}
\sphinxAtStartPar
Is \(\mathbb{R}^2\) a linear subspace of \(\mathbb{R}^3\)? Why or why not?


\section{Question D.3}
\label{\detokenize{05.exercises.D:question-d-3}}
\sphinxAtStartPar
Show that if \(T \colon \mathbb{R}^K \to \mathbb{R}^N\) is a linear function then \({\bf 0} \in \mathrm{ker}(T)\).


\section{Question D.4}
\label{\detokenize{05.exercises.D:question-d-4}}
\sphinxAtStartPar
Let \(S\) be any nonempty subset of \(\mathbb{R}^N\) with the following two
properties:
\begin{itemize}
\item {} 
\sphinxAtStartPar
\({\bf x}, {\bf y} \in S \implies {\bf x} + {\bf y} \in S\)

\item {} 
\sphinxAtStartPar
\(c \in \mathbb{R}\) and \({\bf x} \in S \implies c{\bf x} \in S\)

\end{itemize}

\sphinxAtStartPar
Is \(S\) a linear subspace of \(\mathbb{R}^N\)?


\section{Question D.5}
\label{\detokenize{05.exercises.D:question-d-5}}
\sphinxAtStartPar
If \(S\) is a linear subspace of \(\mathbb{R}^N\) then any linear combination of \(K\)
elements of \(S\) is also in \(S\). Show this for the case \(K = 3\).


\section{Question D.6}
\label{\detokenize{05.exercises.D:question-d-6}}
\sphinxAtStartPar
Let \(\{{\bf x}_1, {\bf x}_2\}\) be a linearly independent set in \(\mathbb{R}^2\) and let
\(\gamma\) be a nonzero scalar. Is it true that \(\{\gamma {\bf x}_1, \gamma
{\bf x}_2\}\) is also linearly independent?


\section{Question D.7}
\label{\detokenize{05.exercises.D:question-d-7}}
\sphinxAtStartPar
Is
\begin{equation*}
\begin{split}
z=
\begin{pmatrix}
-3.98 \\
11.73 \\
-4.32
\end{pmatrix}
\end{split}
\end{equation*}
\sphinxAtStartPar
in the span of \(X:=\{{\bf x}_1, {\bf x}_2, {\bf x}_3\}\), where
\begin{equation*}
\begin{split}
{\bf x}_1=
\begin{pmatrix}
-4 \\
0 \\
0
\end{pmatrix},
\;\;
{\bf x}_2=
\begin{pmatrix}
1 \\
2 \\
0
\end{pmatrix},
\;\;
{\bf x}_3=
\begin{pmatrix}
0 \\
1 \\
-1
\end{pmatrix}?
\end{split}
\end{equation*}

\section{Question D.8}
\label{\detokenize{05.exercises.D:question-d-8}}
\sphinxAtStartPar
What is the rank of the \(N \times N\) identity matrix \({\bf I}\)?

\sphinxAtStartPar
What about the upper\sphinxhyphen{}triangular matrix which non\sphinxhyphen{}zero elements are \(1\)?


\section{Question D.9}
\label{\detokenize{05.exercises.D:question-d-9}}
\sphinxAtStartPar
Show that if \(T: \mathbb{R}^N \to \mathbb{R}^N\) is nonsingular, i.e. linear bijection, the inverse map \(T^{-1}\) is also linear.

\sphinxstepscope


\chapter{Exercise set E}
\label{\detokenize{06.exercises.E:exercise-set-e}}\label{\detokenize{06.exercises.E::doc}}
\sphinxAtStartPar
Please, see the
{\hyperref[\detokenize{02.exercises.A::doc}]{\sphinxcrossref{\DUrole{doc,std,std-doc}{\sphinxstylestrong{general comment on the tutorial exercises}}}}}


\section{Question E.1}
\label{\detokenize{06.exercises.E:question-e-1}}
\sphinxAtStartPar
Show that the function \(f(x) = - |x|\) from \(\mathbb{R}\) to \(\mathbb{R}\) is concave.


\section{Question E.2}
\label{\detokenize{06.exercises.E:question-e-2}}
\sphinxAtStartPar
Let \({\bf A}\) be the \(1 \times 1\) matrix \((a)\). Give a necessary and
sufficient condition on \(a\) (that is, an “if and only if” condition on
\(a\)) under which \({\bf A}\) is nonsingular.


\section{Question E.3}
\label{\detokenize{06.exercises.E:question-e-3}}
\sphinxAtStartPar
Consider the function \(f\) from \(\mathbb{R}\) to \(\mathbb{R}\) defined by
\begin{equation*}
\begin{split}
%
f(x) = (c x)^2 + z
%
\end{split}
\end{equation*}
\sphinxAtStartPar
Give a necessary and sufficient (if and only if) condition on \(c\) under
which \(f\) has a unique minimizer.


\section{Question E.4}
\label{\detokenize{06.exercises.E:question-e-4}}
\sphinxAtStartPar
Let \({\bf C}\) be an \(N \times K\) matrix, let \(z \in \mathbb{R}\) and consider the function
\(f\) from \(\mathbb{R}^K\) to \(\mathbb{R}\) defined by
\begin{equation*}
\begin{split}
%
f({\bf x}) = {\bf x}' {\bf C}' {\bf C} {\bf x} + z
%
\end{split}
\end{equation*}
\sphinxAtStartPar
Show that \(f\) has a unique minimizer on \(\mathbb{R}^K\) if and only if \({\bf C}\)
has linearly independent columns.

\begin{sphinxadmonition}{tip}{Tip:}
\sphinxAtStartPar
Obviously, you should
draw intuition from the preceding question. Also, what does linear
independence of the columns of \({\bf C}\) say about the vector \({\bf C}
{\bf x}\) for different choices of \({\bf x}\)?
\end{sphinxadmonition}


\section{Question E.5}
\label{\detokenize{06.exercises.E:question-e-5}}
\sphinxAtStartPar
Consider the maximization problem
\begin{equation*}
\begin{split}
%
\max_{c_1, c_2} ( \sqrt c_1 + \beta \sqrt{c_2})
%
\end{split}
\end{equation*}
\sphinxAtStartPar
subject to \(c_1, c_2 \geq 0\) and \(p_1 c_1 + p_2 c_2 \leq m\).
Here \(p_1, p_2\) and \(m\) are nonnegative constants, and \(\beta \in (0, 1)\).

\sphinxAtStartPar
Show that this problem has a solution if and only if \(p_1\) and \(p_2\) are both
strictly positive.


\section{Question E.6}
\label{\detokenize{06.exercises.E:question-e-6}}
\sphinxAtStartPar
Let \(A\) be a nonempty bounded set and let \(B := \{ b \in \mathbb{R} \colon b = 2a \text{ for some } a \in A\}\).
Obtain \(\sup B\) in terms of \(\sup A\). Justify your answer.







\renewcommand{\indexname}{Index}
\printindex
\end{document}